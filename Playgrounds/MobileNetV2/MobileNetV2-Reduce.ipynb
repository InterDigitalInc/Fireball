{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing number of parameters of MobileNetV2 Model\n",
    "This notebook shows how to use Low-Rank decomposition to reduce the number of parameters of a MobileNetV2 model. It assumes that a trained model already exist in the ```Models``` directory. Please refer to the notebook [Image Classification with MobileNetV2](MobileNetV2.ipynb) for more info about using a pretrained MobileNetV2 model.\n",
    "\n",
    "## Load and evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading from \"Models/MobileNetV2.fbm\" ... Done.\n",
      "Creating the fireball model \"MobileNetV2\" ... Done.\n",
      "\n",
      "Scope            InShape       Comments                 OutShape      Activ.   Post Act.        # of Params\n",
      "---------------  ------------  -----------------------  ------------  -------  ---------------  -----------\n",
      "IN_IMG                         Image Size: 224x224x3    224 224 3     None                      0          \n",
      "S1_L1_CONV       224 224 3     KSP: 3 2 0x1x0x1         112 112 32    None                      864        \n",
      "S1_L2_BN         112 112 32                             112 112 32    ReLU     x<6.0            128        \n",
      "S2_L1_DWCN       112 112 32    KSP: 3 1 s               112 112 32    None                      288        \n",
      "S2_L2_BN         112 112 32                             112 112 32    ReLU     x<6.0            128        \n",
      "S2_L3_CONV       112 112 32    KSP: 1 1 s               112 112 16    None                      512        \n",
      "S2_L4_BN         112 112 16                             112 112 16    None                      64         \n",
      "S3_L1_MN2        112 112 16    6 layers                 56 56 24      None                      5,568      \n",
      "S3_L2_MN1S       56 56 24      2 Paths, 6 layers        56 56 24      None                      9,456      \n",
      "S4_L1_MN2        56 56 24      6 layers                 28 28 32      None                      10,640     \n",
      "S4_L2_MN1S       28 28 32      2 Paths, 6 layers        28 28 32      None                      15,680     \n",
      "S4_L3_MN1S       28 28 32      2 Paths, 6 layers        28 28 32      None                      15,680     \n",
      "S5_L1_MN2        28 28 32      6 layers                 14 14 64      None                      21,952     \n",
      "S5_L2_MN1S       14 14 64      2 Paths, 6 layers        14 14 64      None                      55,936     \n",
      "S5_L3_MN1S       14 14 64      2 Paths, 6 layers        14 14 64      None                      55,936     \n",
      "S5_L4_MN1S       14 14 64      2 Paths, 6 layers        14 14 64      None                      55,936     \n",
      "S6_L1_MN1        14 14 64      6 layers                 14 14 96      None                      68,352     \n",
      "S6_L2_MN1S       14 14 96      2 Paths, 6 layers        14 14 96      None                      120,768    \n",
      "S6_L3_MN1S       14 14 96      2 Paths, 6 layers        14 14 96      None                      120,768    \n",
      "S7_L1_MN2        14 14 96      6 layers                 7 7 160       None                      157,888    \n",
      "S7_L2_MN1S       7 7 160       2 Paths, 6 layers        7 7 160       None                      324,160    \n",
      "S7_L3_MN1S       7 7 160       2 Paths, 6 layers        7 7 160       None                      324,160    \n",
      "S7_L4_MN1        7 7 160       6 layers                 7 7 320       None                      478,400    \n",
      "S8_L1_CONV       7 7 320       KSP: 1 1 s               7 7 1280      None                      409,600    \n",
      "S8_L2_BN         7 7 1280                               1 1 1280      ReLU     CLP->GAP         5,120      \n",
      "S8_L3_FC         1 1 1280                               1000          None                      1,281,000  \n",
      "OUT_CLASS        1000          1000 classes             1000          None                      0          \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "                                                                  Total Number of parameters: 3,538,984  \n",
      "  Processed 50000 Sample. (Time: 48.58 Sec.)                              \n",
      "\n",
      "Observed Accuracy: 0.711160\n",
      "Top-5 Accuracy:   0.900680\n"
     ]
    }
   ],
   "source": [
    "from fireball import Model\n",
    "from fireball.datasets.imagenet import ImageNetDSet\n",
    "gpus=\"0,1,2,3\"   # Change this to match the GPUs available on your machine\n",
    "\n",
    "testDs = ImageNetDSet.makeDatasets('Test', batchSize=256, preProcessing='Crop256Tf', numWorkers=8)\n",
    "\n",
    "model = Model.makeFromFile(\"Models/MobileNetV2.fbm\", testDs=testDs, gpus=gpus)\n",
    "model.printLayersInfo()\n",
    "model.initSession()\n",
    "\n",
    "results = model.evaluate(topK=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing number of parameters\n",
    "Here we apply Low-Rank Decomposition on different layers of the model to reduce the number of parameters. We first create a list of layers we want to apply Low-Rank Decomposition, with the rank value for each layer. We then pass this information to the ```createLrModel``` method to create a new fireball model saved to the file ```Models/MobileNetV2R.fbm```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now reducing number of network parameters ... \n",
      "  S8_L1_CONV => LR(184), MSE=0.000260, Shape: (320, 1280), Params: 409600->294400 (Reduction: 28.1%)\n",
      "  S8_L3_FC => LR(304), MSE=0.000467, Params: 1280000->693120 (Reduction: 45.9%)\n",
      "Total New Parameters: 2,836,904\n",
      "Done. (14.53 Seconds)\n"
     ]
    }
   ],
   "source": [
    "# Here we want to reduce the number of parameters for layers \"S8_L1_CONV\" and \"S8_L3_FC\".\n",
    "# Instead of specifying the tolerance (MSE), we are using spceific \"rank\" values for each\n",
    "# one of these layers:\n",
    "import time\n",
    "layerParams = [('S8_L1_CONV', 184), ('S8_L3_FC', 304)]\n",
    "print('Now reducing number of network parameters ... ')\n",
    "t0 = time.time()\n",
    "model.createLrModel(\"Models/MobileNetV2R.fbm\", layerParams)\n",
    "print('Done. (%.2f Seconds)'%(time.time()-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the new number of parameters with the original 3,538,984. \n",
    "\n",
    "## Evaluating the new model\n",
    "Let's see the impact of this reduction to the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading from \"Models/MobileNetV2R.fbm\" ... Done.\n",
      "Creating the fireball model \"MobileNetV2\" ... Done.\n",
      "\n",
      "Scope            InShape       Comments                 OutShape      Activ.   Post Act.        # of Params\n",
      "---------------  ------------  -----------------------  ------------  -------  ---------------  -----------\n",
      "IN_IMG                         Image Size: 224x224x3    224 224 3     None                      0          \n",
      "S1_L1_CONV       224 224 3     KSP: 3 2 0x1x0x1         112 112 32    None                      864        \n",
      "S1_L2_BN         112 112 32                             112 112 32    ReLU     x<6.0            128        \n",
      "S2_L1_DWCN       112 112 32    KSP: 3 1 s               112 112 32    None                      288        \n",
      "S2_L2_BN         112 112 32                             112 112 32    ReLU     x<6.0            128        \n",
      "S2_L3_CONV       112 112 32    KSP: 1 1 s               112 112 16    None                      512        \n",
      "S2_L4_BN         112 112 16                             112 112 16    None                      64         \n",
      "S3_L1_MN2        112 112 16    6 layers                 56 56 24      None                      5,568      \n",
      "S3_L2_MN1S       56 56 24      2 Paths, 6 layers        56 56 24      None                      9,456      \n",
      "S4_L1_MN2        56 56 24      6 layers                 28 28 32      None                      10,640     \n",
      "S4_L2_MN1S       28 28 32      2 Paths, 6 layers        28 28 32      None                      15,680     \n",
      "S4_L3_MN1S       28 28 32      2 Paths, 6 layers        28 28 32      None                      15,680     \n",
      "S5_L1_MN2        28 28 32      6 layers                 14 14 64      None                      21,952     \n",
      "S5_L2_MN1S       14 14 64      2 Paths, 6 layers        14 14 64      None                      55,936     \n",
      "S5_L3_MN1S       14 14 64      2 Paths, 6 layers        14 14 64      None                      55,936     \n",
      "S5_L4_MN1S       14 14 64      2 Paths, 6 layers        14 14 64      None                      55,936     \n",
      "S6_L1_MN1        14 14 64      6 layers                 14 14 96      None                      68,352     \n",
      "S6_L2_MN1S       14 14 96      2 Paths, 6 layers        14 14 96      None                      120,768    \n",
      "S6_L3_MN1S       14 14 96      2 Paths, 6 layers        14 14 96      None                      120,768    \n",
      "S7_L1_MN2        14 14 96      6 layers                 7 7 160       None                      157,888    \n",
      "S7_L2_MN1S       7 7 160       2 Paths, 6 layers        7 7 160       None                      324,160    \n",
      "S7_L3_MN1S       7 7 160       2 Paths, 6 layers        7 7 160       None                      324,160    \n",
      "S7_L4_MN1        7 7 160       6 layers                 7 7 320       None                      478,400    \n",
      "S8_L1_CONV       7 7 320       KSP: 1 1 s, LR184        7 7 1280      None                      294,400    \n",
      "S8_L2_BN         7 7 1280                               1 1 1280      ReLU     CLP->GAP         5,120      \n",
      "S8_L3_FC         1 1 1280      LR304                    1000          None                      694,120    \n",
      "OUT_CLASS        1000          1000 classes             1000          None                      0          \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "                                                                  Total Number of parameters: 2,836,904  \n",
      "  Processed 50000 Sample. (Time: 37.49 Sec.)                              \n",
      "\n",
      "Observed Accuracy: 0.645580\n",
      "Top-5 Accuracy:   0.876280\n"
     ]
    }
   ],
   "source": [
    "model = Model.makeFromFile(\"Models/MobileNetV2R.fbm\", testDs=testDs, gpus=gpus)\n",
    "model.printLayersInfo()\n",
    "model.initSession()\n",
    "results = model.evaluate(topK=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-training\n",
    "The following cell creates a \"tune\" dataset by sampling from the training dataset and uses it to re-train the  model for 10 epochs. For better results we could also use the whole training dataset for re-training.\n",
    "\n",
    "If the trained model ```MobileNetV2RR.fbm``` is already available in the ```Models``` directory, this cell shows the results of last training. If you want to force it to do the training again, you can un-remark the lines at the beginning of the cell to delete the existing file. Note that the re-training can take up to 1 hour on a 4-GPU machine (Using the whole training dataset it could take up to 10 hours)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageNetDSet Dataset Info:\n",
      "    Dataset Name ................................... tune\n",
      "    Dataset Location ............................... /data/ImageNet/\n",
      "    Number of Classes .............................. 1000\n",
      "    Number of Samples .............................. 64000\n",
      "    Sample Shape ................................... (224, 224, 3)\n",
      "    Preprocessing .................................. Crop256Tf\n",
      "    Number of Workers .............................. 8\n",
      "\n",
      "\n",
      "Reading from \"Models/MobileNetV2R.fbm\" ... Done.\n",
      "Creating the fireball model \"MobileNetV2\" ... Done.\n",
      "\n",
      "Network configuration:\n",
      "  Input:                     Color images of size 224x224\n",
      "  Output:                    Probability distributions for 1000 classes.\n",
      "  Network Layers:            27\n",
      "  Tower Devices:             GPU0, GPU1, GPU2, GPU3\n",
      "  Total Network Parameters:  2,836,904\n",
      "  Total Parameter Tensors:   264\n",
      "  Trainable Tensors:         160\n",
      "  Training Samples:          64,000\n",
      "  Test Samples:              50,000\n",
      "  Num Epochs:                10\n",
      "  Batch Size:                256\n",
      "  L2 Reg. Factor:            0     \n",
      "  Global Drop Rate:          0   \n",
      "  Learning Rate: (Exponential Decay)\n",
      "    Initial Value:           0.0002       \n",
      "    Final Value:             0.000002     \n",
      "  Optimizer:                 Adam\n",
      "  Save model information to: Models/MobileNetV2RR.fbm\n",
      "\n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "| Epoch  | Batch   | Learning Rate | Loss      | Valid/Test Error  |\n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "| 1      | 250     | 0.00012604985 | 1.0153932 | N/A        33.60% |\n",
      "| 2      | 500     | 0.00007944284 | 0.5235952 | N/A        32.77% |\n",
      "| 3      | 750     | 0.0000500688  | 0.3480202 | N/A        32.47% |\n",
      "| 4      | 1000    | 0.00002997804 | 0.2688038 | N/A        32.25% |\n",
      "| 5      | 1250    | 0.00001889364 | 0.2245957 | N/A        32.35% |\n",
      "| 6      | 1500    | 0.0000119077  | 0.2004078 | N/A        32.32% |\n",
      "| 7      | 1750    | 0.00000750482 | 0.1855461 | N/A        32.34% |\n",
      "| 8      | 2000    | 0.00000449341 | 0.1785426 | N/A        32.37% |\n",
      "| 9      | 2250    | 0.00000283197 | 0.1723043 | N/A        32.40% |\n",
      "| 10     | 2500    | 0.00000178485 | 0.1683987 | N/A        32.39% |\n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "Total Training Time: 2026.42 Seconds\n"
     ]
    }
   ],
   "source": [
    "# Un-remark the following line if you want to delete the existing re-trained model and re-train it again.\n",
    "# import os\n",
    "# if os.path.exists( \"Models/MobileNetV2RR.fbm\" ): os.remove( \"Models/MobileNetV2RR.fbm\" )\n",
    "\n",
    "tuneDs = ImageNetDSet.makeDatasets('tune', batchSize=256, preProcessing='Crop256Tf', numWorkers=8)\n",
    "print(tuneDs)\n",
    "\n",
    "model = Model.makeFromFile(\"Models/MobileNetV2R.fbm\", trainDs=tuneDs, testDs=testDs,\n",
    "                           numEpochs=10,\n",
    "                           learningRate=(0.0002,0.000002),\n",
    "                           optimizer='Adam',\n",
    "                           saveModelFileName=\"Models/MobileNetV2RR.fbm\",  # Save the re-training state ...\n",
    "                           savePeriod=1, saveBest=False,                  # ... every epoch\n",
    "                           gpus=gpus)\n",
    "model.printNetConfig()\n",
    "model.initSession()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model after re-training\n",
    "Let's see how re-training helped with the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading from \"Models/MobileNetV2RR.fbm\" ... Done.\n",
      "Creating the fireball model \"MobileNetV2\" ... Done.\n",
      "  Processed 50000 Sample. (Time: 39.74 Sec.)                              \n",
      "\n",
      "Observed Accuracy: 0.676120\n",
      "Top-5 Accuracy:   0.882240\n"
     ]
    }
   ],
   "source": [
    "model = Model.makeFromFile(\"Models/MobileNetV2RR.fbm\", testDs=testDs, gpus=gpus)\n",
    "model.initSession()\n",
    "results = model.evaluate(topK=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where do I go from here?\n",
    "\n",
    "[Pruning MobileNetV2 Model](MobileNetV2-Prune.ipynb)\n",
    "\n",
    "[Quantizing MobileNetV2 Model](MobileNetV2-Quantize.ipynb)\n",
    "\n",
    "[Exporting MobileNetV2 Model to ONNX](MobileNetV2-ONNX.ipynb)\n",
    "\n",
    "[Exporting MobileNetV2 Model to TensorFlow](MobileNetV2-TF.ipynb)\n",
    "________________\n",
    "\n",
    "[Fireball Playgrounds](../Contents.ipynb)\n",
    "\n",
    "[Image Classification with MobileNetV2](MobileNetV2.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
