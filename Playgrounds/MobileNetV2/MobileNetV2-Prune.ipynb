{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "protected-cedar",
   "metadata": {},
   "source": [
    "# Pruning MobileNetV2 Model\n",
    "This notebook shows how to reduce the size of a model by pruning its parameters. It assumes \n",
    "that a trained ```MobileNetV2``` model already exists in the ```Models``` directory. Please refer to the notebook\n",
    "[Image Classification with MobileNetV2](MobileNetV2.ipynb) for more info about using a pretrained MobileNetV2 model.\n",
    "\n",
    "If you want to prune a Low-Rank model, you can use [this](MobileNetV2-Reduce.ipynb) notebook\n",
    "to reduce the number of parameters in ```MobileNetV2```.\n",
    "\n",
    "## Load and evaluate the original pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "serial-occurrence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading from \"Models/MobileNetV2RR.fbm\" ... Done.\n",
      "Creating the fireball model \"MobileNetV2\" ... Done.\n",
      "\n",
      "Scope            InShape       Comments                 OutShape      Activ.   Post Act.        # of Params\n",
      "---------------  ------------  -----------------------  ------------  -------  ---------------  -----------\n",
      "IN_IMG                         Image Size: 224x224x3    224 224 3     None                      0          \n",
      "S1_L1_CONV       224 224 3     KSP: 3 2 0x1x0x1         112 112 32    None                      864        \n",
      "S1_L2_BN         112 112 32                             112 112 32    ReLU     x<6.0            128        \n",
      "S2_L1_DWCN       112 112 32    KSP: 3 1 s               112 112 32    None                      288        \n",
      "S2_L2_BN         112 112 32                             112 112 32    ReLU     x<6.0            128        \n",
      "S2_L3_CONV       112 112 32    KSP: 1 1 s               112 112 16    None                      512        \n",
      "S2_L4_BN         112 112 16                             112 112 16    None                      64         \n",
      "S3_L1_MN2        112 112 16    6 layers                 56 56 24      None                      5,568      \n",
      "S3_L2_MN1S       56 56 24      2 Paths, 6 layers        56 56 24      None                      9,456      \n",
      "S4_L1_MN2        56 56 24      6 layers                 28 28 32      None                      10,640     \n",
      "S4_L2_MN1S       28 28 32      2 Paths, 6 layers        28 28 32      None                      15,680     \n",
      "S4_L3_MN1S       28 28 32      2 Paths, 6 layers        28 28 32      None                      15,680     \n",
      "S5_L1_MN2        28 28 32      6 layers                 14 14 64      None                      21,952     \n",
      "S5_L2_MN1S       14 14 64      2 Paths, 6 layers        14 14 64      None                      55,936     \n",
      "S5_L3_MN1S       14 14 64      2 Paths, 6 layers        14 14 64      None                      55,936     \n",
      "S5_L4_MN1S       14 14 64      2 Paths, 6 layers        14 14 64      None                      55,936     \n",
      "S6_L1_MN1        14 14 64      6 layers                 14 14 96      None                      68,352     \n",
      "S6_L2_MN1S       14 14 96      2 Paths, 6 layers        14 14 96      None                      120,768    \n",
      "S6_L3_MN1S       14 14 96      2 Paths, 6 layers        14 14 96      None                      120,768    \n",
      "S7_L1_MN2        14 14 96      6 layers                 7 7 160       None                      157,888    \n",
      "S7_L2_MN1S       7 7 160       2 Paths, 6 layers        7 7 160       None                      324,160    \n",
      "S7_L3_MN1S       7 7 160       2 Paths, 6 layers        7 7 160       None                      324,160    \n",
      "S7_L4_MN1        7 7 160       6 layers                 7 7 320       None                      478,400    \n",
      "S8_L1_CONV       7 7 320       KSP: 1 1 s, LR184        7 7 1280      None                      294,400    \n",
      "S8_L2_BN         7 7 1280                               1 1 1280      ReLU     CLP->GAP         5,120      \n",
      "S8_L3_FC         1 1 1280      LR304                    1000          None                      694,120    \n",
      "OUT_CLASS        1000          1000 classes             1000          None                      0          \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "                                                                  Total Number of parameters: 2,836,904  \n",
      "  Processed 50000 Sample. (Time: 46.26 Sec.)                              \n",
      "\n",
      "Observed Accuracy: 0.676120\n",
      "Top-5 Accuracy:   0.882240\n"
     ]
    }
   ],
   "source": [
    "from fireball import Model\n",
    "from fireball.datasets.imagenet import ImageNetDSet\n",
    "gpus='0,1,2,3'\n",
    "\n",
    "# Create the test dataset for evaluation.\n",
    "testDs = ImageNetDSet.makeDatasets('Test', batchSize=256, preProcessing='Crop256Tf', numWorkers=8)\n",
    "\n",
    "# orgFileName = \"Models/MobileNetV2.fbm\"    # Original model\n",
    "# orgFileName = \"Models/MobileNetV2R.fbm\"   # Reduced\n",
    "orgFileName = \"Models/MobileNetV2RR.fbm\"    # Reduced - Retrained\n",
    "\n",
    "model = Model.makeFromFile(orgFileName, testDs=testDs, gpus=gpus)\n",
    "model.initSession()\n",
    "model.printLayersInfo()\n",
    "results = model.evaluate(topK=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-college",
   "metadata": {},
   "source": [
    "## Pruning the model\n",
    "Here we prune the model using the ``pruneModel`` class method of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "suffering-prince",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading model parameters from \"Models/MobileNetV2RR.fbm\" ... Done.\n",
      "Pruning 264 tensors (mseUb=0.000050)\n",
      "    Tensor 1 of 264 Shape: 3x3x3x32 ......... Done. 428 Pruned < 0.030167, MSE=0.000049, Reduced: 46.3%)\n",
      "    Tensor 2 of 264 Shape: 32 ............... Ignored. (1-D Tensor)\n",
      "    Tensor 3 of 264 Shape: 32 ............... Ignored. (1-D Tensor)\n",
      "    Tensor 4 of 264 Shape: 32 ............... Ignored. (1-D Tensor)\n",
      "    Tensor 5 of 264 Shape: 32 ............... Ignored. (1-D Tensor)\n",
      "    Tensor 6 of 264 Shape: 3x3x32x1 ......... Done. 9 Pruned < 0.078409, MSE=0.000046, Reduced: -0.3%)\n",
      "    Tensor 7 of 264 Shape: 32 ............... Ignored. (1-D Tensor)\n",
      "    Tensor 8 of 264 Shape: 32 ............... Ignored. (1-D Tensor)\n",
      "    Tensor 9 of 264 Shape: 32 ............... Ignored. (1-D Tensor)\n",
      "    Tensor 10 of 264 Shape: 32 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 11 of 264 Shape: 1x1x32x16 ....... Done. 247 Pruned < 0.028462, MSE=0.000049, Reduced: 45.0%)\n",
      "    Tensor 12 of 264 Shape: 16 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 13 of 264 Shape: 16 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 14 of 264 Shape: 16 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 15 of 264 Shape: 16 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 16 of 264 Shape: 1x1x16x96 ....... Done. 388 Pruned < 0.024652, MSE=0.000050, Reduced: 22.1%)\n",
      "    Tensor 17 of 264 Shape: 96 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 18 of 264 Shape: 96 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 19 of 264 Shape: 96 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 20 of 264 Shape: 96 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 21 of 264 Shape: 3x3x96x1 ........ Not pruned! (No Reduction - numPruned=19)\n",
      "    Tensor 22 of 264 Shape: 96 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 23 of 264 Shape: 96 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 24 of 264 Shape: 96 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 25 of 264 Shape: 96 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 26 of 264 Shape: 1x1x96x24 ....... Done. 544 Pruned < 0.025548, MSE=0.000050, Reduced: 20.5%)\n",
      "    Tensor 27 of 264 Shape: 24 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 28 of 264 Shape: 24 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 29 of 264 Shape: 24 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 30 of 264 Shape: 24 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 31 of 264 Shape: 1x1x24x144 ...... Done. 922 Pruned < 0.023757, MSE=0.000050, Reduced: 23.5%)\n",
      "    Tensor 32 of 264 Shape: 144 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 33 of 264 Shape: 144 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 34 of 264 Shape: 144 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 35 of 264 Shape: 144 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 36 of 264 Shape: 3x3x144x1 ....... Done. 51 Pruned < 0.053866, MSE=0.000049, Reduced: 0.7%)\n",
      "    Tensor 37 of 264 Shape: 144 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 38 of 264 Shape: 144 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 39 of 264 Shape: 144 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 40 of 264 Shape: 144 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 41 of 264 Shape: 1x1x144x24 ...... Done. 946 Pruned < 0.024274, MSE=0.000050, Reduced: 24.2%)\n",
      "    Tensor 42 of 264 Shape: 24 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 43 of 264 Shape: 24 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 44 of 264 Shape: 24 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 45 of 264 Shape: 24 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 46 of 264 Shape: 1x1x24x144 ...... Done. 862 Pruned < 0.025626, MSE=0.000050, Reduced: 21.8%)\n",
      "    Tensor 47 of 264 Shape: 144 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 48 of 264 Shape: 144 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 49 of 264 Shape: 144 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 50 of 264 Shape: 144 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 51 of 264 Shape: 3x3x144x1 ....... Not pruned! (No Reduction - numPruned=20)\n",
      "    Tensor 52 of 264 Shape: 144 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 53 of 264 Shape: 144 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 54 of 264 Shape: 144 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 55 of 264 Shape: 144 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 56 of 264 Shape: 1x1x144x32 ...... Done. 1066 Pruned < 0.025745, MSE=0.000050, Reduced: 20.0%)\n",
      "    Tensor 57 of 264 Shape: 32 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 58 of 264 Shape: 32 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 59 of 264 Shape: 32 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 60 of 264 Shape: 32 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 61 of 264 Shape: 1x1x32x192 ...... Done. 1870 Pruned < 0.022940, MSE=0.000050, Reduced: 27.3%)\n",
      "    Tensor 62 of 264 Shape: 192 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 63 of 264 Shape: 192 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 64 of 264 Shape: 192 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 65 of 264 Shape: 192 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 66 of 264 Shape: 3x3x192x1 ....... Done. 108 Pruned < 0.049677, MSE=0.000049, Reduced: 3.1%)\n",
      "    Tensor 67 of 264 Shape: 192 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 68 of 264 Shape: 192 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 69 of 264 Shape: 192 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 70 of 264 Shape: 192 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 71 of 264 Shape: 1x1x192x32 ...... Done. 1844 Pruned < 0.022706, MSE=0.000050, Reduced: 26.9%)\n",
      "    Tensor 72 of 264 Shape: 32 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 73 of 264 Shape: 32 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 74 of 264 Shape: 32 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 75 of 264 Shape: 32 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 76 of 264 Shape: 1x1x32x192 ...... Done. 1887 Pruned < 0.022355, MSE=0.000050, Reduced: 27.6%)\n",
      "    Tensor 77 of 264 Shape: 192 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 78 of 264 Shape: 192 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 79 of 264 Shape: 192 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 80 of 264 Shape: 192 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 81 of 264 Shape: 3x3x192x1 ....... Done. 121 Pruned < 0.051167, MSE=0.000050, Reduced: 3.8%)\n",
      "    Tensor 82 of 264 Shape: 192 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 83 of 264 Shape: 192 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 84 of 264 Shape: 192 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 85 of 264 Shape: 192 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 86 of 264 Shape: 1x1x192x32 ...... Done. 1952 Pruned < 0.021978, MSE=0.000050, Reduced: 28.6%)\n",
      "    Tensor 87 of 264 Shape: 32 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 88 of 264 Shape: 32 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 89 of 264 Shape: 32 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 90 of 264 Shape: 32 .............. Ignored. (1-D Tensor)\n",
      "    Tensor 91 of 264 Shape: 1x1x32x192 ...... Done. 1515 Pruned < 0.024897, MSE=0.000050, Reduced: 21.5%)\n",
      "    Tensor 92 of 264 Shape: 192 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 93 of 264 Shape: 192 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 94 of 264 Shape: 192 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 95 of 264 Shape: 192 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 96 of 264 Shape: 3x3x192x1 ....... Not pruned! (No Reduction - numPruned=11)\n",
      "    Tensor 97 of 264 Shape: 192 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 98 of 264 Shape: 192 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 99 of 264 Shape: 192 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 100 of 264 Shape: 192 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 101 of 264 Shape: 1x1x192x64 ..... Done. 3241 Pruned < 0.023824, MSE=0.000050, Reduced: 23.2%)\n",
      "    Tensor 102 of 264 Shape: 64 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 103 of 264 Shape: 64 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 104 of 264 Shape: 64 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 105 of 264 Shape: 64 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 106 of 264 Shape: 1x1x64x384 ..... Done. 9101 Pruned < 0.020438, MSE=0.000050, Reduced: 33.9%)\n",
      "    Tensor 107 of 264 Shape: 384 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 108 of 264 Shape: 384 ............ Ignored. (1-D Tensor)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Tensor 109 of 264 Shape: 384 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 110 of 264 Shape: 384 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 111 of 264 Shape: 3x3x384x1 ...... Done. 227 Pruned < 0.049420, MSE=0.000049, Reduced: 3.4%)\n",
      "    Tensor 112 of 264 Shape: 384 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 113 of 264 Shape: 384 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 114 of 264 Shape: 384 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 115 of 264 Shape: 384 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 116 of 264 Shape: 1x1x384x64 ..... Done. 9695 Pruned < 0.019906, MSE=0.000050, Reduced: 36.3%)\n",
      "    Tensor 117 of 264 Shape: 64 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 118 of 264 Shape: 64 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 119 of 264 Shape: 64 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 120 of 264 Shape: 64 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 121 of 264 Shape: 1x1x64x384 ..... Done. 9287 Pruned < 0.020290, MSE=0.000050, Reduced: 34.7%)\n",
      "    Tensor 122 of 264 Shape: 384 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 123 of 264 Shape: 384 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 124 of 264 Shape: 384 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 125 of 264 Shape: 384 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 126 of 264 Shape: 3x3x384x1 ...... Done. 232 Pruned < 0.047192, MSE=0.000049, Reduced: 3.6%)\n",
      "    Tensor 127 of 264 Shape: 384 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 128 of 264 Shape: 384 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 129 of 264 Shape: 384 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 130 of 264 Shape: 384 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 131 of 264 Shape: 1x1x384x64 ..... Done. 9781 Pruned < 0.019875, MSE=0.000050, Reduced: 36.7%)\n",
      "    Tensor 132 of 264 Shape: 64 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 133 of 264 Shape: 64 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 134 of 264 Shape: 64 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 135 of 264 Shape: 64 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 136 of 264 Shape: 1x1x64x384 ..... Done. 9140 Pruned < 0.020573, MSE=0.000050, Reduced: 34.1%)\n",
      "    Tensor 137 of 264 Shape: 384 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 138 of 264 Shape: 384 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 139 of 264 Shape: 384 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 140 of 264 Shape: 384 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 141 of 264 Shape: 3x3x384x1 ...... Done. 265 Pruned < 0.045493, MSE=0.000050, Reduced: 4.5%)\n",
      "    Tensor 142 of 264 Shape: 384 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 143 of 264 Shape: 384 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 144 of 264 Shape: 384 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 145 of 264 Shape: 384 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 146 of 264 Shape: 1x1x384x64 ..... Done. 9766 Pruned < 0.019943, MSE=0.000050, Reduced: 36.6%)\n",
      "    Tensor 147 of 264 Shape: 64 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 148 of 264 Shape: 64 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 149 of 264 Shape: 64 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 150 of 264 Shape: 64 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 151 of 264 Shape: 1x1x64x384 ..... Done. 7717 Pruned < 0.022275, MSE=0.000050, Reduced: 28.3%)\n",
      "    Tensor 152 of 264 Shape: 384 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 153 of 264 Shape: 384 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 154 of 264 Shape: 384 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 155 of 264 Shape: 384 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 156 of 264 Shape: 3x3x384x1 ...... Done. 262 Pruned < 0.045665, MSE=0.000050, Reduced: 4.4%)\n",
      "    Tensor 157 of 264 Shape: 384 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 158 of 264 Shape: 384 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 159 of 264 Shape: 384 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 160 of 264 Shape: 384 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 161 of 264 Shape: 1x1x384x96 ..... Done. 11641 Pruned < 0.021985, MSE=0.000050, Reduced: 28.5%)\n",
      "    Tensor 162 of 264 Shape: 96 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 163 of 264 Shape: 96 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 164 of 264 Shape: 96 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 165 of 264 Shape: 96 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 166 of 264 Shape: 1x1x96x576 ..... Done. 20231 Pruned < 0.020716, MSE=0.000050, Reduced: 33.5%)\n",
      "    Tensor 167 of 264 Shape: 576 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 168 of 264 Shape: 576 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 169 of 264 Shape: 576 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 170 of 264 Shape: 576 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 171 of 264 Shape: 3x3x576x1 ...... Done. 344 Pruned < 0.047246, MSE=0.000050, Reduced: 3.5%)\n",
      "    Tensor 172 of 264 Shape: 576 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 173 of 264 Shape: 576 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 174 of 264 Shape: 576 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 175 of 264 Shape: 576 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 176 of 264 Shape: 1x1x576x96 ..... Done. 21054 Pruned < 0.020219, MSE=0.000050, Reduced: 34.9%)\n",
      "    Tensor 177 of 264 Shape: 96 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 178 of 264 Shape: 96 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 179 of 264 Shape: 96 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 180 of 264 Shape: 96 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 181 of 264 Shape: 1x1x96x576 ..... Done. 19796 Pruned < 0.020781, MSE=0.000050, Reduced: 32.7%)\n",
      "    Tensor 182 of 264 Shape: 576 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 183 of 264 Shape: 576 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 184 of 264 Shape: 576 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 185 of 264 Shape: 576 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 186 of 264 Shape: 3x3x576x1 ...... Done. 354 Pruned < 0.048174, MSE=0.000050, Reduced: 3.7%)\n",
      "    Tensor 187 of 264 Shape: 576 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 188 of 264 Shape: 576 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 189 of 264 Shape: 576 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 190 of 264 Shape: 576 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 191 of 264 Shape: 1x1x576x96 ..... Done. 20995 Pruned < 0.020279, MSE=0.000050, Reduced: 34.8%)\n",
      "    Tensor 192 of 264 Shape: 96 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 193 of 264 Shape: 96 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 194 of 264 Shape: 96 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 195 of 264 Shape: 96 ............. Ignored. (1-D Tensor)\n",
      "    Tensor 196 of 264 Shape: 1x1x96x576 ..... Done. 17138 Pruned < 0.022409, MSE=0.000050, Reduced: 27.9%)\n",
      "    Tensor 197 of 264 Shape: 576 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 198 of 264 Shape: 576 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 199 of 264 Shape: 576 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 200 of 264 Shape: 576 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 201 of 264 Shape: 3x3x576x1 ...... Not pruned! (No Reduction - numPruned=46)\n",
      "    Tensor 202 of 264 Shape: 576 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 203 of 264 Shape: 576 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 204 of 264 Shape: 576 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 205 of 264 Shape: 576 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 206 of 264 Shape: 1x1x576x160 .... Done. 29411 Pruned < 0.021889, MSE=0.000050, Reduced: 28.8%)\n",
      "    Tensor 207 of 264 Shape: 160 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 208 of 264 Shape: 160 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 209 of 264 Shape: 160 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 210 of 264 Shape: 160 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 211 of 264 Shape: 1x1x160x960 .... Done. 60696 Pruned < 0.019901, MSE=0.000050, Reduced: 36.4%)\n",
      "    Tensor 212 of 264 Shape: 960 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 213 of 264 Shape: 960 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 214 of 264 Shape: 960 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 215 of 264 Shape: 960 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 216 of 264 Shape: 3x3x960x1 ...... Done. 403 Pruned < 0.056068, MSE=0.000050, Reduced: 1.5%)\n",
      "    Tensor 217 of 264 Shape: 960 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 218 of 264 Shape: 960 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 219 of 264 Shape: 960 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 220 of 264 Shape: 960 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 221 of 264 Shape: 1x1x960x160 .... Done. 61951 Pruned < 0.019661, MSE=0.000050, Reduced: 37.2%)\n",
      "    Tensor 222 of 264 Shape: 160 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 223 of 264 Shape: 160 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 224 of 264 Shape: 160 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 225 of 264 Shape: 160 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 226 of 264 Shape: 1x1x160x960 .... Done. 57818 Pruned < 0.020327, MSE=0.000050, Reduced: 34.5%)\n",
      "    Tensor 227 of 264 Shape: 960 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 228 of 264 Shape: 960 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 229 of 264 Shape: 960 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 230 of 264 Shape: 960 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 231 of 264 Shape: 3x3x960x1 ...... Done. 501 Pruned < 0.047437, MSE=0.000050, Reduced: 2.7%)\n",
      "    Tensor 232 of 264 Shape: 960 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 233 of 264 Shape: 960 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 234 of 264 Shape: 960 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 235 of 264 Shape: 960 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 236 of 264 Shape: 1x1x960x160 .... Done. 63500 Pruned < 0.019534, MSE=0.000050, Reduced: 38.2%)\n",
      "    Tensor 237 of 264 Shape: 160 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 238 of 264 Shape: 160 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 239 of 264 Shape: 160 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 240 of 264 Shape: 160 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 241 of 264 Shape: 1x1x160x960 .... Done. 53415 Pruned < 0.021108, MSE=0.000050, Reduced: 31.6%)\n",
      "    Tensor 242 of 264 Shape: 960 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 243 of 264 Shape: 960 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 244 of 264 Shape: 960 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 245 of 264 Shape: 960 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 246 of 264 Shape: 3x3x960x1 ...... Done. 693 Pruned < 0.031982, MSE=0.000050, Reduced: 4.9%)\n",
      "    Tensor 247 of 264 Shape: 960 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 248 of 264 Shape: 960 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 249 of 264 Shape: 960 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 250 of 264 Shape: 960 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 251 of 264 Shape: 1x1x960x320 .... Done. 129665 Pruned < 0.019320, MSE=0.000050, Reduced: 39.1%)\n",
      "    Tensor 252 of 264 Shape: 320 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 253 of 264 Shape: 320 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 254 of 264 Shape: 320 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 255 of 264 Shape: 320 ............ Ignored. (1-D Tensor)\n",
      "    Tensor 256 of 264 Shape: 1x1x320x184 .... Done. 20213 Pruned < 0.021488, MSE=0.000050, Reduced: 31.2%)\n",
      "    Tensor 257 of 264 Shape: 1x1x184x1280 ... Done. 109592 Pruned < 0.018444, MSE=0.000050, Reduced: 43.4%)\n",
      "    Tensor 258 of 264 Shape: 1280 ........... Ignored. (1-D Tensor)\n",
      "    Tensor 259 of 264 Shape: 1280 ........... Ignored. (1-D Tensor)\n",
      "    Tensor 260 of 264 Shape: 1280 ........... Ignored. (1-D Tensor)\n",
      "    Tensor 261 of 264 Shape: 1280 ........... Ignored. (1-D Tensor)\n",
      "    Tensor 262 of 264 Shape: 1280x304 ....... Done. 138311 Pruned < 0.020830, MSE=0.000050, Reduced: 32.4%)\n",
      "    Tensor 263 of 264 Shape: 304x1000 ....... Done. 101992 Pruned < 0.021373, MSE=0.000050, Reduced: 30.4%)\n",
      "    Tensor 264 of 264 Shape: 1000 ........... Ignored. (1-D Tensor)\n",
      "Pruning process complete (0.63 Sec.)\n",
      "Now saving to \"Models/MobileNetV2RRP.fbm\" ... Done.\n",
      "\n",
      "Number of parameters: 2,836,904 -> 1,813,716 (1,023,188 pruned)\n",
      "Model File Size: 11,366,477 -> 7,619,917 bytes\n"
     ]
    }
   ],
   "source": [
    "prunedFileName = orgFileName.replace('.fbm', 'P.fbm')  # Append 'P' to the filename for \"Pruned\"\n",
    "pResults = Model.pruneModel(orgFileName, prunedFileName, mseUb=.00005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-comparative",
   "metadata": {},
   "source": [
    "## Evaluate the pruned model\n",
    "Compare the new number of parameters with the original. Let's see the impact of this reduction to the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial-black",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading from \"Models/MobileNetV2RRP.fbm\" ... Done.\n",
      "Creating the fireball model \"MobileNetV2\" ... Done.\n",
      "\n",
      "Scope            InShape       Comments                 OutShape      Activ.   Post Act.        # of Params\n",
      "---------------  ------------  -----------------------  ------------  -------  ---------------  -----------\n",
      "IN_IMG                         Image Size: 224x224x3    224 224 3     None                      0          \n",
      "S1_L1_CONV       224 224 3     KSP: 3 2 0x1x0x1         112 112 32    None                      436        \n",
      "S1_L2_BN         112 112 32                             112 112 32    ReLU     x<6.0            128        \n",
      "S2_L1_DWCN       112 112 32    KSP: 3 1 s               112 112 32    None                      279        \n",
      "S2_L2_BN         112 112 32                             112 112 32    ReLU     x<6.0            128        \n",
      "S2_L3_CONV       112 112 32    KSP: 1 1 s               112 112 16    None                      265        \n",
      "S2_L4_BN         112 112 16                             112 112 16    None                      64         \n",
      "S3_L1_MN2        112 112 16    6 layers                 56 56 24      None                      4,636      \n",
      "S3_L2_MN1S       56 56 24      2 Paths, 6 layers        56 56 24      None                      7,537      \n",
      "S4_L1_MN2        56 56 24      6 layers                 28 28 32      None                      8,712      \n",
      "S4_L2_MN1S       28 28 32      2 Paths, 6 layers        28 28 32      None                      11,858     \n",
      "S4_L3_MN1S       28 28 32      2 Paths, 6 layers        28 28 32      None                      11,720     \n",
      "S5_L1_MN2        28 28 32      6 layers                 14 14 64      None                      17,196     \n",
      "S5_L2_MN1S       14 14 64      2 Paths, 6 layers        14 14 64      None                      36,913     \n",
      "S5_L3_MN1S       14 14 64      2 Paths, 6 layers        14 14 64      None                      36,636     \n",
      "S5_L4_MN1S       14 14 64      2 Paths, 6 layers        14 14 64      None                      36,765     \n",
      "S6_L1_MN1        14 14 64      6 layers                 14 14 96      None                      48,732     \n",
      "S6_L2_MN1S       14 14 96      2 Paths, 6 layers        14 14 96      None                      79,139     \n",
      "S6_L3_MN1S       14 14 96      2 Paths, 6 layers        14 14 96      None                      79,623     \n",
      "S7_L1_MN2        14 14 96      6 layers                 7 7 160       None                      111,339    \n",
      "S7_L2_MN1S       7 7 160       2 Paths, 6 layers        7 7 160       None                      201,110    \n",
      "S7_L3_MN1S       7 7 160       2 Paths, 6 layers        7 7 160       None                      202,341    \n",
      "S7_L4_MN1        7 7 160       6 layers                 7 7 320       None                      294,627    \n",
      "S8_L1_CONV       7 7 320       KSP: 1 1 s, LR184        7 7 1280      None                      164,595    \n",
      "S8_L2_BN         7 7 1280                               1 1 1280      ReLU     CLP->GAP         5,120      \n",
      "S8_L3_FC         1 1 1280      LR304                    1000          None                      453,817    \n",
      "OUT_CLASS        1000          1000 classes             1000          None                      0          \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "                                                                  Total Number of parameters: 1,813,716  \n",
      "  Processed 50000 Sample. (Time: 72.49 Sec.)                              \n",
      "\n",
      "Observed Accuracy: 0.240780\n"
     ]
    }
   ],
   "source": [
    "model = Model.makeFromFile(prunedFileName, testDs=testDs, gpus=gpus)   \n",
    "model.printLayersInfo()\n",
    "model.initSession()\n",
    "results = model.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-alaska",
   "metadata": {},
   "source": [
    "## Re-training after pruning\n",
    "Here we make a new model for re-training from the file created above. We then call the ```train``` method of the model to start the re-training.\n",
    "\n",
    "After re-training, we run the ```evaluate``` function again to see how the re-training improved the performance\n",
    "of the model.\n",
    "\n",
    "The re-trained model is then saved to a file appending an 'R' letter (for Re-trained) to the end of the pruned model file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sticky-dover",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageNetDSet Dataset Info:\n",
      "    Dataset Name ................................... tune\n",
      "    Dataset Location ............................... /data/ImageNet/\n",
      "    Number of Classes .............................. 1000\n",
      "    Number of Samples .............................. 64000\n",
      "    Sample Shape ................................... (224, 224, 3)\n",
      "    Preprocessing .................................. Crop256Tf\n",
      "    Number of Workers .............................. 8\n",
      "\n",
      "\n",
      "Reading from \"Models/MobileNetV2RRP.fbm\" ... Done.\n",
      "Creating the fireball model \"MobileNetV2\" ... Done.\n",
      "\n",
      "Scope            InShape       Comments                 OutShape      Activ.   Post Act.        # of Params\n",
      "---------------  ------------  -----------------------  ------------  -------  ---------------  -----------\n",
      "IN_IMG                         Image Size: 224x224x3    224 224 3     None                      0          \n",
      "S1_L1_CONV       224 224 3     KSP: 3 2 0x1x0x1         112 112 32    None                      436        \n",
      "S1_L2_BN         112 112 32                             112 112 32    ReLU     x<6.0            128        \n",
      "S2_L1_DWCN       112 112 32    KSP: 3 1 s               112 112 32    None                      279        \n",
      "S2_L2_BN         112 112 32                             112 112 32    ReLU     x<6.0            128        \n",
      "S2_L3_CONV       112 112 32    KSP: 1 1 s               112 112 16    None                      265        \n",
      "S2_L4_BN         112 112 16                             112 112 16    None                      64         \n",
      "S3_L1_MN2        112 112 16    6 layers                 56 56 24      None                      4,636      \n",
      "S3_L2_MN1S       56 56 24      2 Paths, 6 layers        56 56 24      None                      7,537      \n",
      "S4_L1_MN2        56 56 24      6 layers                 28 28 32      None                      8,712      \n",
      "S4_L2_MN1S       28 28 32      2 Paths, 6 layers        28 28 32      None                      11,858     \n",
      "S4_L3_MN1S       28 28 32      2 Paths, 6 layers        28 28 32      None                      11,720     \n",
      "S5_L1_MN2        28 28 32      6 layers                 14 14 64      None                      17,196     \n",
      "S5_L2_MN1S       14 14 64      2 Paths, 6 layers        14 14 64      None                      36,913     \n",
      "S5_L3_MN1S       14 14 64      2 Paths, 6 layers        14 14 64      None                      36,636     \n",
      "S5_L4_MN1S       14 14 64      2 Paths, 6 layers        14 14 64      None                      36,765     \n",
      "S6_L1_MN1        14 14 64      6 layers                 14 14 96      None                      48,732     \n",
      "S6_L2_MN1S       14 14 96      2 Paths, 6 layers        14 14 96      None                      79,139     \n",
      "S6_L3_MN1S       14 14 96      2 Paths, 6 layers        14 14 96      None                      79,623     \n",
      "S7_L1_MN2        14 14 96      6 layers                 7 7 160       None                      111,339    \n",
      "S7_L2_MN1S       7 7 160       2 Paths, 6 layers        7 7 160       None                      201,110    \n",
      "S7_L3_MN1S       7 7 160       2 Paths, 6 layers        7 7 160       None                      202,341    \n",
      "S7_L4_MN1        7 7 160       6 layers                 7 7 320       None                      294,627    \n",
      "S8_L1_CONV       7 7 320       KSP: 1 1 s, LR184        7 7 1280      None                      164,595    \n",
      "S8_L2_BN         7 7 1280                               1 1 1280      ReLU     CLP->GAP         5,120      \n",
      "S8_L3_FC         1 1 1280      LR304                    1000          None                      453,817    \n",
      "OUT_CLASS        1000          1000 classes             1000          None                      0          \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "                                                                  Total Number of parameters: 1,813,716  \n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "| Epoch  | Batch   | Learning Rate | Loss      | Valid/Test Error  |\n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "| 1      | 250     | 0.00003151246 | 0.4059965 | N/A        34.85% |\n",
      "| 2      | 500     | 0.00001986071 | 0.3138709 | N/A        34.37% |\n",
      "| 3      | 750     | 0.0000125172  | 0.2820887 | N/A        34.29% |\n",
      "| 4      | 1000    | 0.00000749451 | 0.2674916 | N/A        34.25% |\n",
      "| 5      | 1250    | 0.00000472341 | 0.2580876 | N/A        34.22% |\n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "Total Training Time: 992.85 Seconds\n",
      "  Processed 50000 Sample. (Time: 35.26 Sec.)                              \n",
      "\n",
      "Observed Accuracy: 0.657820\n",
      "Top-5 Accuracy:   0.871800\n"
     ]
    }
   ],
   "source": [
    "tuneDs = ImageNetDSet.makeDatasets('tune', batchSize=256, preProcessing='Crop256Tf', numWorkers=8)\n",
    "print(tuneDs)\n",
    "\n",
    "model = Model.makeFromFile(prunedFileName, trainDs=tuneDs, testDs=testDs,\n",
    "                           numEpochs=5,\n",
    "                           learningRate=(0.00005, 0.000005),\n",
    "                           optimizer=\"Adam\",\n",
    "                           gpus=gpus)\n",
    "model.printLayersInfo()\n",
    "model.initSession()\n",
    "model.train()\n",
    "results = model.evaluate(topK=5)\n",
    "\n",
    "retrainedFileName = prunedFileName.replace('.fbm', 'R.fbm')  # Append 'R' to the filename for \"Retrained\"\n",
    "model.save(retrainedFileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-model",
   "metadata": {},
   "source": [
    "## Where do I go from here?\n",
    "\n",
    "[Quantizing MobileNetV2 Model](MobileNetV2-Quantize.ipynb)\n",
    "\n",
    "[Exporting MobileNetV2 Model to ONNX](MobileNetV2-ONNX.ipynb)\n",
    "\n",
    "[Exporting MobileNetV2 Model to TensorFlow](MobileNetV2-TF.ipynb)\n",
    "\n",
    "[Exporting MobileNetV2 Model to CoreML](MobileNetV2-CoreML.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "[Fireball Playgrounds](../Contents.ipynb)\n",
    "\n",
    "[Image Classification with MobileNetV2](MobileNetV2.ipynb)\n",
    "\n",
    "[Reducing number of parameters of MobileNetV2 Model](MobileNetV2-Reduce.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
