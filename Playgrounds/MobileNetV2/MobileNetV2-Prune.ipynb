{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "protected-cedar",
   "metadata": {},
   "source": [
    "# Pruning MobileNetV2 Model\n",
    "This notebook shows how to reduce the size of a model by pruning its parameters. It assumes \n",
    "that a trained ```MobileNetV2``` model already exists in the ```Models``` directory. Please refer to the notebook\n",
    "[Image Classification with MobileNetV2](MobileNetV2.ipynb) for more info about using a pretrained MobileNetV2 model.\n",
    "\n",
    "If you want to prune a Low-Rank model, you can use [this](MobileNetV2-Reduce.ipynb) notebook\n",
    "to reduce the number of parameters in ```MobileNetV2```.\n",
    "\n",
    "## Load and evaluate the original pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "serial-occurrence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading from \"Models/MobileNetV2RR.fbm\" ... Done.\n",
      "Creating the fireball model \"MobileNetV2\" ... Done.\n",
      "\n",
      "Scope            InShape       Comments                 OutShape      Activ.   Post Act.        # of Params\n",
      "---------------  ------------  -----------------------  ------------  -------  ---------------  -----------\n",
      "IN_IMG                         Image Size: 224x224x3    224 224 3     None                      0          \n",
      "S1_L1_CONV       224 224 3     KSP: 3 2 0x1x0x1         112 112 32    None                      864        \n",
      "S1_L2_BN         112 112 32                             112 112 32    ReLU     x<6.0            128        \n",
      "S2_L1_DWCN       112 112 32    KSP: 3 1 s               112 112 32    None                      288        \n",
      "S2_L2_BN         112 112 32                             112 112 32    ReLU     x<6.0            128        \n",
      "S2_L3_CONV       112 112 32    KSP: 1 1 s               112 112 16    None                      512        \n",
      "S2_L4_BN         112 112 16                             112 112 16    None                      64         \n",
      "S3_L1_MN2        112 112 16    6 layers                 56 56 24      None                      5,568      \n",
      "S3_L2_MN1S       56 56 24      2 Paths, 6 layers        56 56 24      None                      9,456      \n",
      "S4_L1_MN2        56 56 24      6 layers                 28 28 32      None                      10,640     \n",
      "S4_L2_MN1S       28 28 32      2 Paths, 6 layers        28 28 32      None                      15,680     \n",
      "S4_L3_MN1S       28 28 32      2 Paths, 6 layers        28 28 32      None                      15,680     \n",
      "S5_L1_MN2        28 28 32      6 layers                 14 14 64      None                      21,952     \n",
      "S5_L2_MN1S       14 14 64      2 Paths, 6 layers        14 14 64      None                      55,936     \n",
      "S5_L3_MN1S       14 14 64      2 Paths, 6 layers        14 14 64      None                      55,936     \n",
      "S5_L4_MN1S       14 14 64      2 Paths, 6 layers        14 14 64      None                      55,936     \n",
      "S6_L1_MN1        14 14 64      6 layers                 14 14 96      None                      68,352     \n",
      "S6_L2_MN1S       14 14 96      2 Paths, 6 layers        14 14 96      None                      120,768    \n",
      "S6_L3_MN1S       14 14 96      2 Paths, 6 layers        14 14 96      None                      120,768    \n",
      "S7_L1_MN2        14 14 96      6 layers                 7 7 160       None                      157,888    \n",
      "S7_L2_MN1S       7 7 160       2 Paths, 6 layers        7 7 160       None                      324,160    \n",
      "S7_L3_MN1S       7 7 160       2 Paths, 6 layers        7 7 160       None                      324,160    \n",
      "S7_L4_MN1        7 7 160       6 layers                 7 7 320       None                      478,400    \n",
      "S8_L1_CONV       7 7 320       KSP: 1 1 s, LR184        7 7 1280      None                      294,400    \n",
      "S8_L2_BN         7 7 1280                               1 1 1280      ReLU     CLP->GAP         5,120      \n",
      "S8_L3_FC         1 1 1280      LR304                    1000          None                      694,120    \n",
      "OUT_CLASS        1000          1000 classes             1000          None                      0          \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "                                                                  Total Number of parameters: 2,836,904  \n",
      "  Processed 50000 Sample. (Time: 50.54 Sec.)                              \n",
      "\n",
      "Observed Accuracy: 0.656100\n",
      "Top-5 Accuracy:   0.866140\n"
     ]
    }
   ],
   "source": [
    "from fireball import Model\n",
    "from fireball.datasets.imagenet import ImageNetDSet\n",
    "gpus='0,1,2,3'\n",
    "\n",
    "# Create the test dataset for evaluation.\n",
    "testDs = ImageNetDSet.makeDatasets('Test', batchSize=256, preProcessing='Crop256Tf', numWorkers=8)\n",
    "\n",
    "# orgFileName = \"Models/MobileNetV2.fbm\"    # Original model\n",
    "# orgFileName = \"Models/MobileNetV2R.fbm\"   # Reduced\n",
    "orgFileName = \"Models/MobileNetV2RR.fbm\"    # Reduced - Retrained\n",
    "\n",
    "model = Model.makeFromFile(orgFileName, testDs=testDs, gpus=gpus)\n",
    "model.initSession()\n",
    "model.printLayersInfo()\n",
    "results = model.evaluate(topK=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-college",
   "metadata": {},
   "source": [
    "## Pruning the model\n",
    "Here we prune the model using the [pruneModel](https://interdigitalinc.github.io/Fireball/html/source/model.html#fireball.model.Model.pruneModel) class method of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "suffering-prince",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading model parameters from \"Models/MobileNetV2RR.fbm\" ... Done.\n",
      "Pruning 264 tensors using 20 workers ... \n",
      "   Pruning Parameters:\n",
      "        mseUb ................ 0.000050\n",
      "Pruning process complete (1.19 Sec.)\n",
      "Now saving to \"Models/MobileNetV2RRP.fbm\" ... Done.\n",
      "\n",
      "Number of parameters: 2,836,904 -> 1,833,245 (1,003,659 pruned)\n",
      "Model File Size: 11,373,248 -> 7,706,069 bytes\n"
     ]
    }
   ],
   "source": [
    "prunedFileName = orgFileName.replace('.fbm', 'P.fbm')  # Append 'P' to the filename for \"Pruned\"\n",
    "pResults = Model.pruneModel(orgFileName, prunedFileName, mseUb=.00005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-comparative",
   "metadata": {},
   "source": [
    "## Evaluate the pruned model\n",
    "Compare the new number of parameters with the original. Let's see the impact of this reduction to the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial-black",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading from \"Models/MobileNetV2RRP.fbm\" ... Done.\n",
      "Creating the fireball model \"MobileNetV2\" ... Done.\n",
      "\n",
      "Scope            InShape       Comments                 OutShape      Activ.   Post Act.        # of Params\n",
      "---------------  ------------  -----------------------  ------------  -------  ---------------  -----------\n",
      "IN_IMG                         Image Size: 224x224x3    224 224 3     None                      0          \n",
      "S1_L1_CONV       224 224 3     KSP: 3 2 0x1x0x1         112 112 32    None                      438        \n",
      "S1_L2_BN         112 112 32                             112 112 32    ReLU     x<6.0            128        \n",
      "S2_L1_DWCN       112 112 32    KSP: 3 1 s               112 112 32    None                      279        \n",
      "S2_L2_BN         112 112 32                             112 112 32    ReLU     x<6.0            128        \n",
      "S2_L3_CONV       112 112 32    KSP: 1 1 s               112 112 16    None                      265        \n",
      "S2_L4_BN         112 112 16                             112 112 16    None                      64         \n",
      "S3_L1_MN2        112 112 16    6 layers                 56 56 24      None                      4,613      \n",
      "S3_L2_MN1S       56 56 24      2 Paths, 6 layers        56 56 24      None                      7,533      \n",
      "S4_L1_MN2        56 56 24      6 layers                 28 28 32      None                      8,697      \n",
      "S4_L2_MN1S       28 28 32      2 Paths, 6 layers        28 28 32      None                      11,876     \n",
      "S4_L3_MN1S       28 28 32      2 Paths, 6 layers        28 28 32      None                      11,708     \n",
      "S5_L1_MN2        28 28 32      6 layers                 14 14 64      None                      17,217     \n",
      "S5_L2_MN1S       14 14 64      2 Paths, 6 layers        14 14 64      None                      37,079     \n",
      "S5_L3_MN1S       14 14 64      2 Paths, 6 layers        14 14 64      None                      36,816     \n",
      "S5_L4_MN1S       14 14 64      2 Paths, 6 layers        14 14 64      None                      36,858     \n",
      "S6_L1_MN1        14 14 64      6 layers                 14 14 96      None                      48,818     \n",
      "S6_L2_MN1S       14 14 96      2 Paths, 6 layers        14 14 96      None                      79,397     \n",
      "S6_L3_MN1S       14 14 96      2 Paths, 6 layers        14 14 96      None                      79,937     \n",
      "S7_L1_MN2        14 14 96      6 layers                 7 7 160       None                      111,501    \n",
      "S7_L2_MN1S       7 7 160       2 Paths, 6 layers        7 7 160       None                      202,135    \n",
      "S7_L3_MN1S       7 7 160       2 Paths, 6 layers        7 7 160       None                      203,413    \n",
      "S7_L4_MN1        7 7 160       6 layers                 7 7 320       None                      296,065    \n",
      "S8_L1_CONV       7 7 320       KSP: 1 1 s, LR184        7 7 1280      None                      166,088    \n",
      "S8_L2_BN         7 7 1280                               1 1 1280      ReLU     CLP->GAP         5,120      \n",
      "S8_L3_FC         1 1 1280      LR304                    1000          None                      467,072    \n",
      "OUT_CLASS        1000          1000 classes             1000          None                      0          \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "                                                                  Total Number of parameters: 1,833,245  \n",
      "  Processed 50000 Sample. (Time: 44.83 Sec.)                              \n",
      "\n",
      "Observed Accuracy: 0.186300\n"
     ]
    }
   ],
   "source": [
    "model = Model.makeFromFile(prunedFileName, testDs=testDs, gpus=gpus)   \n",
    "model.printLayersInfo()\n",
    "model.initSession()\n",
    "results = model.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-alaska",
   "metadata": {},
   "source": [
    "## Re-training after pruning\n",
    "Here we first make a new model from the file created above. We then call the [train](https://interdigitalinc.github.io/Fireball/html/source/model.html#fireball.model.Model.train) method of the model to start the re-training.\n",
    "\n",
    "After re-training, we run the [evaluate](https://interdigitalinc.github.io/Fireball/html/source/model.html#fireball.model.Model.evaluate) function again to see how the re-training improved the performance\n",
    "of the model.\n",
    "\n",
    "The re-trained model is then saved to a file appending an 'R' letter (for Re-trained) to the end of the pruned model file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sticky-dover",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageNetDSet Dataset Info:\n",
      "    Dataset Name ................................... tune\n",
      "    Dataset Location ............................... /home/shahab/data/ImageNet/\n",
      "    Number of Classes .............................. 1000\n",
      "    Number of Samples .............................. 64000\n",
      "    Sample Shape ................................... (224, 224, 3)\n",
      "    Preprocessing .................................. Crop256Tf\n",
      "    Number of Workers .............................. 8\n",
      "\n",
      "\n",
      "Reading from \"Models/MobileNetV2RRP.fbm\" ... Done.\n",
      "Creating the fireball model \"MobileNetV2\" ... Done.\n",
      "\n",
      "Scope            InShape       Comments                 OutShape      Activ.   Post Act.        # of Params\n",
      "---------------  ------------  -----------------------  ------------  -------  ---------------  -----------\n",
      "IN_IMG                         Image Size: 224x224x3    224 224 3     None                      0          \n",
      "S1_L1_CONV       224 224 3     KSP: 3 2 0x1x0x1         112 112 32    None                      438        \n",
      "S1_L2_BN         112 112 32                             112 112 32    ReLU     x<6.0            128        \n",
      "S2_L1_DWCN       112 112 32    KSP: 3 1 s               112 112 32    None                      279        \n",
      "S2_L2_BN         112 112 32                             112 112 32    ReLU     x<6.0            128        \n",
      "S2_L3_CONV       112 112 32    KSP: 1 1 s               112 112 16    None                      265        \n",
      "S2_L4_BN         112 112 16                             112 112 16    None                      64         \n",
      "S3_L1_MN2        112 112 16    6 layers                 56 56 24      None                      4,613      \n",
      "S3_L2_MN1S       56 56 24      2 Paths, 6 layers        56 56 24      None                      7,533      \n",
      "S4_L1_MN2        56 56 24      6 layers                 28 28 32      None                      8,697      \n",
      "S4_L2_MN1S       28 28 32      2 Paths, 6 layers        28 28 32      None                      11,876     \n",
      "S4_L3_MN1S       28 28 32      2 Paths, 6 layers        28 28 32      None                      11,708     \n",
      "S5_L1_MN2        28 28 32      6 layers                 14 14 64      None                      17,217     \n",
      "S5_L2_MN1S       14 14 64      2 Paths, 6 layers        14 14 64      None                      37,079     \n",
      "S5_L3_MN1S       14 14 64      2 Paths, 6 layers        14 14 64      None                      36,816     \n",
      "S5_L4_MN1S       14 14 64      2 Paths, 6 layers        14 14 64      None                      36,858     \n",
      "S6_L1_MN1        14 14 64      6 layers                 14 14 96      None                      48,818     \n",
      "S6_L2_MN1S       14 14 96      2 Paths, 6 layers        14 14 96      None                      79,397     \n",
      "S6_L3_MN1S       14 14 96      2 Paths, 6 layers        14 14 96      None                      79,937     \n",
      "S7_L1_MN2        14 14 96      6 layers                 7 7 160       None                      111,501    \n",
      "S7_L2_MN1S       7 7 160       2 Paths, 6 layers        7 7 160       None                      202,135    \n",
      "S7_L3_MN1S       7 7 160       2 Paths, 6 layers        7 7 160       None                      203,413    \n",
      "S7_L4_MN1        7 7 160       6 layers                 7 7 320       None                      296,065    \n",
      "S8_L1_CONV       7 7 320       KSP: 1 1 s, LR184        7 7 1280      None                      166,088    \n",
      "S8_L2_BN         7 7 1280                               1 1 1280      ReLU     CLP->GAP         5,120      \n",
      "S8_L3_FC         1 1 1280      LR304                    1000          None                      467,072    \n",
      "OUT_CLASS        1000          1000 classes             1000          None                      0          \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "                                                                  Total Number of parameters: 1,833,245  \n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "| Epoch  | Batch   | Learning Rate | Loss      | Valid/Test Error  |\n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "| 1      | 249     | 0.00003151246 | 0.1061049 | N/A        36.82% |\n",
      "| 2      | 499     | 0.00001986071 | 0.0890924 | N/A        36.30% |\n",
      "| 3      | 749     | 0.0000125172  | 0.0789132 | N/A        36.18% |\n",
      "| 4      | 999     | 0.00000749451 | 0.0735984 | N/A        36.25% |\n",
      "| 5      | 1249    | 0.00000472341 | 0.0704228 | N/A        36.16% |\n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "Total Training Time: 1151.87 Seconds\n",
      "  Processed 50000 Sample. (Time: 41.77 Sec.)                              \n",
      "\n",
      "Observed Accuracy: 0.638380\n",
      "Top-5 Accuracy:   0.853740\n"
     ]
    }
   ],
   "source": [
    "tuneDs = ImageNetDSet.makeDatasets('tune', batchSize=256, preProcessing='Crop256Tf', numWorkers=8)\n",
    "print(tuneDs)\n",
    "\n",
    "model = Model.makeFromFile(prunedFileName, trainDs=tuneDs, testDs=testDs,\n",
    "                           numEpochs=5,\n",
    "                           learningRate=(0.00005, 0.000005),\n",
    "                           optimizer=\"Adam\",\n",
    "                           gpus=gpus)\n",
    "model.printLayersInfo()\n",
    "model.initSession()\n",
    "model.train()\n",
    "results = model.evaluate(topK=5)\n",
    "\n",
    "retrainedFileName = prunedFileName.replace('.fbm', 'R.fbm')  # Append 'R' to the filename for \"Retrained\"\n",
    "model.save(retrainedFileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-model",
   "metadata": {},
   "source": [
    "## Where do I go from here?\n",
    "\n",
    "[Quantizing MobileNetV2 Model](MobileNetV2-Quantize.ipynb)\n",
    "\n",
    "[Exporting MobileNetV2 Model to ONNX](MobileNetV2-ONNX.ipynb)\n",
    "\n",
    "[Exporting MobileNetV2 Model to TensorFlow](MobileNetV2-TF.ipynb)\n",
    "\n",
    "[Exporting MobileNetV2 Model to CoreML](MobileNetV2-CoreML.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "[Fireball Playgrounds](../Contents.ipynb)\n",
    "\n",
    "[Image Classification with MobileNetV2](MobileNetV2.ipynb)\n",
    "\n",
    "[Reducing number of parameters of MobileNetV2 Model](MobileNetV2-Reduce.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
