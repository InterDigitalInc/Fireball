{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantizing the MobileNetV2 Model\n",
    "This notebook shows how to quantize a pre-trained Fireball model using Codebook Quantization. It assumes \n",
    "that a trained ```MobileNetV2``` model already exists in the ```Models``` directory. Please refer to the notebook\n",
    "[Image Classification with MobileNetV2](MobileNetV2.ipynb) for more info about using a pretrained MobileNetV2 model.\n",
    "\n",
    "If you want to quantize a Low-Rank model, you can use [this](MobileNetV2-Reduce.ipynb) notebook\n",
    "to reduce the number of parameters in ```MobileNetV2```.\n",
    "\n",
    "Model quantization reduces the size of the model by using less number of bits for each floating \n",
    "point parameter. Fireball uses a codebook quantization method based on K-Means clustering algorithm.\n",
    "\n",
    "```quantizeModel``` is a class method that receives the file names of input and output to the \n",
    "quantization process. It also receives the quantization parameters such as ```minBits```, ```maxBits```, \n",
    "```mse```, and ```pdfFactor```.\n",
    "\n",
    "Fireball can create models with 2-bit to 12-bit quantization (Codebook sizes 4 to 4096). For the quantized\n",
    "model to be compatible with ```CoreML```, we need to make sure the codebook size is a power of 2, less than or equal to 256, and only \"weight\" parameters are quantized (not biases)\n",
    "\n",
    "## Quantizing a pretrained model\n",
    "The code in the following cell quantizes the model specified by ```orgFileName``` and creates a new quantized model.\n",
    "\n",
    "For each parameter tensor of the model, we try quantization bits 2 to 8 and find the best quantization that satisfies the specified MSE value.\n",
    "\n",
    "To get better quantization (smaller model) increase ```mse```; to get better performance (larger model)\n",
    "use a smaller ```mse```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading model parameters from \"Models/MobileNetV2RRPR.fbm\" ... Done.\n",
      "Quantizing 264 tensors using 20 workers ... \n",
      "   Quantization Parameters:\n",
      "        mseUb .............. 1.6e-05\n",
      "        pdfFactor .......... 0.1\n",
      "        reuseEmptyClusters . True\n",
      "        weightsOnly ........ True\n",
      "        minBits ............ 2\n",
      "        maxBits ............ 8\n",
      "Quantization complete (1.01 Sec.)).\n",
      "Now saving to \"Models/MobileNetV2RRPRQ.fbm\" ... Done.\n",
      "\n",
      "Size of Data: 7,680,163 -> 2,581,447 bytes\n",
      "Model File Size: 7,726,371 -> 2,628,765 bytes\n"
     ]
    }
   ],
   "source": [
    "from fireball import Model\n",
    "gpus='0,1,2,3'\n",
    "\n",
    "# orgFileName = \"Models/MobileNetV2.fbm\"        # Original model\n",
    "# orgFileName = \"Models/MobileNetV2P.fbm\"       # Pruned\n",
    "# orgFileName = \"Models/MobileNetV2PR.fbm\"      # Pruned - Retrained\n",
    "# orgFileName = \"Models/MobileNetV2R.fbm\"       # Reduced\n",
    "# orgFileName = \"Models/MobileNetV2RP.fbm\"      # Reduced - Pruned\n",
    "# orgFileName = \"Models/MobileNetV2RP.fbm\"      # Reduced - Pruned - Retrained\n",
    "# orgFileName = \"Models/MobileNetV2RR.fbm\"      # Reduced - Retrained\n",
    "# orgFileName = \"Models/MobileNetV2RRP.fbm\"     # Reduced - Retrained - Pruned\n",
    "orgFileName = \"Models/MobileNetV2RRPR.fbm\"    # Reduced - Retrained - Pruned - Retrained\n",
    "\n",
    "\n",
    "quantizedFileName = orgFileName.replace('.fbm', 'Q.fbm')  # Append 'Q' to the filename for \"Quantized\"\n",
    "\n",
    "\n",
    "qResults = Model.quantizeModel(orgFileName, quantizedFileName,\n",
    "                               mseUb=0.000016, minBits=2, maxBits=8, reuseEmptyClusters=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the data size before and after quantization. \n",
    "\n",
    "## Evaluate the quantized model\n",
    "Let's see the impact on model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading from \"Models/MobileNetV2RRPRQ.fbm\" ... Done.\n",
      "Creating the fireball model \"MobileNetV2\" ... Done.\n",
      "  Processed 50000 Sample. (Time: 52.89 Sec.)                              \n",
      "\n",
      "Observed Accuracy: 0.589240\n",
      "Top-5 Accuracy:   0.818640\n"
     ]
    }
   ],
   "source": [
    "from fireball import Model\n",
    "from fireball.datasets.imagenet import ImageNetDSet\n",
    "\n",
    "# Create the test dataset for evaluation.\n",
    "testDs = ImageNetDSet.makeDatasets('Test', batchSize=256, preProcessing='Crop256Tf', numWorkers=8)\n",
    "\n",
    "model = Model.makeFromFile(quantizedFileName, testDs=testDs, gpus=gpus)\n",
    "model.initSession()\n",
    "results = model.evaluate(topK=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-train and evaluate\n",
    "Fireball can retrain the quantized models by modifying the quantization codebooks. The following cell creates a \"tune\" dataset by sampling from the training dataset and uses it to \"fine-tune\" the quantized model for 5 epochs.\n",
    "\n",
    "If the trained model specified by ```quantizedFileName``` is already available in the ```Models``` directory, this cell shows the results of last training. If you want to force it to do the training again, you can un-remark the line at the beginning of the cell to delete the existing file. Since we use the \"tuning\" dataset instead of \"training\" dataset, this is much faster (Under 10 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageNetDSet Dataset Info:\n",
      "    Dataset Name ................................... tune\n",
      "    Dataset Location ............................... /home/shahab/data/ImageNet/\n",
      "    Number of Classes .............................. 1000\n",
      "    Number of Samples .............................. 64000\n",
      "    Sample Shape ................................... (224, 224, 3)\n",
      "    Preprocessing .................................. Crop256Tf\n",
      "    Number of Workers .............................. 8\n",
      "\n",
      "\n",
      "Reading from \"Models/MobileNetV2RRPRQ.fbm\" ... Done.\n",
      "Creating the fireball model \"MobileNetV2\" ... Done.\n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "| Epoch  | Batch   | Learning Rate | Loss      | Valid/Test Error  |\n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "| 1      | 249     | 9.9999998e-14 | 0.0487485 | N/A        36.71% |\n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "Total Training Time: 240.47 Seconds\n",
      "  Processed 50000 Sample. (Time: 42.62 Sec.)                              \n",
      "\n",
      "Observed Accuracy: 0.632920\n",
      "Top-5 Accuracy:   0.850700\n"
     ]
    }
   ],
   "source": [
    "tuneDs = ImageNetDSet.makeDatasets('tune', batchSize=256, preProcessing='Crop256Tf', numWorkers=8)\n",
    "print(tuneDs)\n",
    "\n",
    "model = Model.makeFromFile(quantizedFileName, trainDs=tuneDs, testDs=testDs,\n",
    "                           numEpochs=1,\n",
    "                           learningRate=1e-13,\n",
    "                           optimizer=\"Momentum\",\n",
    "                           gpus=gpus)\n",
    "model.initSession()\n",
    "model.train()\n",
    "results = model.evaluate(topK=5)\n",
    "\n",
    "retrainedFileName = quantizedFileName.replace('.fbm', 'R.fbm')  # Append 'R' to the filename for \"Re-trained\"\n",
    "model.save(retrainedFileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where do I go from here?\n",
    "\n",
    "[Exporting MobileNetV2 Model to ONNX](MobileNetV2-ONNX.ipynb)\n",
    "\n",
    "[Exporting MobileNetV2 Model to TensorFlow](MobileNetV2-TF.ipynb)\n",
    "\n",
    "[Exporting MobileNetV2 Model to CoreML](MobileNetV2-CoreML.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "[Fireball Playgrounds](../Contents.ipynb)\n",
    "\n",
    "[Image Classification with MobileNetV2](MobileNetV2.ipynb)\n",
    "\n",
    "[Reducing number of parameters of MobileNetV2 Model](MobileNetV2-Reduce.ipynb)\n",
    "\n",
    "[Pruning MobileNetV2 Model](MobileNetV2-Prune.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
