{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification with ResNet50\n",
    "A residual neural network (https://arxiv.org/abs/1512.03385) is an artificial neural network (ANN) of a kind that builds on constructs known from pyramidal cells in the cerebral cortex. Residual neural networks do this by utilizing skip connections, or shortcuts to jump over some layers. \n",
    "\n",
    "In this playground we load a pre-trained ResNet50 model and do some inference and evaluation on ImageNet dataset.\n",
    "\n",
    "Note: Fireball uses the OpenCV python package to process images in the ImageNet dataset. If this package is not installed already, you can just run the following command in a new cell and restart the kernel.\n",
    "\n",
    "```\n",
    "%pip install opencv-python\n",
    "```\n",
    "\n",
    "## Create an ImageNet dataset\n",
    "Lets first load the ImageNet dataset and see dataset statistics.\n",
    "\n",
    "**Note 1:** ResNet50 uses the \"Crop256Cafe\" pre-processing for the images. This pre-processing first resizes the image (keeping the aspect ratio) so that its smaller dimension is 256. It then crops a 224x224 image from the center of the resized image. The image is in BGR format and the values are normalized using mean values 103.939, 116.779, 123.68 for blue, green, and red respectively. Please refer to Fireball's ```imagenet.py``` file for more information about different types of pre-processing supported by Fireball.\n",
    "\n",
    "**Note 2:** If the ImageNet dataset is not available on this machine, the following code can take a long time the first time it is executed as the dataset needs to be downloaded and intialized. Please be patient and avoid interrupting the process during the download.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating folder \"./Models/\" ...\n",
      "Downloading from \"https://fireball.s3.us-west-1.amazonaws.com/Models/Fireball/ResNet50.fbm\" ...\n",
      "  Success!\n",
      "\n",
      "Preparing ImageNet dataset ... Done.\n",
      "ImageNetDSet Dataset Info:\n",
      "    Number of Classes .............................. 1000\n",
      "    Dataset Location ............................... /home/shahab/data/ImageNet/\n",
      "    Number of Training Samples ..................... 1281167\n",
      "    Number of Test Samples ......................... 50000\n",
      "    Sample Shape ................................... (224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time, os\n",
    "from fireball import Model, Block, myPrint\n",
    "from fireball.datasets.imagenet import ImageNetDSet\n",
    "\n",
    "gpus=\"0,1,2,3\"\n",
    "\n",
    "# Preparing the dataset and model (Downloading them if necessary)\n",
    "ImageNetDSet.download()\n",
    "Model.downloadFromZoo(\"ResNet50.fbm\", \"./Models/\")\n",
    "\n",
    "myPrint('\\nPreparing ImageNet dataset ... ', False)\n",
    "trainDs,testDs = ImageNetDSet.makeDatasets('Train,Test', batchSize=256, preProcessing='Crop256Cafe', numWorkers=8)\n",
    "myPrint('Done.')\n",
    "ImageNetDSet.printDsInfo(trainDs, testDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a ResNet50 Fireball model and print the model information\n",
    "Let's load the model information from a pre-trained fireball model and print information about different layers of the model. For your information, the ResNet50's layer info text and blocks are as follows. Since we already have a trained fbm file for ResNet50, we don't need them here.\n",
    "\n",
    "```\n",
    "blocks = [ \n",
    "    Block('RES1|k_kernel_ixi,o_outSizes_i*3,s_stride_ixi_1|' +\n",
    "          'add|' +\n",
    "          'CONV_K1_S%s_O%o0_Pv,BN:ReLU,CONV_K%k_S1_O%o1_Ps,BN:ReLU,CONV_K1_S1_O%o2,BN;ID'),\n",
    "    Block('RES2|k_kernel_ixi,o_outSizes_i*3,s_stride_ixi_1|' +\n",
    "          'add|' +\n",
    "          'CONV_K1_S%s_O%o0_Pv,BN:ReLU,CONV_K%k_S1_O%o1_Ps,BN:ReLU,CONV_K1_S1_O%o2,BN;'+\n",
    "          'CONV_K1_S%s_O%o2_Pv,BN') ]\n",
    "\n",
    "layers = ('IMG_S224;CONV_K7_O64_S2_P3,BN:ReLu:MP_K3_S2_P1;'  +              # Stage 1\n",
    "          'RES2_K3_O64/64/256_S1:ReLU,2*RES1_K3_O64/64/256:ReLU;' +         # Stage 2\n",
    "          'RES2_K3_O128/128/512_S2:ReLU,3*RES1_K3_O128/128/512:ReLU;' +     # Stage 3\n",
    "          'RES2_K3_O256/256/1024_S2:ReLU,5*RES1_K3_O256/256/1024:ReLU;' +   # Stage 4\n",
    "          'RES2_K3_O512/512/2048_S2:ReLU:DO,' +\n",
    "          'RES1_K3_O512/512/2048:ReLU:DO,RES1_K3_O512/512/2048:ReLU:GAP;' + # Stage 5\n",
    "          'FC_O1000,CLASS_C1000')                                           # Stage 6\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading from \"Models/ResNet50.fbm\" ... Done.\n",
      "Creating the fireball model \"ResNet50\" ... Done.\n",
      "\n",
      "Scope            InShape       Comments                 OutShape      Activ.   Post Act.        # of Params\n",
      "---------------  ------------  -----------------------  ------------  -------  ---------------  -----------\n",
      "IN_IMG                         Image Size: 224x224x3    224 224 3     None                      0          \n",
      "S1_L1_CONV       224 224 3     KSP: 7 2 3               112 112 64    None                      9,472      \n",
      "S1_L2_BN         112 112 64                             56 56 64      ReLU     MP(KSP):3 2 1    256        \n",
      "S2_L1_RES2       56 56 64      2 Paths, 8 layers        56 56 256     ReLU                      76,928     \n",
      "S2_L2_RES1       56 56 256     2 Paths, 6 layers        56 56 256     ReLU                      71,552     \n",
      "S2_L3_RES1       56 56 256     2 Paths, 6 layers        56 56 256     ReLU                      71,552     \n",
      "S3_L1_RES2       56 56 256     2 Paths, 8 layers        28 28 512     ReLU                      383,232    \n",
      "S3_L2_RES1       28 28 512     2 Paths, 6 layers        28 28 512     ReLU                      282,368    \n",
      "S3_L3_RES1       28 28 512     2 Paths, 6 layers        28 28 512     ReLU                      282,368    \n",
      "S3_L4_RES1       28 28 512     2 Paths, 6 layers        28 28 512     ReLU                      282,368    \n",
      "S4_L1_RES2       28 28 512     2 Paths, 8 layers        14 14 1024    ReLU                      1,520,128  \n",
      "S4_L2_RES1       14 14 1024    2 Paths, 6 layers        14 14 1024    ReLU                      1,121,792  \n",
      "S4_L3_RES1       14 14 1024    2 Paths, 6 layers        14 14 1024    ReLU                      1,121,792  \n",
      "S4_L4_RES1       14 14 1024    2 Paths, 6 layers        14 14 1024    ReLU                      1,121,792  \n",
      "S4_L5_RES1       14 14 1024    2 Paths, 6 layers        14 14 1024    ReLU                      1,121,792  \n",
      "S4_L6_RES1       14 14 1024    2 Paths, 6 layers        14 14 1024    ReLU                      1,121,792  \n",
      "S5_L1_RES2       14 14 1024    2 Paths, 8 layers        7 7 2048      ReLU     DO               6,054,912  \n",
      "S5_L2_RES1       7 7 2048      2 Paths, 6 layers        7 7 2048      ReLU     DO               4,471,808  \n",
      "S5_L3_RES1       7 7 2048      2 Paths, 6 layers        1 1 2048      ReLU     Global Avg       4,471,808  \n",
      "S6_L1_FC         1 1 2048                               1000          None                      2,049,000  \n",
      "OUT_CLASS        1000          1000 classes             1000          None                      0          \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "                                                                  Total Number of parameters: 25,636,712 \n"
     ]
    }
   ],
   "source": [
    "model = Model.makeFromFile(\"Models/ResNet50.fbm\", testDs=testDs, gpus=gpus)\n",
    "model.printLayersInfo()\n",
    "model.initSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A quick inference demo\n",
    "Now let's show how this model can be used to classify an image. Here we are using a JPEG image of a coffee mug.\n",
    "The function ```getPreprocessedImage```, loads, scales, and preprocesses the image before returning it as numpy array of floating point numbers. We can pass the preprocessed image to the ```inferOne``` function to get the probabilities for each one of 1000 classes. We then print the top-3 classes with highest probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-3 Classes (For \"CoffeeMug.jpg\"):\n",
      "    coffee_mug (0.497880)\n",
      "    cup (0.264278)\n",
      "    pitcher (0.110466)\n"
     ]
    }
   ],
   "source": [
    "imageFileName = 'CoffeeMug.jpg'\n",
    "image = testDs.getPreprocessedImage(imageFileName)\n",
    "classProbs = model.inferOne(image, returnProbs=True)\n",
    "top3Indexes = np.argsort(classProbs)[-3:][::-1]   # Indexes of classes with 3 highest probs (decreasing order)\n",
    "top3Porbs = classProbs[top3Indexes]\n",
    "print('Top-3 Classes (For \"%s\"):'%(imageFileName))\n",
    "for i in range(3):\n",
    "    print('    %s (%f)'%(ImageNetDSet.classNames[top3Indexes[i]], top3Porbs[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model\n",
    "This code runs inference on all images in the ImageNet dataset and compares the results with the ground truth labels in the testDs. The accuracy of the model is then printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference on 50000 Test Samples (batchSize:256, 4 towers) ... \n",
      "  Processed 50000 Sample. (Time: 59.68 Sec.)                              \n",
      "\n",
      "Observed Accuracy: 0.747360\n",
      "Top-5 Accuracy:   0.919360\n"
     ]
    }
   ],
   "source": [
    "myPrint('Running inference on %d Test Samples (batchSize:%d, %d towers) ... '%(testDs.numSamples,\n",
    "                                                                               testDs.batchSize,\n",
    "                                                                               len(model.towers)))\n",
    "results = model.evaluate(topK=5)    # Calculate and print top-5 accuracy as well as the default top-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where do I go from here?\n",
    "\n",
    "[Reducing number of parameters of ResNet50 Model](ResNet50-Reduce.ipynb)\n",
    "\n",
    "[Pruning ResNet50 Model](ResNet50-Prune.ipynb)\n",
    "\n",
    "[Quantizing ResNet50 Model](ResNet50-Quantize.ipynb)\n",
    "\n",
    "[Exporting ResNet50 Model to ONNX](ResNet50-ONNX.ipynb)\n",
    "\n",
    "[Exporting ResNet50 Model to CoreML](ResNet50-CoreML.ipynb)\n",
    "\n",
    "[Exporting ResNet50 Model to TensorFlow](ResNet50-TF.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "[Fireball Playgrounds](../Contents.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
