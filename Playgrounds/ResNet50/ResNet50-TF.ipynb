{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting a ResNet50 model to TensorFlow\n",
    "You can use the Fireball's ```exportToTf``` function to export a model to TensorFlow code. This function creates a\n",
    "python file that implements the model using TensorFlow APIs. It also creates a numpy file (npz) that contains the parameters of the network. This notebook shows how to use this function to export a Fireball model to TensorFlow. It is assumed that a trained ResNet50 model already exists in the ```Models``` directory. Please refer to the notebook [Image Classification with ResNet50](ResNet50.ipynb) for more info about using a pretrained ResNet50 model.\n",
    "\n",
    "Fireball can also export models with reduced number of parameters, pruned models, and quatized models. Please refer to the following notebooks for more information:\n",
    "\n",
    "- [Reducing number of parameters of ResNet50 Model](ResNet50-Reduce.ipynb)\n",
    "- [Pruning ResNet50 Model](ResNet50-Prune.ipynb)\n",
    "- [Quantizing ResNet50 Model](ResNet50-Quantize.ipynb)\n",
    "\n",
    "\n",
    "## Load a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading from \"Models/ResNet50RRPRQR.fbm\" ... Done.\n",
      "Creating the fireball model \"ResNet50\" ... Done.\n",
      "\n",
      "Scope            InShape       Comments                 OutShape      Activ.   Post Act.        # of Params\n",
      "---------------  ------------  -----------------------  ------------  -------  ---------------  -----------\n",
      "IN_IMG                         Image Size: 224x224x3    224 224 3     None                      0          \n",
      "S1_L1_CONV       224 224 3     KSP: 7 2 3               112 112 64    None                      7,120      \n",
      "S1_L2_BN         112 112 64                             56 56 64      ReLU     MP(KSP):3 2 1    256        \n",
      "S2_L1_RES2       56 56 64      2 Paths, 8 layers        56 56 256     ReLU                      48,614     \n",
      "S2_L2_RES1       56 56 256     2 Paths, 6 layers        56 56 256     ReLU                      48,346     \n",
      "S2_L3_RES1       56 56 256     2 Paths, 6 layers        56 56 256     ReLU                      48,873     \n",
      "S3_L1_RES2c1     56 56 256     2 Paths, 8 layers        28 28 512     ReLU                      177,500    \n",
      "S3_L2_RES1c2     28 28 512     2 Paths, 6 layers        28 28 512     ReLU                      137,989    \n",
      "S3_L3_RES1c3     28 28 512     2 Paths, 6 layers        28 28 512     ReLU                      82,706     \n",
      "S3_L4_RES1c4     28 28 512     2 Paths, 6 layers        28 28 512     ReLU                      151,147    \n",
      "S4_L1_RES2c5     28 28 512     2 Paths, 8 layers        14 14 1024    ReLU                      472,082    \n",
      "S4_L2_RES1c6     14 14 1024    2 Paths, 6 layers        14 14 1024    ReLU                      310,354    \n",
      "S4_L3_RES1c7     14 14 1024    2 Paths, 6 layers        14 14 1024    ReLU                      389,784    \n",
      "S4_L4_RES1c8     14 14 1024    2 Paths, 6 layers        14 14 1024    ReLU                      376,839    \n",
      "S4_L5_RES1c9     14 14 1024    2 Paths, 6 layers        14 14 1024    ReLU                      399,527    \n",
      "S4_L6_RES1c10    14 14 1024    2 Paths, 6 layers        14 14 1024    ReLU                      407,968    \n",
      "S5_L1_RES2c11    14 14 1024    2 Paths, 8 layers        7 7 2048      ReLU     DO               1,635,749  \n",
      "S5_L2_RES1c12    7 7 2048      2 Paths, 6 layers        7 7 2048      ReLU     DO               1,109,162  \n",
      "S5_L3_RES1c13    7 7 2048      2 Paths, 6 layers        1 1 2048      ReLU     Global Avg       1,188,549  \n",
      "S6_L1_FC         1 1 2048      LR400                    1000          None                      913,769    \n",
      "OUT_CLASS        1000          1000 classes             1000          None                      0          \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "                                                                  Total Number of parameters: 7,906,334  \n",
      "  Processed 50000 Sample. (Time: 64.56 Sec.)                              \n",
      "\n",
      "Observed Accuracy: 0.683440\n"
     ]
    }
   ],
   "source": [
    "from fireball import Model\n",
    "from fireball.datasets.imagenet import ImageNetDSet\n",
    "gpus=\"0,1,2,3\"\n",
    "\n",
    "testDs = ImageNetDSet.makeDatasets('Test', batchSize=256, preProcessing='Crop256Cafe', numWorkers=8)\n",
    "\n",
    "\n",
    "# orgFileName = \"Models/ResNet50.fbm\"        # Original model\n",
    "# orgFileName = \"Models/ResNet50QR.fbm\"      # Quantized - Retrained\n",
    "# orgFileName = \"Models/ResNet50PR.fbm\"      # Pruned - Retrained\n",
    "# orgFileName = \"Models/ResNet50PRQR.fbm\"    # Pruned - Retrained - Quantized - Retrained\n",
    "# orgFileName = \"Models/ResNet50RR.fbm\"      # Reduced - Retrained\n",
    "# orgFileName = \"Models/ResNet50RRQR.fbm\"    # Reduced - Retrained - Quantized - Retrained\n",
    "# orgFileName = \"Models/ResNet50RRPR.fbm\"    # Reduced - Retrained - Pruned - Retrained\n",
    "orgFileName = \"Models/ResNet50RRPRQR.fbm\"  # Reduced - Retrained - Pruned - Retrained - Quantized - Retrained\n",
    "\n",
    "\n",
    "model = Model.makeFromFile(orgFileName, testDs=testDs, gpus=gpus)\n",
    "model.initSession()\n",
    "model.printLayersInfo()\n",
    "results = model.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the model\n",
    "Fireball creates a folder and puts 2 files in the folder. Here we call the ```exportToTf``` funtion to export the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exporting to TensorFlow model \"Models/ResNet50_TF\" ... \n",
      "    Processed all 21 layers.                                      \n",
      "    Creating parameters file \"Params.npz\" ... Done.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "model.exportToTf(\"Models/ResNet50_TF\", runQuantized=True, classNames=ImageNetDSet.classNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running inference on the exported model\n",
    "To verify the exported model, we can now run inference on it. Here we load an image and do the required pre-processing before passing it to the exported model as input. We then print the top-3 most probable predicted labels for the image.\n",
    "\n",
    "**NOTE**: Please reset the kernel before running the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-3 Classes (For \"CoffeeMug.jpg\"):\n",
      "    coffee_mug (0.773873)\n",
      "    cup (0.129940)\n",
      "    pitcher (0.048318)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "imageFileName = 'CoffeeMug.jpg'\n",
    "\n",
    "img = cv2.imread(imageFileName)     # Reads image in BGR order\n",
    "\n",
    "# Resize the image to 256x256\n",
    "imgSize = img.shape[:2]\n",
    "ratio = 256.0/min(imgSize)\n",
    "newSize = (int(np.round(imgSize[1]*ratio)), int(np.round(imgSize[0]*ratio)))\n",
    "\n",
    "# Note: INTER_AREA is best when shrinking and CV_INTER_CUBIC is best when enlarging\n",
    "img = cv2.resize(img, newSize,  interpolation = (cv2.INTER_AREA if ratio<1.0 else cv2.INTER_CUBIC))\n",
    "\n",
    "# Now crop the center 224x224 image\n",
    "dw = newSize[0] - 224\n",
    "dh = newSize[1] - 224\n",
    "resizedImg = img[dh//2:dh//2+224, dw//2:dw//2+224,:]\n",
    "\n",
    "# Normalize the image using the mean values for blue, green, and red\n",
    "inputImage = (np.float32(resizedImg) - [103.939, 116.779, 123.68])\n",
    "\n",
    "# Choose the module corresponding to the model selected in the first cell of this notebook.\n",
    "# from Models.ResNet50_TF.TfModel import Network\n",
    "# from Models.ResNet50RR_TF.TfModel import Network\n",
    "from Models.ResNet50_TF.TfModel import Network\n",
    "\n",
    "net=Network()\n",
    "classNames = net.getClassNames()\n",
    "\n",
    "classProbs = net.infer([inputImage])[0]\n",
    "top3Indexes = np.argsort(classProbs)[-3:][::-1]\n",
    "top3Porbs = classProbs[top3Indexes]\n",
    "print('Top-3 Classes (For \"%s\"):'%(imageFileName))\n",
    "for i in range(3):\n",
    "    print('    %s (%f)'%(classNames[top3Indexes[i]], top3Porbs[i])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where do I go from here?\n",
    "\n",
    "[Exporting ResNet50 Model to CoreML](ResNet50-CoreML.ipynb)\n",
    "\n",
    "[Exporting ResNet50 Model to ONNX](ResNet50-ONNX.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "[Fireball Playgrounds](../Contents.ipynb)\n",
    "\n",
    "[Image Classification with ResNet50](ResNet50.ipynb)\n",
    "\n",
    "[Reducing number of parameters of ResNet50 Model](ResNet50-Reduce.ipynb)\n",
    "\n",
    "[Pruning ResNet50 Model](ResNet50-Prune.ipynb)\n",
    "\n",
    "[Quantizing ResNet50 Model](ResNet50-Quantize.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
