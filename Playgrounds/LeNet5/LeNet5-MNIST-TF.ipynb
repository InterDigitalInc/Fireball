{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting to TensorFlow\n",
    "You can use the Fireball's ```exportToTf``` function to export a model to TensorFlow code. This function creates a\n",
    "python file that implements the model using TensorFlow APIs. It also creates a numpy file (npz) that contains the parameters of the network. This notebook shows how to use this function to export a Fireball model to TensorFlow. It assumes that a trained LeNet-5 model already exists in the ```Models``` directory. You can use the notebook [Handwritten Digit recognition (LeNet-5/MNIST)](LeNet5-MNIST.ipynb) to create and train a LeNet-5 model.\n",
    "\n",
    "Fireball can also export models with reduced number of parameters, pruned models, and quatized models. Please refer to the following notebooks for more information:\n",
    "\n",
    "- [Reducing number of parameters of LeNet-5 Model](LeNet5-MNIST-Reduce.ipynb)\n",
    "- [Pruning LeNet-5 Model](LeNet5-MNIST-Prune.ipynb)\n",
    "- [Quantizing LeNet-5 Model](LeNet5-MNIST-Quantize.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading from \"Models/LeNet5RRPR.fbm\" ... Done.\n",
      "Creating the fireball model \"LeNet-5\" ... Done.\n",
      "Metal device set to: Apple M1 Max\n",
      "\n",
      "Scope            InShape       Comments                 OutShape      Activ.   Post Act.        # of Params\n",
      "---------------  ------------  -----------------------  ------------  -------  ---------------  -----------\n",
      "IN_IMG                         Image Size: 28x28x1      28 28 1       None                      0          \n",
      "L1_CONV          28 28 1       KSP: 5 1 s               14 14 6       ReLU     MP(KSP):2 2 v    111        \n",
      "L2_CONV          14 14 6       KSP: 5 1 v, LR8          5 5 16        ReLU     MP(KSP):2 2 v    844        \n",
      "L3_FC            5 5 16        LR8                      120           ReLU                      2,441      \n",
      "L4_FC            120           LR8                      84            ReLU                      987        \n",
      "L5_FC            84                                     10            None                      539        \n",
      "OUT_CLASS        10            10 classes               10            None                      0          \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "                                                                  Total Number of parameters: 4,922      \n",
      "  Processed 10000 Sample. (Time: 1.56 Sec.)                              \n",
      "\n",
      "Observed Accuracy: 0.990100\n",
      "Expected Accuracy: 0.100361\n",
      "Kappa: 0.988996 (Excellent)\n"
     ]
    }
   ],
   "source": [
    "from fireball import Model\n",
    "from fireball.datasets.mnist import MnistDSet\n",
    "\n",
    "testDs = MnistDSet.makeDatasets('test', batchSize=128)\n",
    "\n",
    "# orgFileName = \"Models/LeNet5.fbm\"        # Original model\n",
    "# orgFileName = \"Models/LeNet5QR.fbm\"      # Quantized - Retrained\n",
    "# orgFileName = \"Models/LeNet5PR.fbm\"      # Pruned - Retrained\n",
    "# orgFileName = \"Models/LeNet5PRQR.fbm\"    # Pruned - Retrained - Quantized - Retrained\n",
    "# orgFileName = \"Models/LeNet5RR.fbm\"      # Reduced - Retrained\n",
    "# orgFileName = \"Models/LeNet5RRQR.fbm\"    # Reduced - Retrained - Quantized - Retrained\n",
    "orgFileName = \"Models/LeNet5RRPR.fbm\"    # Reduced - Retrained - Pruned - Retrained\n",
    "# orgFileName = \"Models/LeNet5RRPRQR.fbm\"  # Reduced - Retrained - Pruned - Retrained - Quantized - Retrained\n",
    "\n",
    "model = Model.makeFromFile(orgFileName, testDs=testDs, gpus='0')   \n",
    "model.initSession()\n",
    "model.printLayersInfo()\n",
    "\n",
    "results = model.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the model\n",
    "Fireball creates a folder and puts 2 files in the folder. Here we call the ```exportToTf``` funtion to export the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exporting to TensorFlow model \"Models/LeNet5TF\" ... \n",
      "    Processed all 7 layers.                                     \n",
      "    Creating parameters file \"Params.npz\" ... Done.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.exportToTf(\"Models/LeNet5TF\", runQuantized=True, classNames=[str(i) for i in range(10)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the exported model in the folder ``Models/LeNet5TF``. Inside this folder there is a python file \"TfModel.py\" that was created by Fireball. Open this file and review the code generated by Fireball. This file defines a class called Network which implements the exported Fireball model.\n",
    "\n",
    "## Evaluating the exported model\n",
    "We can now evaluate the exported model. Before running the next cell, reset the kernel to make sure there is no dependency to the Fireball library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 15:13:23.447079: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-05-12 15:13:23.447211: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-05-12 15:13:23.449599: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-05-12 15:13:23.449662: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-12 15:13:23.485543: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "\n",
    "def getDataset(imagesFileName, labelsFileName):\n",
    "    file = open(imagesFileName, mode='rb')\n",
    "    header = file.read(16)\n",
    "    magic, numImages, imageWidth, imageHeight = struct.unpack(\">iiii\", header)\n",
    "    assert magic == 2051, \"Error: Invalid MNIST Image format!\"\n",
    "\n",
    "    buf = file.read(imageWidth * imageHeight * numImages)\n",
    "    data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "    data = (data-127.5)/255.0   # Normalize to [-1..1]\n",
    "    samples = data.reshape(numImages, imageWidth, imageHeight, 1)\n",
    "\n",
    "    file = open(labelsFileName, mode='rb')\n",
    "    header = file.read(8)\n",
    "    magic, numLabels = struct.unpack(\">ii\", header)\n",
    "    assert magic == 2049, \"Error: Invalid MNIST Label format!\"\n",
    "\n",
    "    buf = file.read(numLabels)\n",
    "    labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "    return samples, labels\n",
    "\n",
    "# Update the file names to point to the location of MNIST dataset\n",
    "testSamples, testLabels = getDataset('/Users/shahab/data/mnist/t10k-images.idx3-ubyte',\n",
    "                                     '/Users/shahab/data/mnist/t10k-labels.idx1-ubyte')\n",
    "\n",
    "# Now we import the Network class that was generated by Fireball in the \"TfModel.py\" file\n",
    "from Models.LeNet5TF.TfModel import Network\n",
    "net=Network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell shows how to run inference. We get a random test sample and call the infer function to get the probabilities of different classes in an array. The ```argmax``` function gives us the actual label. You can run it several time to test it with different samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual label of the sample no 9605 in the dataset: 4\n",
      "Predicted label: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 15:13:23.499873: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "i = np.random.randint(len(testLabels))\n",
    "print( \"Actual label of the sample no %d in the dataset: %d\"%(i, testLabels[i]))\n",
    "classProbs = net.infer(testSamples[i:i+1])\n",
    "print( \"Predicted label: %d\"%(np.argmax(classProbs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the evaluation over all test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.990100\n"
     ]
    }
   ],
   "source": [
    "classProbs = net.infer(testSamples)\n",
    "accuracy = float(np.sum(testLabels == np.argmax(classProbs,1)))/len(testLabels)\n",
    "print( \"Test Accuracy: %f\"%(accuracy) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the exported model in TensorFlow\n",
    "The exported model also includes everything that is needed for training a model. You just need to create your own optimizer (using TensorFlow) and pass it to the ```trainBatch``` function of the ```Network``` class. The following cell shows an example of how to train an exported model.\n",
    "\n",
    "Please note that when the ```Network``` class is instantiated for training, the exported parameter values are not used. The parameters of the network are initialized randomly.\n",
    "\n",
    "**IMPORTANT:** Do not use a quantized model for training. Quantization must happen after training. So, please scroll up and make sure the quantized model file (Models/LeNet5RRQR.fbm) is not selected in the first cell of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 15:13:30.177491: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-05-12 15:13:30.177511: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-05-12 15:13:30.180340: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-12 15:13:30.270565: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-12 15:13:33.178854: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-05-12 15:13:33.188049: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 -> Learning Rate: 0.054209, Test Accuracy: 0.966300\n",
      "Epoch 2 -> Learning Rate: 0.028210, Test Accuracy: 0.976100\n",
      "Epoch 3 -> Learning Rate: 0.015292, Test Accuracy: 0.977300\n",
      "Epoch 4 -> Learning Rate: 0.007958, Test Accuracy: 0.979500\n",
      "Epoch 5 -> Learning Rate: 0.004141, Test Accuracy: 0.980600\n",
      "Epoch 6 -> Learning Rate: 0.002245, Test Accuracy: 0.980400\n",
      "Epoch 7 -> Learning Rate: 0.001168, Test Accuracy: 0.980500\n",
      "Epoch 8 -> Learning Rate: 0.000633, Test Accuracy: 0.980400\n",
      "Epoch 9 -> Learning Rate: 0.000330, Test Accuracy: 0.980600\n",
      "Epoch 10 -> Learning Rate: 0.000172, Test Accuracy: 0.980600\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# NOTE: Make sure to update this with the same file used above in the first cell\n",
    "orgFileName = \"Models/LeNet5RRPR.fbm\"    # Reduced - Retrained - Pruned - Retrained\n",
    "\n",
    "# This works for Non-Quantized models only!\n",
    "assert ('QR.fbm' not in orgFileName) and ('Q.fbm' not in orgFileName), \"No Training for Quanized Models!\"\n",
    "\n",
    "# first create the training dataset:\n",
    "trainSamples, trainLabels = getDataset('/Users/shahab/data/mnist/train-images.idx3-ubyte',\n",
    "                                       '/Users/shahab/data/mnist/train-labels.idx1-ubyte')\n",
    "\n",
    "# Create an instance of the Network for training:\n",
    "net = Network(train=True)\n",
    "\n",
    "# Create a learning rate and a gradient descent optimizer:\n",
    "startLearningRate = 0.1\n",
    "learningRate = tf.compat.v1.train.exponential_decay(startLearningRate,\n",
    "                                                    net.globalStep,  # Use the \"globalStep\" from the exported model\n",
    "                                                    30,\n",
    "                                                    0.96,\n",
    "                                                    staircase=True)\n",
    "optimizer = tf.compat.v1.train.GradientDescentOptimizer(learningRate)\n",
    "optimize = optimizer.minimize(net.loss, global_step=net.globalStep)\n",
    "\n",
    "# Train for 10 epochs:\n",
    "sampleIndexes = np.arange(len(trainLabels))\n",
    "numEpochs = 10\n",
    "batchSize = 128\n",
    "\n",
    "for e in range(numEpochs):\n",
    "    np.random.shuffle(sampleIndexes)\n",
    "    numBatches = len(trainLabels)//batchSize\n",
    "    for b in range(numBatches):\n",
    "        batchSamples = trainSamples[sampleIndexes[b*batchSize:(b+1)*batchSize]]\n",
    "        batchLabels = trainLabels[sampleIndexes[b*batchSize:(b+1)*batchSize]]\n",
    "        \n",
    "        net.trainBatch(optimize, batchSamples, batchLabels)\n",
    "    \n",
    "    lr = net.session.run(learningRate)\n",
    "    classProbs = net.infer(testSamples)\n",
    "    accuracy = float(np.sum(testLabels == np.argmax(classProbs,1)))/len(testLabels)\n",
    "    print(\"Epoch %d -> Learning Rate: %f, Test Accuracy: %f\"%(e+1, lr, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where do I go from here?\n",
    "\n",
    "[Exporting LeNet-5 Model to ONNX](LeNet5-MNIST-ONNX.ipynb)\n",
    "\n",
    "[Exporting LeNet-5 Model to CoreML](LeNet5-MNIST-CoreML.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "[Fireball Playgrounds](../Contents.ipynb)\n",
    "\n",
    "[Handwritten Digit Recognition (LeNet-5/MNIST)](LeNet5-MNIST.ipynb)\n",
    "\n",
    "[Reducing number of parameters of LeNet-5 Model](LeNet5-MNIST-Reduce.ipynb)\n",
    "\n",
    "[Pruning LeNet-5 Model](LeNet5-MNIST-Prune.ipynb)\n",
    "\n",
    "[Quantizing LeNet-5 Model](LeNet5-MNIST-Quantize.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
