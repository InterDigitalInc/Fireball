{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting to CoreML\n",
    "To use a Fireball model in an iOS application, we can use [exportToCoreMl](https://interdigitalinc.github.io/Fireball/html/source/model.html#fireball.model.Model.exportToCoreMl) method. This notebook shows how to use this function to create a CoreML model ready to be deployed in an iOS app. It assumes that a trained LeNet-5 model already exists in the ```Models``` directory. You can use the notebook [Handwritten Digit recognition (LeNet-5/MNIST)](LeNet5-MNIST.ipynb) to create and train a LeNet-5 model.\n",
    "\n",
    "Fireball can also export models with reduced number of parameters, pruned models, and quatized models. Please refer to the following notebooks for more information:\n",
    "\n",
    "- [Reducing number of parameters of LeNet-5 Model](LeNet5-MNIST-Reduce.ipynb)\n",
    "- [Pruning LeNet-5 Model](LeNet5-MNIST-Prune.ipynb)\n",
    "- [Quantizing LeNet-5 Model](LeNet5-MNIST-Quantize.ipynb)\n",
    "\n",
    "Note: Fireball uses the [coremltools](https://github.com/apple/coremltools) python package to export CoreML models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading from \"Models/LeNet5RRPRQR.fbm\" ... Done.\n",
      "Creating the fireball model \"LeNet-5\" ... Done.\n",
      "Metal device set to: Apple M1 Max\n",
      "\n",
      "Scope            InShape       Comments                 OutShape      Activ.   Post Act.        # of Params\n",
      "---------------  ------------  -----------------------  ------------  -------  ---------------  -----------\n",
      "IN_IMG                         Image Size: 28x28x1      28 28 1       None                      0          \n",
      "L1_CONV          28 28 1       KSP: 5 1 s               14 14 6       ReLU     MP(KSP):2 2 v    111        \n",
      "L2_CONV          14 14 6       KSP: 5 1 v, LR8          5 5 16        ReLU     MP(KSP):2 2 v    844        \n",
      "L3_FC            5 5 16        LR8                      120           ReLU                      2,441      \n",
      "L4_FC            120           LR8                      84            ReLU                      987        \n",
      "L5_FC            84                                     10            None                      539        \n",
      "OUT_CLASS        10            10 classes               10            None                      0          \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "                                                                  Total Number of parameters: 4,922      \n",
      "  Processed 10000 Sample. (Time: 0.63 Sec.)                              \n",
      "\n",
      "Observed Accuracy: 0.989100\n",
      "Expected Accuracy: 0.100368\n",
      "Kappa: 0.987884 (Excellent)\n"
     ]
    }
   ],
   "source": [
    "from fireball import Model\n",
    "from fireball.datasets.mnist import MnistDSet\n",
    "\n",
    "testDs = MnistDSet.makeDatasets('test', batchSize=128)\n",
    "\n",
    "# orgFileName = \"Models/LeNet5.fbm\"        # Original model\n",
    "# orgFileName = \"Models/LeNet5QR.fbm\"      # Quantized - Retrained\n",
    "# orgFileName = \"Models/LeNet5PR.fbm\"      # Pruned - Retrained\n",
    "# orgFileName = \"Models/LeNet5PRQR.fbm\"    # Pruned - Retrained - Quantized - Retrained\n",
    "# orgFileName = \"Models/LeNet5RR.fbm\"      # Reduced - Retrained\n",
    "# orgFileName = \"Models/LeNet5RRQR.fbm\"    # Reduced - Retrained - Quantized - Retrained\n",
    "# orgFileName = \"Models/LeNet5RRPR.fbm\"    # Reduced - Retrained - Pruned - Retrained\n",
    "orgFileName = \"Models/LeNet5RRPRQR.fbm\"  # Reduced - Retrained - Pruned - Retrained - Quantized - Retrained\n",
    "\n",
    "model = Model.makeFromFile(orgFileName, testDs=testDs, gpus='0')   \n",
    "model.initSession()\n",
    "model.printLayersInfo()\n",
    "\n",
    "results = model.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "CoreML handles the pre-processing of the images inside the model. The arguments ```rgbBias``` and ```scale``` are used to tell CoreML how to do this pre-processing. The pre-processed image is calculated by CoreML as:\n",
    "```\n",
    "processedImage = image * scale + rgbBias\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:TensorFlow version 2.8.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.6.2 is the most recent version that has been tested.\n",
      "WARNING:root:Keras version 2.8.0 has not been tested with coremltools. You may run into unexpected errors. Keras 2.6.0 is the most recent version that has been tested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exporting to CoreML model \"Models/LeNet5RRPRQR.mlmodel\" ... \n",
      "    Exported all 7 layers.                               \n",
      "    Saving to \"Models/LeNet5RRPRQR.mlmodel\" ... Done.\n",
      "Done (0.12 Sec.)\n",
      "\n",
      "Original Model File Size: 9,071 bytes\n",
      "CoreML Model File Size: 7,484 bytes (82.50% of original)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "cmlFile = orgFileName.replace('.fbm', '.mlmodel')\n",
    "\n",
    "model.exportToCoreMl(cmlFile,\n",
    "                     classNames=[str(i) for i in range(10)],  # List of labels (strings)\n",
    "                     rgbBias=-.5,\n",
    "                     scale=1.0/255)\n",
    "\n",
    "orgFileSize = os.stat(orgFileName).st_size\n",
    "print('\\nOriginal Model File Size: {:,} bytes'.format(orgFileSize))\n",
    "fileSize = os.stat(cmlFile).st_size\n",
    "print('CoreML Model File Size: {:,} bytes ({:2.2%} of original)'.format(fileSize, fileSize/orgFileSize))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using netron to visualize the exported model\n",
    "We can now visualize the model's network structure using the [netron](https://github.com/lutzroeder/netron) package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'Models/LeNet5RRPRQR.mlmodel' at http://localhost:8081\n"
     ]
    }
   ],
   "source": [
    "import netron\n",
    "import platform\n",
    "\n",
    "if platform.system() == 'Darwin':      # Running on MAC\n",
    "    netron.start(cmlFile)   \n",
    "else:\n",
    "    import socket\n",
    "    hostIp = socket.gethostbyname(socket.gethostname())\n",
    "    netron.start(cmlFile, address=(hostIp,8084))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the CoreML model (Runs only on Mac)\n",
    "We can now evaluate the CoreML model. This also shows how to use a CoreML model for inference. Currently the CoreML runtime is only available on Mac. You also need the [pillow package](https://pypi.org/project/Pillow/) because CoreML only accepts images in this format. \n",
    "\n",
    "We could use fireball's implementation of MNIST dataset. But here we want to run and test the CoreML model without any dependency to Fireball libraty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.989100\n"
     ]
    }
   ],
   "source": [
    "assert platform.system() == 'Darwin'\n",
    "\n",
    "# Load MNIST Test Dataset:\n",
    "import numpy as np\n",
    "import struct\n",
    "\n",
    "def getDataset(imagesFileName, labelsFileName):\n",
    "    file = open(imagesFileName, mode='rb')\n",
    "    header = file.read(16)\n",
    "    magic, numImages, imageWidth, imageHeight = struct.unpack(\">iiii\", header)\n",
    "    assert magic == 2051, \"Error: Invalid MNIST Image format!\"\n",
    "\n",
    "    buf = file.read(imageWidth * imageHeight * numImages)\n",
    "    data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "    # The followint normalization is not needed. It is done in CoreML (Preprocessing)    \n",
    "    # data = (data-127.5)/255.0   # Normalize to [-1..1]\n",
    "    samples = data.reshape(numImages, imageWidth, imageHeight, 1)\n",
    "\n",
    "    file = open(labelsFileName, mode='rb')\n",
    "    header = file.read(8)\n",
    "    magic, numLabels = struct.unpack(\">ii\", header)\n",
    "    assert magic == 2049, \"Error: Invalid MNIST Label format!\"\n",
    "\n",
    "    buf = file.read(numLabels)\n",
    "    labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "    return samples, labels\n",
    "\n",
    "# Update the file names to point to the location of MNIST dataset\n",
    "testSamples, testLabels = getDataset('/Users/shahab/data/mnist/t10k-images.idx3-ubyte',\n",
    "                                     '/Users/shahab/data/mnist/t10k-labels.idx1-ubyte')\n",
    "\n",
    "testSamples = testSamples.reshape(-1,1,28,28)  # CoreML uses Channel-First format\n",
    "\n",
    "# Inference using the CoreML model\n",
    "import PIL\n",
    "import coremltools\n",
    "\n",
    "coreMlModel = coremltools.models.MLModel(cmlFile)\n",
    "\n",
    "predictions = []\n",
    "for sample in testSamples:\n",
    "    img = PIL.Image.fromarray(np.uint8(sample.reshape(28,28)),'L')\n",
    "    results = coreMlModel.predict({'InputImage': img})\n",
    "\n",
    "    predictions += [ int(results[\"PredictedLabel\"]) ]\n",
    "    \n",
    "accuracy = float(np.sum(testLabels == predictions))/len(testLabels)\n",
    "print( \"Test Accuracy: %f\"%(accuracy) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where do I go from here?\n",
    "\n",
    "[Exporting LeNet-5 Model to ONNX](LeNet5-MNIST-ONNX.ipynb)\n",
    "\n",
    "[Exporting LeNet-5 Model to TensorFlow](LeNet5-MNIST-TF.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "[Fireball Playgrounds](../Contents.ipynb)\n",
    "\n",
    "[Handwritten Digit Recognition (LeNet-5/MNIST)](LeNet5-MNIST.ipynb)\n",
    "\n",
    "[Reducing number of parameters of LeNet-5 Model](LeNet5-MNIST-Reduce.ipynb)\n",
    "\n",
    "[Pruning LeNet-5 Model](LeNet5-MNIST-Prune.ipynb)\n",
    "\n",
    "[Quantizing LeNet-5 Model](LeNet5-MNIST-Quantize.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
