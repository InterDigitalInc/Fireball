{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantizing LeNet-5 model\n",
    "This notebook shows how to quantize a pre-trained Fireball model using Codebook Quantization. It assumes \n",
    "that a trained LeNet-5 model already exists in the ```Models``` directory. You can use the notebook\n",
    "[Handwritten Digit recognition (LeNet-5/MNIST)](LeNet5-MNIST.ipynb) to create and train a LeNet-5 model.\n",
    "\n",
    "If you want to quantize a Low-Rank model, you can use [this](LeNet5-MNIST-Reduce.ipynb) notebook\n",
    "to reduce the number of parameters in LeNet-5.\n",
    "\n",
    "Model quantization reduces the size of the model by using less number of bits for each floating \n",
    "point parameter. Fireball uses a codebook quantization method based on K-Means clustering algorithm.\n",
    "\n",
    "```quantizeModel``` is a class method that receives the file names of input and output to the \n",
    "quantization process. It also receives the quantization parameters such as ```minBits```, ```maxBits```, \n",
    "```mse```, and ```pdfFactor```.\n",
    "\n",
    "Fireball can create models with 2-bit to 12-bit quantization (Codebook sizes 4 to 4096). For the quantized\n",
    "model to be compatible with ```CoreML```, we need to make sure the codebook size is a power of 2, less than or equal to 256, and only \"weight\" parameters are quantized (not biases)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantizing a pretrained model\n",
    "The code in the following cell quantizes the model specified by ```orgFileName``` and creates a\n",
    "new quantized model.\n",
    "\n",
    "For each parameter tensor of the model, we try quantization bits 2 to 8 and find the best quantization\n",
    "that satisfies the specified MSE value.\n",
    "\n",
    "To get better quantization (smaller model) increase ```mse```; to get better performance (larger model)\n",
    "use a smaller ```mse```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading model parameters from \"Models/LeNet5RRPR.fbm\" ... Done.\n",
      "Quantizing 13 tensors ... \n",
      "   Quantization Parameters:\n",
      "        mseUb .............. 0.001\n",
      "        pdfFactor .......... 0.1\n",
      "        reuseEmptyClusters . True\n",
      "        weightsOnly ........ True\n",
      "        minBits ............ 2\n",
      "        maxBits ............ 8\n",
      "    Tensor 1 of 13 Shape: 5x5x1x6 ........... Quantized. (16 clusters - MSE: 0.0006)\n",
      "    Tensor 2 of 13 Shape: 6 ................. Ignored. (1-D Tensor)\n",
      "    Tensor 3 of 13 Shape: 5x5x6x8 ........... Quantized. (16 clusters - MSE: 0.0004)\n",
      "    Tensor 4 of 13 Shape: 1x1x8x16 .......... Quantized. (32 clusters - MSE: 0.0003)\n",
      "    Tensor 5 of 13 Shape: 16 ................ Ignored. (1-D Tensor)\n",
      "    Tensor 6 of 13 Shape: 400x8 ............. Quantized. (16 clusters - MSE: 0.0010)\n",
      "    Tensor 7 of 13 Shape: 8x120 ............. Quantized. (32 clusters - MSE: 0.0002)\n",
      "    Tensor 8 of 13 Shape: 120 ............... Ignored. (1-D Tensor)\n",
      "    Tensor 9 of 13 Shape: 120x8 ............. Quantized. (16 clusters - MSE: 0.0005)\n",
      "    Tensor 10 of 13 Shape: 8x84 ............. Quantized. (16 clusters - MSE: 0.0006)\n",
      "    Tensor 11 of 13 Shape: 84 ............... Ignored. (1-D Tensor)\n",
      "    Tensor 12 of 13 Shape: 84x10 ............ Quantized. (32 clusters - MSE: 0.0007)\n",
      "    Tensor 13 of 13 Shape: 10 ............... Ignored. (1-D Tensor)\n",
      "Quantization complete (0.05 Sec.)\n",
      "Now saving to \"Models/LeNet5RRPRQ.fbm\" ... Done.\n",
      "\n",
      "Size of Data: 20,779 -> 7,425 bytes\n",
      "Model File Size: 22,205 -> 9,067 bytes\n"
     ]
    }
   ],
   "source": [
    "from fireball import Model\n",
    "\n",
    "# orgFileName = \"Models/LeNet5.fbm\"        # Original model\n",
    "# orgFileName = \"Models/LeNet5P.fbm\"       # Pruned\n",
    "# orgFileName = \"Models/LeNet5PR.fbm\"      # Pruned - Retrained\n",
    "# orgFileName = \"Models/LeNet5R.fbm\"       # Reduced\n",
    "# orgFileName = \"Models/LeNet5RP.fbm\"      # Reduced - Pruned\n",
    "# orgFileName = \"Models/LeNet5RP.fbm\"      # Reduced - Pruned - Retrained\n",
    "# orgFileName = \"Models/LeNet5RR.fbm\"      # Reduced - Retrained\n",
    "# orgFileName = \"Models/LeNet5RRP.fbm\"     # Reduced - Retrained - Pruned\n",
    "orgFileName = \"Models/LeNet5RRPR.fbm\"    # Reduced - Retrained - Pruned - Retrained\n",
    "\n",
    "quantizedFileName = orgFileName.replace('.fbm', 'Q.fbm')  # Append 'Q' to the filename for \"Quantized\"\n",
    "\n",
    "# quantizing the model\n",
    "qResults = Model.quantizeModel(orgFileName, quantizedFileName, \n",
    "                               mseUb=.001, minBits=2, maxBits=8, reuseEmptyClusters=True, weightsOnly=True,\n",
    "                               quiet=False, verbose=True, numWorkers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the data and file sizes before and after quantization.\n",
    "## Evaluate the quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading from \"Models/LeNet5RRPRQ.fbm\" ... Done.\n",
      "Creating the fireball model \"LeNet-5\" ... Done.\n",
      "Metal device set to: Apple M1 Max\n",
      "  Processed 10000 Sample. (Time: 0.62 Sec.)                              \n",
      "\n",
      "Observed Accuracy: 0.988700\n",
      "Expected Accuracy: 0.100361\n",
      "Kappa: 0.987439 (Excellent)\n"
     ]
    }
   ],
   "source": [
    "from fireball.datasets.mnist import MnistDSet\n",
    "\n",
    "testDs = MnistDSet.makeDatasets('test', batchSize=128)\n",
    "\n",
    "model = Model.makeFromFile(quantizedFileName, testDs=testDs, gpus='0')   \n",
    "model.initSession()\n",
    "\n",
    "results = model.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-training after quantization\n",
    "Fireball can retrain the quantized models by modifying (learning) the quantization codebooks. The following cell creates a \"tune\" dataset by sampling from the training dataset and uses it to \"fine-tune\" the quantized model for 5 epochs. The re-trained model is then evaluated and saved to the ```Models``` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MnistDSet Dataset Info:\n",
      "    Dataset Name ................................... tune\n",
      "    Dataset Location ............................... /Users/shahab/data/mnist/\n",
      "    Number of Classes .............................. 10\n",
      "    Number of Samples .............................. 5400\n",
      "    Sample Shape ................................... (28, 28, 1)\n",
      "\n",
      "\n",
      "Reading from \"Models/LeNet5RRPRQ.fbm\" ... Done.\n",
      "Creating the fireball model \"LeNet-5\" ... Done.\n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "| Epoch  | Batch   | Learning Rate | Loss      | Valid/Test Error  |\n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "| 1      | 42      | 0.00034056156 | 0.0478891 |    1.67% N/A      |\n",
      "| 2      | 85      | 0.00011598216 | 0.0433467 |    1.33% N/A      |\n",
      "| 3      | 128     | 0.00003752411 | 0.0424052 |    1.33% N/A      |\n",
      "| 4      | 171     | 0.00001277927 | 0.0418267 |    1.33% N/A      |\n",
      "| 5      | 214     | 0.00000413452 | 0.0417304 |    1.33% N/A      |\n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "Total Training Time: 4.19 Seconds\n",
      "  Processed 10000 Sample. (Time: 0.57 Sec.)                              \n",
      "\n",
      "Observed Accuracy: 0.989100\n",
      "Expected Accuracy: 0.100368\n",
      "Kappa: 0.987884 (Excellent)\n"
     ]
    }
   ],
   "source": [
    "tuneDs,validDs = MnistDSet.makeDatasets('tune,valid', batchSize=128)\n",
    "print(tuneDs)\n",
    "\n",
    "model = Model.makeFromFile(quantizedFileName, \n",
    "                           trainDs=tuneDs, validationDs=validDs, # Use the \"tuneDs\" for training\n",
    "                           numEpochs=5,\n",
    "                           learningRate=(1e-3,1e-5),\n",
    "                           optimizer=\"Momentum\",\n",
    "                           gpus='0')\n",
    "model.initSession()\n",
    "model.train()\n",
    "\n",
    "model.evaluateDSet(testDs)\n",
    "\n",
    "retrainedFileName = quantizedFileName.replace('.fbm', 'R.fbm')  # Append 'R' to the filename for \"Re-trained\"\n",
    "model.save(retrainedFileName)   # Save the re-trained model to the \"Models\" directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where do I go from here?\n",
    "\n",
    "[Exporting LeNet-5 Model to ONNX](LeNet5-MNIST-ONNX.ipynb)\n",
    "\n",
    "[Exporting LeNet-5 Model to TensorFlow](LeNet5-MNIST-TF.ipynb)\n",
    "\n",
    "[Exporting LeNet-5 Model to CoreML](LeNet5-MNIST-CoreML.ipynb)\n",
    "\n",
    "[Hand-written Digit Recognition as a Regression problem](Regression.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "[Fireball Playgrounds](../Contents.ipynb)\n",
    "\n",
    "[Handwritten Digit Recognition (LeNet-5/MNIST)](LeNet5-MNIST.ipynb)\n",
    "\n",
    "[Reducing number of parameters of LeNet-5 Model](LeNet5-MNIST-Reduce.ipynb)\n",
    "\n",
    "[Pruning LeNet-5 Model](LeNet5-MNIST-Prune.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
