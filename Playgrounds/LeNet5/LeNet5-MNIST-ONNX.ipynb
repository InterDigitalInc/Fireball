{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting to ONNX\n",
    "You can export any Fireball model to ONNX using the [exportToOnnx](https://interdigitalinc.github.io/Fireball/html/source/model.html#fireball.model.Model.exportToOnnx) function. This notebook shows how to use this function to create an ONNX model. It assumes that a trained LeNet-5 model already exists in the ```Models``` directory. You can use the notebook [Handwritten Digit recognition (LeNet-5/MNIST)](LeNet5-MNIST.ipynb) to create and train a LeNet-5 model.\n",
    "\n",
    "Fireball can also export models with reduced number of parameters, pruned models, and quatized models. Please refer to the following notebooks for more information:\n",
    "\n",
    "- [Reducing number of parameters of LeNet-5 Model](LeNet5-MNIST-Reduce.ipynb)\n",
    "- [Pruning LeNet-5 Model](LeNet5-MNIST-Prune.ipynb)\n",
    "- [Quantizing LeNet-5 Model](LeNet5-MNIST-Quantize.ipynb)\n",
    "\n",
    "Note: Fireball uses the ```onnx``` python package to export models to ONNX. We also use the ```onnxruntime``` here to run and evaluate the onnx models.\n",
    "\n",
    "## Load a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading from \"Models/LeNet5RRPRQR.fbm\" ... Done.\n",
      "Creating the fireball model \"LeNet-5\" ... Done.\n",
      "\n",
      "Scope            InShape       Comments                 OutShape      Activ.   Post Act.        # of Params\n",
      "---------------  ------------  -----------------------  ------------  -------  ---------------  -----------\n",
      "IN_IMG                         Image Size: 28x28x1      28 28 1       None                      0          \n",
      "L1_CONV          28 28 1       KSP: 5 1 s               14 14 6       ReLU     MP(KSP):2 2 v    108        \n",
      "L2_CONV          14 14 6       KSP: 5 1 v, LR8          5 5 16        ReLU     MP(KSP):2 2 v    836        \n",
      "L3_FC            5 5 16        LR8                      120           ReLU                      2,390      \n",
      "L4_FC            120           LR8                      84            ReLU                      959        \n",
      "L5_FC            84                                     10            None                      525        \n",
      "OUT_CLASS        10            10 classes               10            None                      0          \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "                                                                  Total Number of parameters: 4,818      \n",
      "  Processed 10000 Sample. (Time: 1.65 Sec.)                              \n",
      "\n",
      "Observed Accuracy:  0.99\n",
      "Expected Accuracy: 0.100348\n",
      "Kappa: 0.988885 (Excellent)\n"
     ]
    }
   ],
   "source": [
    "from fireball import Model\n",
    "from fireball.datasets.mnist import MnistDSet\n",
    "\n",
    "testDs = MnistDSet.makeDatasets('test', batchSize=128)\n",
    "\n",
    "orgFileName = \"Models/LeNet5RRPRQR.fbm\"  # Reduced - Retrained - Pruned - Retrained - Quantized - Retrained\n",
    "\n",
    "model = Model.makeFromFile(orgFileName, testDs=testDs, gpus='0')\n",
    "model.printLayersInfo()\n",
    "model.initSession()\n",
    "results = model.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the model and check the exported ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exporting to ONNX model \"Models/LeNet5RRPRQR.onnx\" ... \n",
      "    Processed all 7 layers.                                     \n",
      "    Saving to \"Models/LeNet5RRPRQR.onnx\" ... Done.\n",
      "Done (0.11 Sec.)\n"
     ]
    }
   ],
   "source": [
    "onnxFileName = orgFileName.replace(\".fbm\",\".onnx\")\n",
    "model.exportToOnnx(onnxFileName, runQuantized=True, classNames=[str(i) for i in range(10)], \n",
    "                   modelDocStr=\"Fireball example: LeNet-5 Model\")\n",
    "\n",
    "# Check the exported model. This throws exceptions if something is wrong with the exported model.\n",
    "import onnx\n",
    "from onnx import shape_inference\n",
    "\n",
    "onnxModel = onnx.load(onnxFileName)\n",
    "onnx.checker.check_model(onnxModel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using netron to visualize the exported model\n",
    "We can now visualize the model's network structure using the [netron](https://github.com/lutzroeder/netron) package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'Models/LeNet5RRPRQR.onnx' at http://10.1.16.58:8084\n"
     ]
    }
   ],
   "source": [
    "import netron\n",
    "import platform\n",
    "\n",
    "if platform.system() == 'Darwin':      # Running on MAC\n",
    "    netron.start(onnxFileName)   \n",
    "else:\n",
    "    import socket\n",
    "    hostIp = socket.gethostbyname(socket.gethostname())\n",
    "    netron.start(onnxFileName, address=(hostIp,8084))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running inference using the exported ONNX model\n",
    "Here we load the test dataset and use it to run inference on random samples from this dataset. We could use fireball's implementation of MNIST dataset, but here we want to run and test the ONNX model without any dependency to Fireball libraty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST Test Dataset:\n",
    "import numpy as np\n",
    "import struct\n",
    "\n",
    "def getDataset(imagesFileName, labelsFileName):\n",
    "    file = open(imagesFileName, mode='rb')\n",
    "    header = file.read(16)\n",
    "    magic, numImages, imageWidth, imageHeight = struct.unpack(\">iiii\", header)\n",
    "    assert magic == 2051, \"Error: Invalid MNIST Image format!\"\n",
    "\n",
    "    buf = file.read(imageWidth * imageHeight * numImages)\n",
    "    data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "    data = (data-127.5)/255.0   # Normalize to [-1..1]\n",
    "    samples = data.reshape(numImages, imageWidth, imageHeight, 1)\n",
    "\n",
    "    file = open(labelsFileName, mode='rb')\n",
    "    header = file.read(8)\n",
    "    magic, numLabels = struct.unpack(\">ii\", header)\n",
    "    assert magic == 2049, \"Error: Invalid MNIST Label format!\"\n",
    "\n",
    "    buf = file.read(numLabels)\n",
    "    labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "    return samples, labels\n",
    "\n",
    "# Update the file names to point to the location of MNIST dataset\n",
    "testSamples, testLabels = getDataset('/data/mnist/t10k-images.idx3-ubyte',\n",
    "                                     '/data/mnist/t10k-labels.idx1-ubyte')\n",
    "\n",
    "testSamples = testSamples.reshape(-1,1,28,28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the following cell shows how to run inference using an ONNX model. We get a random test sample and run prediction on the ONNX model. The ```argmax``` function gives us the actual label. You can run it several time to test it with different samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual label of the sample no 8076 in the dataset: 9\n",
      "Predicted label: 9\n"
     ]
    }
   ],
   "source": [
    "# Inference using the ONNX model and \"onnxruntime\"\n",
    "import onnxruntime as ort\n",
    "options = ort.SessionOptions()\n",
    "options.intra_op_num_threads = 4\n",
    "session = ort.InferenceSession(onnxModel.SerializeToString(), options, providers=['CPUExecutionProvider'])\n",
    "\n",
    "i = np.random.randint(len(testLabels))\n",
    "print( \"Actual label of the sample no %d in the dataset: %d\"%(i, testLabels[i]))\n",
    "sample = testSamples[i:i+1]\n",
    "\n",
    "y = session.run(['ClassProbs'],{'InputImage':sample})\n",
    "print( \"Predicted label: %d\"%(np.argmax(y[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the evaluation over all test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.990000\n"
     ]
    }
   ],
   "source": [
    "predictedLabels = [np.argmax( session.run(['ClassProbs'],{'InputImage':[sample]})[0]) for sample in testSamples]\n",
    "accuracy = float(np.sum(testLabels == predictedLabels))/len(testLabels)\n",
    "print( \"Test Accuracy: %f\"%(accuracy) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Also look at\n",
    "\n",
    "[Exporting LeNet-5 Model to CoreML](LeNet5-MNIST-CoreML.ipynb)\n",
    "\n",
    "[Exporting LeNet-5 Model to TensorFlow](LeNet5-MNIST-TF.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "[Fireball Playgrounds](../Contents.ipynb)\n",
    "\n",
    "[Handwritten Digit Recognition (LeNet-5/MNIST)](LeNet5-MNIST.ipynb)\n",
    "\n",
    "[Reducing number of parameters of LeNet-5 Model](LeNet5-MNIST-Reduce.ipynb)\n",
    "\n",
    "[Pruning LeNet-5 Model](LeNet5-MNIST-Prune.ipynb)\n",
    "\n",
    "[Quantizing LeNet-5 Model](LeNet5-MNIST-Quantize.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
