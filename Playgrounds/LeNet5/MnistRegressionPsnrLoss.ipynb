{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using PSNR for the loss function for Hand-written Digit Regression model\n",
    "This notebook uses Fireball to creare a regression model. The input to the model is a 28x28 monochrome image from MNIST dataset. The output is the predicted value of the model as a single number. Note that the model does not classify the image. It predicts a floating point value.\n",
    "\n",
    "In this notebook we show how to pass a user-defined loss function to the Fireball model. We use PSNR as the loss function; so, the model learns to **maximize** PSNR unlike the standard case where MSE is minimized.\n",
    "\n",
    "Please note that Fireball even copies the loss function in the saved model. So, when the model is loaded later, the loss function does not need to be defined again. The loaded model already has a copy of user defined loss function even though it was not originally part of Fireball.\n",
    "\n",
    "This notebook also shows how to subclass a Fireball dataset class. We want the labels in the MNIST dataset to be a floating point value. We also want the main evaluation metric of the dataset to be PSNR instead of MSE.\n",
    "\n",
    "## Subclassing the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegMnistDSet Dataset Info:\n",
      "    Dataset Location ............................... /Users/shahab/data/mnist/\n",
      "    Number of Training Samples ..................... 60000\n",
      "    Number of Test Samples ......................... 10000\n",
      "    Sample Shape ................................... (28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from fireball import Model\n",
    "from fireball.datasets.mnist import MnistDSet\n",
    "\n",
    "class RegMnistDSet(MnistDSet):\n",
    "    # ******************************************************************************************************************\n",
    "    @classmethod\n",
    "    def postMakeDatasets(cls):\n",
    "        # This is called at the end of a call to makeDatasets\n",
    "        cls.numClasses = 0            # Make this a regression dataset\n",
    "        cls.psnrMax = 9.0             # Set the max value of the output for PSNR calculations\n",
    "        cls.evalMetricName = 'PSNR'   # Set the main evaluation metric to PSNR\n",
    "\n",
    "    # ******************************************************************************************************************\n",
    "    def getBatch(self, batchIndexes):\n",
    "        return self.samples[batchIndexes], np.float32(self.labels[batchIndexes]) # Return labels as float32\n",
    "\n",
    "trainDs, testDs = RegMnistDSet.makeDatasets('train,test', batchSize=128)\n",
    "RegMnistDSet.printDsInfo(trainDs, testDs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the loss function and creating the Fireball model\n",
    "\n",
    "Fireball can recieve a loss function when a model is instantiated. This function is then used by fireball to calculate the loss in the training mode. This function takes the following arguments:\n",
    "- layers: A \"Layers\" object as defined in the \"Layers.py\" file. This keeps a list of all the layers in the model that may be used for the calculation of the loss.\n",
    "- predictions: The output(s) of the network just before the output layer. This is a tuple containing all outputs of the network.\n",
    "- groundTruths: The batch of labels used for the training step. This is a tuple containing all label objects. The tuple usually contains the placeholders created in the Layer's \"makePlaceholders\" function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scope            InShape       Comments                 OutShape      Activ.   Post Act.        # of Params\n",
      "---------------  ------------  -----------------------  ------------  -------  ---------------  -----------\n",
      "IN_IMG                         Image Size: 28x28x1      28 28 1       None                      0          \n",
      "L1_CONV          28 28 1       KSP: 5 1 s               14 14 6       ReLU     MP(KSP):2 2 v    156        \n",
      "L2_CONV          14 14 6       KSP: 5 1 v               5 5 16        ReLU     MP(KSP):2 2 v    2,416      \n",
      "L3_FC            5 5 16                                 120           ReLU                      48,120     \n",
      "L4_FC            120                                    84            ReLU                      10,164     \n",
      "L5_FC            84                                     1             ReLU                      85         \n",
      "OUT_REG          1                                      1             None                      0          \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "                                                                  Total Number of parameters: 60,941     \n",
      "\n",
      "Network configuration:\n",
      "  Input:                     Monochrome images of size 28x28\n",
      "  Output:                    Predicted scaler values.\n",
      "  Network Layers:            7\n",
      "  Tower Devices:             GPU0\n",
      "  Total Network Parameters:  60,941\n",
      "  Total Parameter Tensors:   10\n",
      "  Trainable Tensors:         10\n",
      "  Training Samples:          60,000\n",
      "  Test Samples:              10,000\n",
      "  Num Epochs:                10\n",
      "  Batch Size:                128\n",
      "  L2 Reg. Factor:            0.0001\n",
      "  Global Drop Rate:          0   \n",
      "  Learning Rate: (Exponential Decay)\n",
      "    Initial Value:           0.001        \n",
      "    Final Value:             0.0001       \n",
      "  Optimizer:                 Adam\n",
      "\n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "| Epoch  | Batch   | Learning Rate | Loss      | Valid/Test PSNR   |\n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "| 1      | 469     | 0.00081450626 | -16.79769 | N/A      20.449   |\n",
      "| 2      | 938     | 0.00063024933 | -21.5822  | N/A      22.178   |\n",
      "| 3      | 1407    | 0.00051334203 | -23.13946 | N/A      23.259   |\n",
      "| 4      | 1876    | 0.00039721426 | -24.21234 | N/A      24.040   |\n",
      "| 5      | 2345    | 0.00032353346 | -24.99031 | N/A      24.381   |\n",
      "| 6      | 2814    | 0.00025034402 | -25.73474 | N/A      24.736   |\n",
      "| 7      | 3283    | 0.00020390675 | -26.2992  | N/A      25.031   |\n",
      "| 8      | 3752    | 0.00015777916 | -26.73063 | N/A      25.158   |\n",
      "| 9      | 4221    | 0.00012851211 | -27.10669 | N/A      25.266   |\n",
      "| 10     | 4690    | 0.00009944021 | -27.41907 | N/A      25.510   |\n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "Total Training Time: 239.75 Seconds\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "def psnrLoss(layers, predictions, groundTruths):\n",
    "    rmse = tf.sqrt( tf.reduce_mean( tf.square(predictions[0] - groundTruths[0]) ) )\n",
    "    rmseClipped = tf.clip_by_value(rmse, 0.000001, 10000000.0, name='CLIP')\n",
    "    psnr = 20.*tf.log(9.0/rmseClipped)/np.log(10)\n",
    "    return -psnr  # We want to maximize PSNR which means minimizing -PSNR\n",
    "\n",
    "\n",
    "# Here we define a \"Regression LeNet-5\" network which has 2 convolutional layers followed by 3 fully connected\n",
    "layersInfo = ('IMG_S28_D1,' +                 # The input layer takes a 28x28 image of depth 1 (monochrome)\n",
    "              'CONV_K5_O6_Ps:ReLU:MP_K2,' +   # Conv, Kernel size 5, 6 out channels, \"same\" padding, ReLU, Max pool\n",
    "              'CONV_K5_O16_Pv:ReLU:MP_K2,' +  # Conv, Kernel size 5, 16 out channels, \"valid\" padding, ReLU, Max pool\n",
    "              'FC_O120:ReLU,FC_O84:ReLU,FC_O1:ReLU,' +   # 3 fully connected layers\n",
    "              'REG')                          # Unlike original LeNet-5, the output is just a float32 number\n",
    "\n",
    "model = Model(name='RegMnistTest',\n",
    "              layersInfo=layersInfo,\n",
    "              trainDs=trainDs, testDs=testDs,\n",
    "              numEpochs=10,\n",
    "              regFactor=0.0001,\n",
    "              learningRate=(0.001,0.0001),\n",
    "              optimizer=\"Adam\",\n",
    "              lossFunction=psnrLoss,\n",
    "              gpus=\"0\")\n",
    "\n",
    "model.printLayersInfo()\n",
    "model.printNetConfig()\n",
    "model.initSession()\n",
    "model.train()\n",
    "model.save(\"Models/TestCustomLoss.fbm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running inference on the trained model\n",
    "Here we run inference on random samples from the test dataset. Run this several times and see the difference between the actual digit and the predicted value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual label of the sample no 2468 in the dataset: 6\n",
      "Predicted Value: 6.177000\n"
     ]
    }
   ],
   "source": [
    "i = np.random.randint(testDs.numSamples)\n",
    "print( \"Actual label of the sample no %d in the dataset: %d\"%(i, testDs.labels[i]))\n",
    "print( \"Predicted Value: %f\"%(model.inferOne(testDs.samples[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model\n",
    "We can now call the ```evaluate``` function of the Fireball model to evaluate it as a regression problem. The standard metric for the evaluation of a regression problem is mean squared error (MSE).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 10000 Sample. (Time: 1.77 Sec.)                              \n",
      "\n",
      "MSE:  0.227759\n",
      "RMSE: 0.477241\n",
      "MAE:  0.203611\n",
      "PSNR: 25.510095\n"
     ]
    }
   ],
   "source": [
    "Results = model.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistance of user-defined loss function\n",
    "Fireball includes a copy of customized loss function in the ```fbm``` file. As long as the loss function does not use any global info, it will continue to work after loading the file.\n",
    "\n",
    "To test this, reset the kernel to make sure the above loss function definition is gone. Then run the only first cell above to create the dataset. DO NOT run the second cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading from \"Models/TestCustomLoss.fbm\" ... Done.\n",
      "Creating the fireball model \"RegMnistTest\" ... Done.\n",
      "  Processed 10000 Sample. (Time: 0.91 Sec.)                              \n",
      "\n",
      "MSE:  0.227759\n",
      "RMSE: 0.477241\n",
      "MAE:  0.203611\n",
      "PSNR: 25.510095\n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "| Epoch  | Batch   | Learning Rate | Loss      | Valid/Test PSNR   |\n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "| 1      | 469     | 0.0001        | -27.67975 | N/A      25.545   |\n",
      "| 2      | 938     | 0.0001        | -27.83217 | N/A      25.402   |\n",
      "| 3      | 1407    | 0.0001        | -27.89658 | N/A      25.633   |\n",
      "| 4      | 1876    | 0.0001        | -27.94295 | N/A      25.576   |\n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "Total Training Time: 96.28 Seconds\n",
      "  Processed 10000 Sample. (Time: 1.41 Sec.)                              \n",
      "\n",
      "MSE:  0.224338\n",
      "RMSE: 0.473643\n",
      "MAE:  0.194202\n",
      "PSNR: 25.575821\n"
     ]
    }
   ],
   "source": [
    "# Now we create a new model using the saved model file. This model already \"contains\" our\n",
    "# user-defined loss function eventhough we did not pass any loss function to it.\n",
    "# Of course we could override the original loss function by passing a new one to the \n",
    "# \"makeFromFile\" function.\n",
    "# Here we want to train it for 4 more epochs with smaller learning rate.\n",
    "from fireball import Model\n",
    "model = Model.makeFromFile(\"Models/TestCustomLoss.fbm\",\n",
    "                           trainDs=trainDs, testDs=testDs,\n",
    "                           optimizer=\"Adam\",\n",
    "                           numEpochs=4,\n",
    "                           learningRate=0.0001,\n",
    "                           gpus=\"0\")\n",
    "model.initSession()\n",
    "model.evaluateDSet(testDs)\n",
    "\n",
    "# Train the model for 4 more epochs\n",
    "model.train()\n",
    "\n",
    "# Evaluate again\n",
    "results = model.evaluateDSet(testDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where do I go from here?\n",
    "[Handwritten Digit recognition (LeNet-5/MNIST)](LeNet5/LeNet5-MNIST.ipynb)\n",
    "\n",
    "[Reducing number of parameters of LeNet-5 Model](LeNet5-MNIST-Reduce.ipynb)\n",
    "\n",
    "[Quantizing the LeNet-5 Model](LeNet5-MNIST-Quantize.ipynb)\n",
    "\n",
    "[Exporting LeNet-5 Model to ONNX](LeNet5-MNIST-ONNX.ipynb)\n",
    "\n",
    "[Exporting LeNet-5 Model to CoreML](LeNet5-MNIST-CoreML.ipynb)\n",
    "\n",
    "[Exporting LeNet-5 Model to TensorFlow](LeNet5-MNIST-TF.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "[Fireball Playgrounds](../Contents.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
