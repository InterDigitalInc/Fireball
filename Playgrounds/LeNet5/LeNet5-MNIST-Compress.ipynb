{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressing LeNet-5 model\n",
    "This notebook shows how to compress a pre-trained Fireball model using arithmetic entropy coding. It assumes \n",
    "that a trained LeNet-5 model already exists in the ```Models``` directory. You can use the notebook\n",
    "[Handwritten Digit recognition (LeNet-5/MNIST)](LeNet5-MNIST.ipynb) to create and train a LeNet-5 model.\n",
    "\n",
    "Fireball reduces the size of model file by applying entropy coding on the model parameters. ```compressModel``` is a class method that receives the file names of input and output to the \n",
    "compression process.\n",
    "\n",
    "The code in the following cell compresses the model specified by ```orgFileName``` and creates a\n",
    "new compressed model file (A ``*.fbmc`` file).\n",
    "\n",
    "Please note that this compression process is **lossless**. So the model performance is not affected by this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading model parameters from \"Models/LeNet5RRPRQR.fbm\" ... Done.\n",
      "Compressing 13 tensors ... \n",
      "    Tensor 1 of 13 Shape: 5x5x1x6 ........... Compressed. (196 -> 147 bytes)\n",
      "    Tensor 2 of 13 Shape: 6 ................. Compressed. (28 -> 27 bytes)\n",
      "    Tensor 3 of 13 Shape: 5x5x6x8 ........... Compressed. (955 -> 549 bytes)\n",
      "    Tensor 4 of 13 Shape: 1x1x8x16 .......... Compressed. (247 -> 221 bytes)\n",
      "    Tensor 5 of 13 Shape: 16 ................ Compressed. (68 -> 67 bytes)\n",
      "    Tensor 6 of 13 Shape: 400x8 ............. Compressed. (2300 -> 1219 bytes)\n",
      "    Tensor 7 of 13 Shape: 8x120 ............. Compressed. (745 -> 534 bytes)\n",
      "    Tensor 8 of 13 Shape: 120 ............... Compressed. (484 -> 438 bytes)\n",
      "    Tensor 9 of 13 Shape: 120x8 ............. Compressed. (659 -> 394 bytes)\n",
      "    Tensor 10 of 13 Shape: 8x84 ............. Compressed. (588 -> 350 bytes)\n",
      "    Tensor 11 of 13 Shape: 84 ............... Compressed. (340 -> 325 bytes)\n",
      "    Tensor 12 of 13 Shape: 84x10 ............ Compressed. (771 -> 515 bytes)\n",
      "    Tensor 13 of 13 Shape: 10 ............... Compressed. (44 -> 44 bytes)\n",
      "Finished compressing model parameters (0.26 Sec.)\n",
      "Now saving to \"Models/LeNet5RRPRQR.fbmc\" ... Done.\n",
      "Model File Size: 9,071 -> 5,930 bytes\n"
     ]
    }
   ],
   "source": [
    "from fireball import Model\n",
    "\n",
    "# orgFileName = \"Models/LeNet5RRQR.fbm\"    # Reduced - Retrained - Quantized - Retrained\n",
    "orgFileName = \"Models/LeNet5RRPRQR.fbm\"  # Reduced - Retrained - Pruned - Retrained - Quantized - Retrained\n",
    "\n",
    "compressedFileName = orgFileName.replace('.fbm', '.fbmc')\n",
    "\n",
    "# quantizing the model\n",
    "qResults = Model.compressModel(orgFileName, compressedFileName,\n",
    "                               quiet=False, verbose=True, numWorkers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the file sizes before and after compression.\n",
    "## Evaluate the compressed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading from \"Models/LeNet5RRPRQR.fbmc\" ... \n",
      "    Decompressed 13 tensors.              \n",
      "Done.\n",
      "Creating the fireball model \"LeNet-5\" ... Done.\n",
      "Metal device set to: Apple M1 Max\n",
      "  Processed 10000 Sample. (Time: 1.65 Sec.)                              \n",
      "\n",
      "Observed Accuracy: 0.989100\n",
      "Expected Accuracy: 0.100368\n",
      "Kappa: 0.987884 (Excellent)\n"
     ]
    }
   ],
   "source": [
    "from fireball import Model\n",
    "\n",
    "from fireball.datasets.mnist import MnistDSet\n",
    "\n",
    "testDs = MnistDSet.makeDatasets('test', batchSize=128)\n",
    "\n",
    "model = Model.makeFromFile(compressedFileName, testDs=testDs, gpus='0')   \n",
    "model.initSession()\n",
    "\n",
    "results = model.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where do I go from here?\n",
    "\n",
    "[Exporting LeNet-5 Model to ONNX](LeNet5-MNIST-ONNX.ipynb)\n",
    "\n",
    "[Exporting LeNet-5 Model to TensorFlow](LeNet5-MNIST-TF.ipynb)\n",
    "\n",
    "[Exporting LeNet-5 Model to CoreML](LeNet5-MNIST-CoreML.ipynb)\n",
    "\n",
    "[Hand-written Digit Recognition as a Regression problem](Regression.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "[Fireball Playgrounds](../Contents.ipynb)\n",
    "\n",
    "[Handwritten Digit Recognition (LeNet-5/MNIST)](LeNet5-MNIST.ipynb)\n",
    "\n",
    "[Reducing number of parameters of LeNet-5 Model](LeNet5-MNIST-Reduce.ipynb)\n",
    "\n",
    "[Pruning LeNet-5 Model](LeNet5-MNIST-Prune.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
