{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting a BERT/SQuAD model to TensorFlow\n",
    "You can use the Fireball's ```exportToTf``` function to export a model to TensorFlow code. This function creates a\n",
    "python file that implements the model using TensorFlow APIs. It also creates a numpy file (npz) that contains the parameters of the network. This notebook shows how to use this function to export a Fireball model to TensorFlow. It is assumed that a trained BERT/SQuAD model already exists in the ```Models``` directory. Please refer to the notebook [Question Answering (BERT/SQuAD)](BertSquad.ipynb) for more info about training and using a BERT/SQuAD model.\n",
    "\n",
    "Fireball can also export models with reduced number of parameters, pruned models, and quatized models. Please refer to the following notebooks for more information:\n",
    "\n",
    "- [Reducing number of parameters of BERT/SQuAD Model](BertSquad-Reduce.ipynb)\n",
    "- [Pruning BERT/SQuAD Model](BertSquad-Quantize.ipynb)\n",
    "- [Quantizing BERT/SQuAD Model](BertSquad-Quantize.ipynb)\n",
    "\n",
    "## Load a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading from \"Models/BertSquadRRPRQR.fbm\" ... Done.\n",
      "Creating the fireball model \"Bert-SQuAD\" ... Done.\n",
      "\n",
      "Scope            InShape       Comments                 OutShape      Activ.   Post Act.        # of Params\n",
      "---------------  ------------  -----------------------  ------------  -------  ---------------  -----------\n",
      "IN_EMB           ≤512 2        LR512                    ≤512 768      None                      4,743,735  \n",
      "S1_L1_LN         ≤512 768                               ≤512 768      None     DO:0.1           1,536      \n",
      "S2_L1_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      2,839,069  \n",
      "S2_L2_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      2,898,847  \n",
      "S2_L3_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      2,909,099  \n",
      "S2_L4_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,036,692  \n",
      "S2_L5_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,125,424  \n",
      "S2_L6_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,135,978  \n",
      "S2_L7_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,094,206  \n",
      "S2_L8_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,102,034  \n",
      "S2_L9_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,161,228  \n",
      "S2_L10_BERT      ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,303,111  \n",
      "S2_L11_BERT      ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,264,611  \n",
      "S2_L12_BERT      ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,197,986  \n",
      "S3_L1_FC         ≤512 768                               ≤512 2        None     L2               918        \n",
      "OUT_ANSWER       ≤512 2                                 2 ≤512        None                      0          \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "                                                                  Total Number of parameters: 41,814,474 \n"
     ]
    }
   ],
   "source": [
    "from fireball import Model\n",
    "\n",
    "# orgFileName = \"Models/BertSquad.fbm\"        # Original model\n",
    "# orgFileName = \"Models/BertSquadQR.fbm\"      # Quantized - Retrained\n",
    "# orgFileName = \"Models/BertSquadPR.fbm\"      # Pruned - Retrained\n",
    "# orgFileName = \"Models/BertSquadPRQR.fbm\"    # Pruned - Retrained - Quantized - Retrained\n",
    "# orgFileName = \"Models/BertSquadRR.fbm\"      # Reduced - Retrained\n",
    "# orgFileName = \"Models/BertSquadRRQR.fbm\"    # Reduced - Retrained - Quantized - Retrained\n",
    "# orgFileName = \"Models/BertSquadRRPR.fbm\"    # Reduced - Retrained - Pruned - Retrained\n",
    "orgFileName = \"Models/BertSquadRRPRQR.fbm\"  # Reduced - Retrained - Pruned - Retrained - Quantized - Retrained\n",
    "\n",
    "model = Model.makeFromFile(orgFileName, gpus='0')\n",
    "model.printLayersInfo()\n",
    "model.initSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the model\n",
    "Fireball creates a folder and puts 2 files in the folder. Here we call the ```exportToTf``` funtion to export the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exporting to TensorFlow model \"Models/BertSquad_TF\" ... \n",
      "    Processed all 16 layers.                                     \n",
      "    Creating parameters file \"Params.npz\" ... Done.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.exportToTf(\"Models/BertSquad_TF\", runQuantized=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running inference on the exported model\n",
    "To verify the exported model, we can now run inference on it. Here we have a \"context\" which is a paragraph about InterDigital copied from Wikipedia and 3 different questions related to the context. We use our exported ONNX model to answer the questions.\n",
    "\n",
    "**Note:** We could use the \"Tokenizer\" included in Fireball. But to show the independence of the following code from Fireball, we are using Google's original tokenizer from [here](https://github.com/google-research/bert/blob/master/tokenization.py).\n",
    "\n",
    "**NOTE**: Please reset the kernel before running the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shahab/code/Fireball/OpenSource/ve/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "\n",
      "InterDigital is a technology research and development company that provides wireless and video technologies for \n",
      "mobile devices, networks, and services worldwide. Founded in 1972, InterDigital is listed on NASDAQ and is \n",
      "included in the S&P SmallCap 600. InterDigital had 2020 revenue of $359 million and a portfolio of about \n",
      "32,000 U.S. and foreign issued patents and patent applications.\n",
      "\n",
      "\n",
      "Q1: When was InterDigital established?\n",
      "    1972\n",
      "\n",
      "Q2: How much was InterDigital's revenue in 2020?\n",
      "    $ 359 million\n",
      "\n",
      "Q3: What does InterDigital provide?\n",
      "    wireless and video technologies\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import numpy as np\n",
    "from Models.BertSquad_TF.TfModel import Network\n",
    "net=Network()\n",
    "\n",
    "import tokenization, os\n",
    "tokenizer = tokenization.FullTokenizer(os.path.expanduser(\"~\")+\"/data/SQuAD/vocab.txt\")\n",
    "\n",
    "context = r\"\"\"\n",
    "InterDigital is a technology research and development company that provides wireless and video technologies for \n",
    "mobile devices, networks, and services worldwide. Founded in 1972, InterDigital is listed on NASDAQ and is \n",
    "included in the S&P SmallCap 600. InterDigital had 2020 revenue of $359 million and a portfolio of about \n",
    "32,000 U.S. and foreign issued patents and patent applications.\n",
    "\"\"\"\n",
    "\n",
    "print(context)\n",
    "questions = [\n",
    "    \"When was InterDigital established?\",\n",
    "    \"How much was InterDigital's revenue in 2020?\",\n",
    "    \"What does InterDigital provide?\",\n",
    "]\n",
    "\n",
    "contextTokens = tokenizer.tokenize(context)\n",
    "\n",
    "for i, question in enumerate(questions):\n",
    "    questionTokens = tokenizer.tokenize(question)\n",
    "    allTokens = [\"[CLS]\"] + questionTokens + [\"[SEP]\"] + contextTokens + [\"[SEP]\"]\n",
    "    tokIds = tokenizer.convert_tokens_to_ids(allTokens)\n",
    "    tokTypes = [0]*(len(questionTokens)+2) + [1]*(len(contextTokens)+1)\n",
    "    sample = ([tokIds], [tokTypes])\n",
    "\n",
    "    startTok, endTok = net.infer(sample)\n",
    "    startTok -= len(questionTokens) + 2\n",
    "    endTok -= len(questionTokens) + 2\n",
    "    answer = ' '.join(contextTokens[int(startTok):int(endTok+1)]).replace(\" ##\",\"\")\n",
    "    print(\"\\nQ%d: %s\\n    %s\"%(i+1, question, answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where do I go from here?\n",
    "\n",
    "[Exporting BERT/SQuAD Model to CoreML](BertSquad-CoreML.ipynb)\n",
    "\n",
    "[Exporting BERT/SQuAD Model to ONNX](BertSquad-ONNX.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "[Fireball Playgrounds](../Contents.ipynb)\n",
    "\n",
    "[Question Answering (BERT/SQuAD)](BertSquad.ipynb)\n",
    "\n",
    "[Reducing number of parameters of BERT/SQuAD Model](BertSquad-Reduce.ipynb)\n",
    "\n",
    "[Pruning BERT/SQuAD Model](BertSquad-Prune.ipynb)\n",
    "\n",
    "[Quantizing BERT/SQuAD Model](BertSquad-Quantize.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
