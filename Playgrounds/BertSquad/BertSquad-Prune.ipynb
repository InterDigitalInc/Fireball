{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7a934cd",
   "metadata": {},
   "source": [
    "# Pruning BERT/SQuAD Model\n",
    "This notebook shows how to reduce the size of a model by pruning its parameters. It assumes \n",
    "that a trained model already exists in the ```Models``` directory. Please refer to the notebook [Question Answering (BERT/SQuAD)](BertSquad.ipynb) for more info about training and using a BERT/SQuAD model.\n",
    "\n",
    "If you want to prune a Low-Rank model, you can use [this](BertSquad-Reduce.ipynb) notebook\n",
    "to reduce the number of parameters in ```BERT/SQuAD```.\n",
    "\n",
    "## Load and evaluate the original pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f3f6e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing tokenizer from \"/data/SQuAD/vocab.txt\" ... Done. (Vocab Size: 30522)\n",
      "\n",
      "Reading from \"Models/BertSquadRR.fbm\" ... Done.\n",
      "Creating the fireball model \"Bert-SQuAD\" ... Done.\n",
      "\n",
      "Scope            InShape       Comments                 OutShape      Activ.   Post Act.        # of Params\n",
      "---------------  ------------  -----------------------  ------------  -------  ---------------  -----------\n",
      "IN_EMB           ≤512 2                                 ≤512 768      None                      23,835,648 \n",
      "S1_L1_LN         ≤512 768                               ≤512 768      None     DO:0.1           1,536      \n",
      "S2_L1_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,097,216  \n",
      "S2_L2_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,177,088  \n",
      "S2_L3_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,207,808  \n",
      "S2_L4_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,398,272  \n",
      "S2_L5_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,533,440  \n",
      "S2_L6_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,551,872  \n",
      "S2_L7_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,484,288  \n",
      "S2_L8_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,508,864  \n",
      "S2_L9_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,576,448  \n",
      "S2_L10_BERT      ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,785,344  \n",
      "S2_L11_BERT      ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,699,328  \n",
      "S2_L12_BERT      ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,527,296  \n",
      "S3_L1_FC         ≤512 768                               ≤512 2        None     L2               1,538      \n",
      "OUT_ANSWER       ≤512 2                                 2 ≤512        None                      0          \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "                                                                  Total Number of parameters: 89,385,986 \n",
      "  Processed 10833 Samples. (Time: 51.87 Sec.)                              \n",
      "\n",
      "    Exact Match: 79.839\n",
      "    f1:          87.478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from fireball import Model, myPrint\n",
    "from fireball.datasets.squad import SquadDSet\n",
    "import time, os\n",
    "\n",
    "gpus = \"upto4\"\n",
    "\n",
    "testDs = SquadDSet.makeDatasets(\"Test\", batchSize=128, version=1 )\n",
    "\n",
    "orgFileName = \"Models/BertSquadRR.fbm\"    # Reduced - Retrained\n",
    "\n",
    "model = Model.makeFromFile(orgFileName, testDs=testDs, gpus=gpus)   \n",
    "model.printLayersInfo()\n",
    "model.initSession()\n",
    "results = model.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545759bf",
   "metadata": {},
   "source": [
    "## Pruning the model\n",
    "Here we prune the model using the [pruneModel](https://interdigitalinc.github.io/Fireball/html/source/model.html#fireball.model.Model.pruneModel) class method of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e00316e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading model parameters from \"Models/BertSquadRR.fbm\" ... Done.\n",
      "Pruning 271 tensors using 36 workers ... \n",
      "   Pruning Parameters:\n",
      "        mseUb ................ 0.000050\n",
      "Pruning process complete (8.76 Sec.)\n",
      "Now saving to \"Models/BertSquadRRP.fbm\" ... Done.\n",
      "\n",
      "Number of parameters: 89,385,986 -> 53,047,718 (36,338,268 pruned)\n",
      "Model File Size: 357,560,138 -> 223,370,708 bytes\n"
     ]
    }
   ],
   "source": [
    "prunedFileName = orgFileName.replace('.fbm', 'P.fbm')  # Append 'P' to the filename for \"Pruned\"\n",
    "pResults = Model.pruneModel(orgFileName, prunedFileName, mseUb=.00005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2314a4",
   "metadata": {},
   "source": [
    "## Evaluate the pruned model\n",
    "Compare the new number of parameters with the original. Let's see the impact of this reduction to the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48708353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading from \"Models/BertSquadRRP.fbm\" ... Done.\n",
      "Creating the fireball model \"Bert-SQuAD\" ... Done.\n",
      "\n",
      "Scope            InShape       Comments                 OutShape      Activ.   Post Act.        # of Params\n",
      "---------------  ------------  -----------------------  ------------  -------  ---------------  -----------\n",
      "IN_EMB           ≤512 2                                 ≤512 768      None                      15,974,954 \n",
      "S1_L1_LN         ≤512 768                               ≤512 768      None     DO:0.1           1,536      \n",
      "S2_L1_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      2,838,763  \n",
      "S2_L2_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      2,899,141  \n",
      "S2_L3_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      2,910,253  \n",
      "S2_L4_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,037,189  \n",
      "S2_L5_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,125,269  \n",
      "S2_L6_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,135,991  \n",
      "S2_L7_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,095,705  \n",
      "S2_L8_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,101,204  \n",
      "S2_L9_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,161,505  \n",
      "S2_L10_BERT      ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,303,353  \n",
      "S2_L11_BERT      ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,264,071  \n",
      "S2_L12_BERT      ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,197,865  \n",
      "S3_L1_FC         ≤512 768                               ≤512 2        None     L2               919        \n",
      "OUT_ANSWER       ≤512 2                                 2 ≤512        None                      0          \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "                                                                  Total Number of parameters: 53,047,718 \n",
      "  Processed 10833 Samples. (Time: 62.21 Sec.)                              \n",
      "\n",
      "    Exact Match: 30.009\n",
      "    f1:          41.846\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model.makeFromFile(prunedFileName, testDs=testDs, gpus=gpus)   \n",
    "model.printLayersInfo()\n",
    "model.initSession()\n",
    "results = model.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cf4751",
   "metadata": {},
   "source": [
    "## Re-training after pruning\n",
    "Here we make a new model for re-training from the file created above. We then call the [train](https://interdigitalinc.github.io/Fireball/html/source/model.html#fireball.model.Model.train) method of the model to start the re-training.\n",
    "\n",
    "After re-training, we run the [evaluate](https://interdigitalinc.github.io/Fireball/html/source/model.html#fireball.model.Model.evaluate) function again to see how the re-training improved the performance\n",
    "of the model.\n",
    "\n",
    "The re-trained model is then saved to a file appending an 'R' letter (for Re-trained) to the end of the pruned model file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b6be014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing tokenizer from \"/data/SQuAD/vocab.txt\" ... Done. (Vocab Size: 30522)\n",
      "\n",
      "Reading from \"Models/BertSquadRRP.fbm\" ... Done.\n",
      "Creating the fireball model \"Bert-SQuAD\" ... Done.\n",
      "\n",
      "Network configuration:\n",
      "  Input:                     A tuple of TokenIds and TokenTypes.\n",
      "  Output:                    2 logit vectors (with length ≤ 512) for start and end indexes of the answer.\n",
      "  Network Layers:            16\n",
      "  Tower Devices:             GPU0, GPU1, GPU2, GPU3\n",
      "  Total Network Parameters:  53,047,718\n",
      "  Total Parameter Tensors:   271\n",
      "  Trainable Tensors:         271\n",
      "  Training Samples:          87,844\n",
      "  Test Samples:              10,833\n",
      "  Num Epochs:                2\n",
      "  Batch Size:                32\n",
      "  L2 Reg. Factor:            0.0001\n",
      "  Global Drop Rate:          0   \n",
      "  Learning Rate: (Exponential Decay)\n",
      "    Initial Value:           0.00002      \n",
      "    Final Value:             0.000004     \n",
      "  Optimizer:                 Adam\n",
      "\n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "| Epoch  | Batch   | Learning Rate | Loss      | Valid/Test Acc.   |\n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "| 1      | 2745    | 0.00000926582 | 0.6564883 | N/A        77.59% |\n",
      "| 2      | 5491    | 0.00000407813 | 0.5167508 | N/A        78.26% |\n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "Total Training Time: 3053.46 Seconds\n",
      "  Processed 10833 Samples. (Time: 47.34 Sec.)                              \n",
      "\n",
      "    Exact Match: 78.259\n",
      "    f1:          86.505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDs = SquadDSet.makeDatasets(\"Train\", batchSize=128, version=1 )\n",
    "\n",
    "model = Model.makeFromFile(prunedFileName, trainDs=trainDs, testDs=testDs,\n",
    "                           batchSize=32, numEpochs=2,\n",
    "                           regFactor=0.0001,\n",
    "                           learningRate=(2e-5,4e-6), optimizer='Adam',\n",
    "                           saveBest=False,\n",
    "                           gpus=gpus)\n",
    "model.printNetConfig()\n",
    "model.initSession()\n",
    "model.train()\n",
    "results = model.evaluate()\n",
    "\n",
    "retrainedFileName = prunedFileName.replace('.fbm', 'R.fbm')  # Append 'R' to the filename for \"Retrained\"\n",
    "model.save(retrainedFileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a036b87",
   "metadata": {},
   "source": [
    "## Also look at\n",
    "\n",
    "[Quantizing BERT/SQuAD Model](BertSquad-Quantize.ipynb)\n",
    "\n",
    "[Exporting BERT/SQuAD Model to ONNX](BertSquad-ONNX.ipynb)\n",
    "\n",
    "[Exporting BERT/SQuAD Model to TensorFlow](BertSquad-TF.ipynb)\n",
    "\n",
    "[Exporting BERT/SQuAD Model to CoreML](BertSquad-CoreML.ipynb)\n",
    "\n",
    "________________\n",
    "\n",
    "[Fireball Playgrounds](../Contents.ipynb)\n",
    "\n",
    "[Question Answering (BERT/SQuAD)](BertSquad.ipynb)\n",
    "\n",
    "[Reducing number of parameters of BERT/SQuAD Model](BertSquad-Reduce.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28692b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
