{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7a934cd",
   "metadata": {},
   "source": [
    "# Pruning BERT/SQuAD Model\n",
    "This notebook shows how to reduce the size of a model by pruning its parameters. It assumes \n",
    "that a trained model already exists in the ```Models``` directory. Please refer to the notebook [Question Answering (BERT/SQuAD)](BertSquad.ipynb) for more info about training and using a BERT/SQuAD model.\n",
    "\n",
    "If you want to prune a Low-Rank model, you can use [this](BertSquad-Reduce.ipynb) notebook\n",
    "to reduce the number of parameters in ```BERT/SQuAD```.\n",
    "\n",
    "## Load and evaluate the original pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f3f6e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing tokenizer from \"/home/shahab/data/SQuAD/vocab.txt\" ... Done. (Vocab Size: 30522)\n",
      "\n",
      "Reading from \"Models/BertSquadRR.fbm\" ... Done.\n",
      "Creating the fireball model \"Bert-SQuAD\" ... Done.\n",
      "\n",
      "Scope            InShape       Comments                 OutShape      Activ.   Post Act.        # of Params\n",
      "---------------  ------------  -----------------------  ------------  -------  ---------------  -----------\n",
      "IN_EMB           ≤512 2        LR512                    ≤512 768      None                      16,415,232 \n",
      "S1_L1_LN         ≤512 768                               ≤512 768      None     DO:0.1           1,536      \n",
      "S2_L1_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,097,216  \n",
      "S2_L2_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,177,088  \n",
      "S2_L3_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,207,808  \n",
      "S2_L4_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,398,272  \n",
      "S2_L5_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,533,440  \n",
      "S2_L6_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,551,872  \n",
      "S2_L7_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,484,288  \n",
      "S2_L8_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,508,864  \n",
      "S2_L9_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,576,448  \n",
      "S2_L10_BERT      ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,785,344  \n",
      "S2_L11_BERT      ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,699,328  \n",
      "S2_L12_BERT      ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,527,296  \n",
      "S3_L1_FC         ≤512 768                               ≤512 2        None     L2               1,538      \n",
      "OUT_ANSWER       ≤512 2                                 2 ≤512        None                      0          \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "                                                                  Total Number of parameters: 81,965,570 \n",
      "  Processed 10833 Samples. (Time: 55.26 Sec.)                              \n",
      "\n",
      "    Exact Match: 79.697\n",
      "    f1:          87.475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from fireball import Model, myPrint\n",
    "from fireball.datasets.squad import SquadDSet\n",
    "import time, os\n",
    "\n",
    "gpus = \"0,1,2,3\"\n",
    "\n",
    "testDs = SquadDSet.makeDatasets(\"Test\", batchSize=128, version=1 )\n",
    "\n",
    "# orgFileName = \"Models/BertSquad.fbm\"    # Original model\n",
    "# orgFileName = \"Models/BertSquadR.fbm\"   # Reduced\n",
    "orgFileName = \"Models/BertSquadRR.fbm\"    # Reduced - Retrained\n",
    "\n",
    "\n",
    "model = Model.makeFromFile(orgFileName, testDs=testDs, gpus=gpus)   \n",
    "model.printLayersInfo()\n",
    "model.initSession()\n",
    "results = model.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545759bf",
   "metadata": {},
   "source": [
    "## Pruning the model\n",
    "Here we prune the model using the ``pruneModel`` class method of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e00316e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading model parameters from \"Models/BertSquadRR.fbm\" ... Done.\n",
      "Pruning 272 tensors using 20 workers ... \n",
      "   Pruning Parameters:\n",
      "        mseUb ................ 0.000050\n",
      "Pruning process complete (6.08 Sec.)\n",
      "Now saving to \"Models/BertSquadRRP.fbm\" ... Done.\n",
      "\n",
      "Number of parameters: 81,965,570 -> 41,814,474 (40,151,096 pruned)\n",
      "Model File Size: 327,878,776 -> 177,510,201 bytes\n"
     ]
    }
   ],
   "source": [
    "prunedFileName = orgFileName.replace('.fbm', 'P.fbm')  # Append 'P' to the filename for \"Pruned\"\n",
    "pResults = Model.pruneModel(orgFileName, prunedFileName, mseUb=.00005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2314a4",
   "metadata": {},
   "source": [
    "## Evaluate the pruned model\n",
    "Compare the new number of parameters with the original. Let's see the impact of this reduction to the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48708353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading from \"Models/BertSquadRRP.fbm\" ... Done.\n",
      "Creating the fireball model \"Bert-SQuAD\" ... Done.\n",
      "\n",
      "Scope            InShape       Comments                 OutShape      Activ.   Post Act.        # of Params\n",
      "---------------  ------------  -----------------------  ------------  -------  ---------------  -----------\n",
      "IN_EMB           ≤512 2        LR512                    ≤512 768      None                      4,743,735  \n",
      "S1_L1_LN         ≤512 768                               ≤512 768      None     DO:0.1           1,536      \n",
      "S2_L1_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      2,839,069  \n",
      "S2_L2_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      2,898,847  \n",
      "S2_L3_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      2,909,099  \n",
      "S2_L4_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,036,692  \n",
      "S2_L5_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,125,424  \n",
      "S2_L6_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,135,978  \n",
      "S2_L7_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,094,206  \n",
      "S2_L8_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,102,034  \n",
      "S2_L9_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,161,228  \n",
      "S2_L10_BERT      ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,303,111  \n",
      "S2_L11_BERT      ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,264,611  \n",
      "S2_L12_BERT      ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,197,986  \n",
      "S3_L1_FC         ≤512 768                               ≤512 2        None     L2               918        \n",
      "OUT_ANSWER       ≤512 2                                 2 ≤512        None                      0          \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "                                                                  Total Number of parameters: 41,814,474 \n",
      "  Processed 10833 Samples. (Time: 59.26 Sec.)                              \n",
      "\n",
      "    Exact Match: 29.470\n",
      "    f1:          42.120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model.makeFromFile(prunedFileName, testDs=testDs, gpus=gpus)   \n",
    "model.printLayersInfo()\n",
    "model.initSession()\n",
    "results = model.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cf4751",
   "metadata": {},
   "source": [
    "## Re-training after pruning\n",
    "Here we make a new model for re-training from the file created above. We then call the ```train``` method of the model to start the re-training.\n",
    "\n",
    "After re-training, we run the ```evaluate``` function again to see how the re-training improved the performance\n",
    "of the model.\n",
    "\n",
    "The re-trained model is then saved to a file appending an 'R' letter (for Re-trained) to the end of the pruned model file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b6be014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing tokenizer from \"/home/shahab/data/SQuAD/vocab.txt\" ... Done. (Vocab Size: 30522)\n",
      "\n",
      "Reading from \"Models/BertSquadRRP.fbm\" ... Done.\n",
      "Creating the fireball model \"Bert-SQuAD\" ... Done.\n",
      "\n",
      "Network configuration:\n",
      "  Input:                     A tuple of TokenIds and TokenTypes.\n",
      "  Output:                    2 logit vectors (with length ≤ 512) for start and end indexes of the answer.\n",
      "  Network Layers:            16\n",
      "  Tower Devices:             GPU0, GPU1, GPU2, GPU3\n",
      "  Total Network Parameters:  41,814,474\n",
      "  Total Parameter Tensors:   272\n",
      "  Trainable Tensors:         272\n",
      "  Training Samples:          87,844\n",
      "  Test Samples:              10,833\n",
      "  Num Epochs:                2\n",
      "  Batch Size:                32\n",
      "  L2 Reg. Factor:            0.0001\n",
      "  Global Drop Rate:          0   \n",
      "  Learning Rate: (Exponential Decay)\n",
      "    Initial Value:           0.00002      \n",
      "    Final Value:             0.000004     \n",
      "  Optimizer:                 Adam\n",
      "\n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "| Epoch  | Batch   | Learning Rate | Loss      | Valid/Test Acc.   |\n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "| 1      | 2745    | 0.00000926582 | 0.8067702 | N/A        77.04% |\n",
      "| 2      | 5491    | 0.00000407813 | 0.6160429 | N/A        77.82% |\n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "Total Training Time: 3082.89 Seconds\n",
      "  Processed 10833 Samples. (Time: 52.11 Sec.)                              \n",
      "\n",
      "    Exact Match: 77.824\n",
      "    f1:          85.868\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDs = SquadDSet.makeDatasets(\"Train\", batchSize=128, version=1 )\n",
    "\n",
    "model = Model.makeFromFile(prunedFileName, trainDs=trainDs, testDs=testDs,\n",
    "                           batchSize=32, numEpochs=2,\n",
    "                           regFactor=0.0001,\n",
    "                           learningRate=(2e-5,4e-6), optimizer='Adam',\n",
    "                           saveBest=False,\n",
    "                           gpus=gpus)\n",
    "model.printNetConfig()\n",
    "model.initSession()\n",
    "model.train()\n",
    "results = model.evaluate()\n",
    "\n",
    "retrainedFileName = prunedFileName.replace('.fbm', 'R.fbm')  # Append 'R' to the filename for \"Retrained\"\n",
    "model.save(retrainedFileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a036b87",
   "metadata": {},
   "source": [
    "## Where do I go from here?\n",
    "\n",
    "[Quantizing BERT/SQuAD Model](BertSquad-Quantize.ipynb)\n",
    "\n",
    "[Exporting BERT/SQuAD Model to ONNX](BertSquad-ONNX.ipynb)\n",
    "\n",
    "[Exporting BERT/SQuAD Model to TensorFlow](BertSquad-TF.ipynb)\n",
    "\n",
    "[Exporting BERT/SQuAD Model to CoreML](BertSquad-CoreML.ipynb)\n",
    "\n",
    "________________\n",
    "\n",
    "[Fireball Playgrounds](../Contents.ipynb)\n",
    "\n",
    "[Question Answering (BERT/SQuAD)](BertSquad.ipynb)\n",
    "\n",
    "[Reducing number of parameters of BERT/SQuAD Model](BertSquad-Reduce.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28692b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
