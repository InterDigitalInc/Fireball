{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting a BERT/SQuAD model to CoreML\n",
    "To use a Fireball model in an iOS application, we can use [exportToCoreMl](https://interdigitalinc.github.io/Fireball/html/source/model.html#fireball.model.Model.exportToCoreMl) method. This notebook shows how to use this function to create a CoreML model ready to be deployed in an iOS app. It assumes that a trained BERT/SQuAD model already exists in the ```Models``` directory. Please refer to the notebook [Question Answering (BERT/SQuAD)](BertSquad.ipynb) for more info about training and using a BERT/SQuAD model.\n",
    "\n",
    "Fireball can also export models with reduced number of parameters, pruned models, and quatized models. Please refer to the following notebooks for more information:\n",
    "\n",
    "- [Reducing number of parameters of BERT/SQuAD Model](BertSquad-Reduce.ipynb)\n",
    "- [Pruning BERT/SQuAD Model](BertSquad-Prune.ipynb)\n",
    "- [Quantizing BERT/SQuAD Model](BertSquad-Quantize.ipynb)\n",
    "\n",
    "Note: Fireball uses the [coremltools](https://github.com/apple/coremltools) python package to export CoreML models. \n",
    "\n",
    "## Load a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading from \"Models/BertSquadRRPRQR.fbm\" ... Done.\n",
      "Creating the fireball model \"Bert-SQuAD\" ... Done.\n",
      "\n",
      "Scope            InShape       Comments                 OutShape      Activ.   Post Act.        # of Params\n",
      "---------------  ------------  -----------------------  ------------  -------  ---------------  -----------\n",
      "IN_EMB           ≤512 2        LR512                    ≤512 768      None                      4,743,735  \n",
      "S1_L1_LN         ≤512 768                               ≤512 768      None     DO:0.1           1,536      \n",
      "S2_L1_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      2,839,069  \n",
      "S2_L2_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      2,898,847  \n",
      "S2_L3_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      2,909,099  \n",
      "S2_L4_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,036,692  \n",
      "S2_L5_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,125,424  \n",
      "S2_L6_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,135,978  \n",
      "S2_L7_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,094,206  \n",
      "S2_L8_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,102,034  \n",
      "S2_L9_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,161,228  \n",
      "S2_L10_BERT      ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,303,111  \n",
      "S2_L11_BERT      ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,264,611  \n",
      "S2_L12_BERT      ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      3,197,986  \n",
      "S3_L1_FC         ≤512 768                               ≤512 2        None     L2               918        \n",
      "OUT_ANSWER       ≤512 2                                 2 ≤512        None                      0          \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "                                                                  Total Number of parameters: 41,814,474 \n"
     ]
    }
   ],
   "source": [
    "from fireball import Model\n",
    "\n",
    "# orgFileName = \"Models/BertSquad.fbm\"        # Original model\n",
    "# orgFileName = \"Models/BertSquadQR.fbm\"      # Quantized - Retrained\n",
    "# orgFileName = \"Models/BertSquadPR.fbm\"      # Pruned - Retrained\n",
    "# orgFileName = \"Models/BertSquadPRQR.fbm\"    # Pruned - Retrained - Quantized - Retrained\n",
    "# orgFileName = \"Models/BertSquadRR.fbm\"      # Reduced - Retrained\n",
    "# orgFileName = \"Models/BertSquadRRQR.fbm\"    # Reduced - Retrained - Quantized - Retrained\n",
    "# orgFileName = \"Models/BertSquadRRPR.fbm\"    # Reduced - Retrained - Pruned - Retrained\n",
    "orgFileName = \"Models/BertSquadRRPRQR.fbm\"  # Reduced - Retrained - Pruned - Retrained - Quantized - Retrained\n",
    "\n",
    "\n",
    "model = Model.makeFromFile(orgFileName, gpus='0')\n",
    "model.printLayersInfo()\n",
    "model.initSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting to CoreML\n",
    "Our Fireball BERT/SQuAD model can handle combined sequence lengths of up to 512. Here we choose 384 as the max sequence length for the exported model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:TensorFlow version 2.8.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.6.2 is the most recent version that has been tested.\n",
      "WARNING:root:Keras version 2.8.0 has not been tested with coremltools. You may run into unexpected errors. Keras 2.6.0 is the most recent version that has been tested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exporting to CoreML model \"Models/BertSquadRRPRQR.mlmodel\" ... \n",
      "    Exported all 16 layers.                               \n",
      "    Saving to \"Models/BertSquadRRPRQR.mlmodel\" ... Done.\n",
      "Done (38.54 Sec.)\n"
     ]
    }
   ],
   "source": [
    "cmlFileName = orgFileName.replace('.fbm', '.mlmodel')\n",
    "\n",
    "seqLen = 384\n",
    "doc = \"This is the question answering model based on BERTbase and fine-tuned on SQuAD dataset. \"\\\n",
    "      \"The inputs are two lists of token IDs and token types based on word-piece vocabulary embedding \"\\\n",
    "      \"scheme. The token IDs list must start with a [CLS] and end with an [SEP] code. The question tokens and \"\\\n",
    "      \"context tokens must also be separated by another [SEP] code. The token types input must have 0's for \"\\\n",
    "      \"question tokens and 1's for context tokens. Both lists must be 0-padded to the length %d.\"%(seqLen)\n",
    "model.exportToCoreMl(cmlFileName, modelDesc=doc, maxSeqLen=seqLen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using netron to visualize the exported model\n",
    "We can now visualize the model's network structure using the [netron](https://github.com/lutzroeder/netron) package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'Models/BertSquadRRPRQR.mlmodel' at http://10.21.16.50:8084\n"
     ]
    }
   ],
   "source": [
    "import netron\n",
    "import platform\n",
    "\n",
    "if platform.system() == 'Darwin':      # Running on MAC\n",
    "    netron.start(cmlFileName)   \n",
    "else:\n",
    "    import socket\n",
    "    hostIp = socket.gethostbyname(socket.gethostname())\n",
    "    netron.start(cmlFileName, address=(hostIp,8084))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running inference on the exported model\n",
    "To verify the exported model, we can now run inference on it. Currently the CoreML runtime is only available on Mac. You can run all previous cells on a GPU-based machine and then copy the exported CoreML file to a Mac and test the model using the code in the following cell.\n",
    "\n",
    "Here we have a \"context\" which is a paragraph about InterDigital copied from Wikipedia and 3 different questions related to the context. We use our exported CoreML model to answer the questions.\n",
    "\n",
    "**Note:** We could use the \"Tokenizer\" included in Fireball. But to show the independence of the following code from Fireball, we are using Google's original tokenizer from here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "InterDigital is a technology research and development company that provides wireless and video technologies for \n",
      "mobile devices, networks, and services worldwide. Founded in 1972, InterDigital is listed on NASDAQ and is \n",
      "included in the S&P SmallCap 600. InterDigital had 2020 revenue of $359 million and a portfolio of about \n",
      "32,000 U.S. and foreign issued patents and patent applications.\n",
      "\n",
      "\n",
      "Q1: When was InterDigital established?\n",
      "    1972\n",
      "\n",
      "Q2: How much was InterDigital's revenue in 2020?\n",
      "    $ 35 ##9 million\n",
      "\n",
      "Q3: What does InterDigital provide?\n",
      "    wireless and video technologies\n"
     ]
    }
   ],
   "source": [
    "# assert platform.system() == 'Darwin', \"This is only supported when running on Mac!\"\n",
    "context = r\"\"\"\n",
    "InterDigital is a technology research and development company that provides wireless and video technologies for \n",
    "mobile devices, networks, and services worldwide. Founded in 1972, InterDigital is listed on NASDAQ and is \n",
    "included in the S&P SmallCap 600. InterDigital had 2020 revenue of $359 million and a portfolio of about \n",
    "32,000 U.S. and foreign issued patents and patent applications.\n",
    "\"\"\"\n",
    "\n",
    "print(context)\n",
    "questions = [\n",
    "    \"When was InterDigital established?\",\n",
    "    \"How much was InterDigital's revenue in 2020?\",\n",
    "    \"What does InterDigital provide?\",\n",
    "]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tokenization\n",
    "tokenizer = tokenization.FullTokenizer(\"/Users/shahab/data/SQuAD/vocab.txt\")\n",
    "\n",
    "import coremltools\n",
    "cmlFileName = \"Models/BertSquadRRPRQR.mlmodel\"\n",
    "seqLen = 384\n",
    "coreMlModel = coremltools.models.MLModel(cmlFileName)\n",
    "\n",
    "contextTokens = tokenizer.tokenize(context)\n",
    "for i, question in enumerate(questions):\n",
    "    questionTokens = tokenizer.tokenize(question)\n",
    "    allTokens = [\"[CLS]\"] + questionTokens + [\"[SEP]\"] + contextTokens + [\"[SEP]\"]\n",
    "    numPad = (seqLen - len(allTokens)) \n",
    "    allTokens += numPad*[\"[PAD]\"]\n",
    "    tokIds = tokenizer.convert_tokens_to_ids(allTokens)\n",
    "    tokTypes = [0]*(len(questionTokens)+2) + [1]*(len(contextTokens)+1) + numPad*[0]\n",
    "\n",
    "    outputDic = coreMlModel.predict({ 'TokIds': np.int32(tokIds), 'TokTypes': np.int32(tokTypes) })\n",
    "    startTok = np.argmax(outputDic['StartLogits']) - len(questionTokens) - 2\n",
    "    endTok = np.argmax(outputDic['EndLogits']) - len(questionTokens) - 2\n",
    "    answer = ' '.join(contextTokens[int(startTok):int(endTok+1)])\n",
    "    print(\"\\nQ%d: %s\\n    %s\"%(i+1, question, answer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where do I go from here?\n",
    "\n",
    "[Exporting BERT/SQuAD Model to ONNX](BertSquad-ONNX.ipynb)\n",
    "\n",
    "[Exporting BERT/SQuAD Model to TensorFlow](BertSquad-TF.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "[Fireball Playgrounds](../Contents.ipynb)\n",
    "\n",
    "[Question Answering (BERT/SQuAD)](BertSquad.ipynb)\n",
    "\n",
    "[Reducing number of parameters of BERT/SQuAD Model](BertSquad-Reduce.ipynb)\n",
    "\n",
    "[Pruning BERT/SQuAD Model](BertSquad-Prune.ipynb)\n",
    "\n",
    "[Quantizing BERT/SQuAD Model](BertSquad-Quantize.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
