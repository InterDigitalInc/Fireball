{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing number of parameters of BERT/SQuAD Model\n",
    "This notebook shows how to use Low-Rank decomposition to reduce the number of parameters of a BERT/SQuAD model. It assumes that a trained model already exist in the ```Models``` directory. Please refer to the notebook [Question Answering (BERT/SQuAD)](BertSquad.ipynb) for more info about training and using a BERT/SQuAD model.\n",
    "\n",
    "## Load and evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing tokenizer from \"/data/SQuAD/vocab.txt\" ... Done. (Vocab Size: 30522)\n",
      "\n",
      "Reading from \"Models/BertSquad.fbm\" ... Done.\n",
      "Creating the fireball model \"Bert-SQuAD\" ... Done.\n",
      "\n",
      "Scope            InShape       Comments                 OutShape      Activ.   Post Act.        # of Params\n",
      "---------------  ------------  -----------------------  ------------  -------  ---------------  -----------\n",
      "IN_EMB           ≤512 2                                 ≤512 768      None                      23,835,648 \n",
      "S1_L1_LN         ≤512 768                               ≤512 768      None     DO:0.1           1,536      \n",
      "S2_L1_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      7,087,872  \n",
      "S2_L2_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      7,087,872  \n",
      "S2_L3_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      7,087,872  \n",
      "S2_L4_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      7,087,872  \n",
      "S2_L5_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      7,087,872  \n",
      "S2_L6_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      7,087,872  \n",
      "S2_L7_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      7,087,872  \n",
      "S2_L8_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      7,087,872  \n",
      "S2_L9_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      7,087,872  \n",
      "S2_L10_BERT      ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      7,087,872  \n",
      "S2_L11_BERT      ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      7,087,872  \n",
      "S2_L12_BERT      ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      7,087,872  \n",
      "S3_L1_FC         ≤512 768                               ≤512 2        None     L2               1,538      \n",
      "OUT_ANSWER       ≤512 2                                 2 ≤512        None                      0          \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "                                                                  Total Number of parameters: 108,893,186\n",
      "  Processed 10833 Samples. (Time: 55.43 Sec.)                              \n",
      "\n",
      "    Exact Match: 80.549\n",
      "    f1:          87.825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from fireball import Model, myPrint\n",
    "from fireball.datasets.squad import SquadDSet\n",
    "import time, os\n",
    "\n",
    "gpus = \"0,1,2,3\"\n",
    "\n",
    "testDs = SquadDSet.makeDatasets(\"Test\", batchSize=128, version=1 )\n",
    "\n",
    "model = Model.makeFromFile(\"Models/BertSquad.fbm\", testDs=testDs, gpus=gpus)   \n",
    "model.printLayersInfo()\n",
    "model.initSession()\n",
    "results = model.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing number of parameters\n",
    "Here we apply Low-Rank Decomposition on different layers of the model to reduce the number of parameters. We first create a list of layers we want to apply Low-Rank Decomposition, and use the MSE value 0.0002 for all the selected layers. We then pass this information to the ```createLrModel``` method to create a new fireball model saved to the file ```Models/BertSquadR.fbm```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now reducing number of network parameters ... \n",
      "  IN_EMB => LR(512), MSE=0.000201, Params: 23440896->16020480 (Reduction: 31.7%)\n",
      "  S2_L1_BERT\n",
      "    SelfQuery => LR(296), MSE=0.000196, Params: 589824->454656 (Reduction: 22.9%)\n",
      "    SelfKey => LR(296), MSE=0.000197, Params: 589824->454656 (Reduction: 22.9%)\n",
      "    SelfValue => LR(208), MSE=0.000202, Params: 589824->319488 (Reduction: 45.8%)\n",
      "    SelfOut => LR(192), MSE=0.000194, Params: 589824->294912 (Reduction: 50.0%)\n",
      "    Intermediate => LR(464), MSE=0.000198, Params: 2359296->1781760 (Reduction: 24.5%)\n",
      "    Out => LR(464), MSE=0.000204, Params: 2359296->1781760 (Reduction: 24.5%)\n",
      "  S2_L2_BERT\n",
      "    SelfQuery => LR(304), MSE=0.000199, Params: 589824->466944 (Reduction: 20.8%)\n",
      "    SelfKey => LR(288), MSE=0.000205, Params: 589824->442368 (Reduction: 25.0%)\n",
      "    SelfValue => LR(200), MSE=0.000200, Params: 589824->307200 (Reduction: 47.9%)\n",
      "    SelfOut => LR(192), MSE=0.000196, Params: 589824->294912 (Reduction: 50.0%)\n",
      "    Intermediate => LR(480), MSE=0.000202, Params: 2359296->1843200 (Reduction: 21.9%)\n",
      "    Out => LR(472), MSE=0.000199, Params: 2359296->1812480 (Reduction: 23.2%)\n",
      "  S2_L3_BERT\n",
      "    SelfQuery => LR(312), MSE=0.000195, Params: 589824->479232 (Reduction: 18.8%)\n",
      "    SelfKey => LR(288), MSE=0.000198, Params: 589824->442368 (Reduction: 25.0%)\n",
      "    SelfValue => LR(192), MSE=0.000205, Params: 589824->294912 (Reduction: 50.0%)\n",
      "    SelfOut => LR(192), MSE=0.000195, Params: 589824->294912 (Reduction: 50.0%)\n",
      "    Intermediate => LR(480), MSE=0.000201, Params: 2359296->1843200 (Reduction: 21.9%)\n",
      "    Out => LR(480), MSE=0.000200, Params: 2359296->1843200 (Reduction: 21.9%)\n",
      "  S2_L4_BERT\n",
      "    SelfQuery => LR(312), MSE=0.000195, Params: 589824->479232 (Reduction: 18.8%)\n",
      "    SelfKey => LR(304), MSE=0.000195, Params: 589824->466944 (Reduction: 20.8%)\n",
      "    SelfValue => LR(216), MSE=0.000199, Params: 589824->331776 (Reduction: 43.8%)\n",
      "    SelfOut => LR(216), MSE=0.000198, Params: 589824->331776 (Reduction: 43.8%)\n",
      "    Intermediate => LR(496), MSE=0.000196, Params: 2359296->1904640 (Reduction: 19.3%)\n",
      "    Out => LR(488), MSE=0.000200, Params: 2359296->1873920 (Reduction: 20.6%)\n",
      "  S2_L5_BERT\n",
      "    SelfQuery => LR(304), MSE=0.000203, Params: 589824->466944 (Reduction: 20.8%)\n",
      "    SelfKey => LR(304), MSE=0.000202, Params: 589824->466944 (Reduction: 20.8%)\n",
      "    SelfValue => LR(264), MSE=0.000196, Params: 589824->405504 (Reduction: 31.2%)\n",
      "    SelfOut => LR(264), MSE=0.000197, Params: 589824->405504 (Reduction: 31.2%)\n",
      "    Intermediate => LR(496), MSE=0.000202, Params: 2359296->1904640 (Reduction: 19.3%)\n",
      "    Out => LR(488), MSE=0.000197, Params: 2359296->1873920 (Reduction: 20.6%)\n",
      "  S2_L6_BERT\n",
      "    SelfQuery => LR(312), MSE=0.000200, Params: 589824->479232 (Reduction: 18.8%)\n",
      "    SelfKey => LR(312), MSE=0.000196, Params: 589824->479232 (Reduction: 18.8%)\n",
      "    SelfValue => LR(272), MSE=0.000195, Params: 589824->417792 (Reduction: 29.2%)\n",
      "    SelfOut => LR(272), MSE=0.000201, Params: 589824->417792 (Reduction: 29.2%)\n",
      "    Intermediate => LR(496), MSE=0.000203, Params: 2359296->1904640 (Reduction: 19.3%)\n",
      "    Out => LR(480), MSE=0.000197, Params: 2359296->1843200 (Reduction: 21.9%)\n",
      "  S2_L7_BERT\n",
      "    SelfQuery => LR(304), MSE=0.000196, Params: 589824->466944 (Reduction: 20.8%)\n",
      "    SelfKey => LR(296), MSE=0.000203, Params: 589824->454656 (Reduction: 22.9%)\n",
      "    SelfValue => LR(272), MSE=0.000202, Params: 589824->417792 (Reduction: 29.2%)\n",
      "    SelfOut => LR(272), MSE=0.000205, Params: 589824->417792 (Reduction: 29.2%)\n",
      "    Intermediate => LR(504), MSE=0.000200, Params: 2359296->1935360 (Reduction: 18.0%)\n",
      "    Out => LR(464), MSE=0.000201, Params: 2359296->1781760 (Reduction: 24.5%)\n",
      "  S2_L8_BERT\n",
      "    SelfQuery => LR(288), MSE=0.000204, Params: 589824->442368 (Reduction: 25.0%)\n",
      "    SelfKey => LR(288), MSE=0.000201, Params: 589824->442368 (Reduction: 25.0%)\n",
      "    SelfValue => LR(288), MSE=0.000195, Params: 589824->442368 (Reduction: 25.0%)\n",
      "    SelfOut => LR(296), MSE=0.000202, Params: 589824->454656 (Reduction: 22.9%)\n",
      "    Intermediate => LR(488), MSE=0.000197, Params: 2359296->1873920 (Reduction: 20.6%)\n",
      "    Out => LR(480), MSE=0.000198, Params: 2359296->1843200 (Reduction: 21.9%)\n",
      "  S2_L9_BERT\n",
      "    SelfQuery => LR(304), MSE=0.000204, Params: 589824->466944 (Reduction: 20.8%)\n",
      "    SelfKey => LR(304), MSE=0.000201, Params: 589824->466944 (Reduction: 20.8%)\n",
      "    SelfValue => LR(288), MSE=0.000197, Params: 589824->442368 (Reduction: 25.0%)\n",
      "    SelfOut => LR(288), MSE=0.000203, Params: 589824->442368 (Reduction: 25.0%)\n",
      "    Intermediate => LR(480), MSE=0.000203, Params: 2359296->1843200 (Reduction: 21.9%)\n",
      "    Out => LR(496), MSE=0.000195, Params: 2359296->1904640 (Reduction: 19.3%)\n",
      "  S2_L10_BERT\n",
      "    SelfQuery => LR(336), MSE=0.000198, Params: 589824->516096 (Reduction: 12.5%)\n",
      "    SelfKey => LR(336), MSE=0.000196, Params: 589824->516096 (Reduction: 12.5%)\n",
      "    SelfValue => LR(304), MSE=0.000195, Params: 589824->466944 (Reduction: 20.8%)\n",
      "    SelfOut => LR(304), MSE=0.000200, Params: 589824->466944 (Reduction: 20.8%)\n",
      "    Intermediate => LR(480), MSE=0.000198, Params: 2359296->1843200 (Reduction: 21.9%)\n",
      "    Out => LR(512), MSE=0.000204, Params: 2359296->1966080 (Reduction: 16.7%)\n",
      "  S2_L11_BERT\n",
      "    SelfQuery => LR(336), MSE=0.000200, Params: 589824->516096 (Reduction: 12.5%)\n",
      "    SelfKey => LR(336), MSE=0.000199, Params: 589824->516096 (Reduction: 12.5%)\n",
      "    SelfValue => LR(296), MSE=0.000204, Params: 589824->454656 (Reduction: 22.9%)\n",
      "    SelfOut => LR(296), MSE=0.000195, Params: 589824->454656 (Reduction: 22.9%)\n",
      "    Intermediate => LR(472), MSE=0.000200, Params: 2359296->1812480 (Reduction: 23.2%)\n",
      "    Out => LR(504), MSE=0.000200, Params: 2359296->1935360 (Reduction: 18.0%)\n",
      "  S2_L12_BERT\n",
      "    SelfQuery => LR(336), MSE=0.000194, Params: 589824->516096 (Reduction: 12.5%)\n",
      "    SelfKey => LR(336), MSE=0.000194, Params: 589824->516096 (Reduction: 12.5%)\n",
      "    SelfValue => LR(320), MSE=0.000199, Params: 589824->491520 (Reduction: 16.7%)\n",
      "    SelfOut => LR(320), MSE=0.000198, Params: 589824->491520 (Reduction: 16.7%)\n",
      "    Intermediate => LR(488), MSE=0.000202, Params: 2359296->1873920 (Reduction: 20.6%)\n",
      "    Out => LR(424), MSE=0.000197, Params: 2359296->1628160 (Reduction: 31.0%)\n",
      "  S3_L1_FC => Cannot Decompose, MSE(1)=0.000480>0.000200\n",
      "Total New Parameters: 81,965,570\n",
      "Done. (191.14 Seconds)\n"
     ]
    }
   ],
   "source": [
    "layers = ['IN_EMB',\n",
    "          'S2_L1_BERT', 'S2_L2_BERT', 'S2_L3_BERT',\n",
    "          'S2_L4_BERT', 'S2_L5_BERT', 'S2_L6_BERT',\n",
    "          'S2_L7_BERT', 'S2_L8_BERT', 'S2_L9_BERT',\n",
    "          'S2_L10_BERT', 'S2_L11_BERT', 'S2_L12_BERT',\n",
    "          'S3_L1_FC']\n",
    "mse = 0.0002\n",
    "layerParams = [ (layer, mse) for layer in layers]\n",
    "\n",
    "myPrint('Now reducing number of network parameters ... ')\n",
    "t0 = time.time()\n",
    "model.createLrModel(\"Models/BertSquadR.fbm\", layerParams)\n",
    "myPrint('Done. (%.2f Seconds)'%(time.time()-t0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the new number of parameters with the original 108,893,186. \n",
    "\n",
    "## Evaluating the new model\n",
    "Let's see the impact of this reduction to the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading from \"Models/BertSquadR.fbm\" ... Done.\n",
      "Creating the fireball model \"Bert-SQuAD\" ... Done.\n",
      "\n",
      "Scope            InShape       Comments                 OutShape      Activ.   Post Act.        # of Params\n",
      "---------------  ------------  -----------------------  ------------  -------  ---------------  -----------\n",
      "IN_EMB           ≤512 2        LR512                    ≤512 768      None                      16,415,232 \n",
      "S1_L1_LN         ≤512 768                               ≤512 768      None     DO:0.1           1,536      \n",
      "S2_L1_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,097,216  \n",
      "S2_L2_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,177,088  \n",
      "S2_L3_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,207,808  \n",
      "S2_L4_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,398,272  \n",
      "S2_L5_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,533,440  \n",
      "S2_L6_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,551,872  \n",
      "S2_L7_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,484,288  \n",
      "S2_L8_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,508,864  \n",
      "S2_L9_BERT       ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,576,448  \n",
      "S2_L10_BERT      ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,785,344  \n",
      "S2_L11_BERT      ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,699,328  \n",
      "S2_L12_BERT      ≤512 768      768/3072, 12 heads       ≤512 768      GELU                      5,527,296  \n",
      "S3_L1_FC         ≤512 768                               ≤512 2        None     L2               1,538      \n",
      "OUT_ANSWER       ≤512 2                                 2 ≤512        None                      0          \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "                                                                  Total Number of parameters: 81,965,570 \n",
      "  Processed 10833 Samples. (Time: 51.86 Sec.)                              \n",
      "\n",
      "    Exact Match: 17.758\n",
      "    f1:          32.650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model.makeFromFile(\"Models/BertSquadR.fbm\", testDs=testDs, gpus=gpus)   \n",
    "model.printLayersInfo()\n",
    "model.initSession()\n",
    "results = model.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-train and evaluate\n",
    "Here we make a new model from ```ResNet50RR.fbm``` for re-training. We then call the ```train``` method of the model to start the re-training. This usually takes around 1 hour on a 4-GPU machine.\n",
    "\n",
    "If the trained model ```BertSquadRR.fbm``` is already available in the ```Models``` directory, this cell shows the results of last training. If you want to force it to do the training again, you can un-remark the line at the beginning of the cell to delete the existing file. Note that the re-training can take up to 1 hour on a 4-GPU machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing tokenizer from \"/data/SQuAD/vocab.txt\" ... Done. (Vocab Size: 30522)\n",
      "\n",
      "Reading from \"Models/BertSquadR.fbm\" ... Done.\n",
      "Creating the fireball model \"Bert-SQuAD\" ... Done.\n",
      "\n",
      "Network configuration:\n",
      "  Input:                     A tuple of TokenIds and TokenTypes.\n",
      "  Output:                    2 logit vectors (with length ≤ 512) for start and end indexes of the answer.\n",
      "  Network Layers:            16\n",
      "  Tower Devices:             GPU0, GPU1, GPU2, GPU3\n",
      "  Total Network Parameters:  81,965,570\n",
      "  Total Parameter Tensors:   272\n",
      "  Trainable Tensors:         272\n",
      "  Training Samples:          87,844\n",
      "  Test Samples:              10,833\n",
      "  Num Epochs:                2\n",
      "  Batch Size:                32\n",
      "  L2 Reg. Factor:            0.0001\n",
      "  Global Drop Rate:          0   \n",
      "  Learning Rate: (Exponential Decay)\n",
      "    Initial Value:           0.00002      \n",
      "    Final Value:             0.000004     \n",
      "  Optimizer:                 Adam\n",
      "  Save model information to: Models/BertSquadRR.fbm\n",
      "\n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "| Epoch  | Batch   | Learning Rate | Loss      | Valid/Test Acc.   |\n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "| 1      | 2746    | 0.00000926582 | 0.8890629 | N/A        79.30% |\n",
      "| 2      | 5492    | 0.00000407813 | 0.5906976 | N/A        79.74% |\n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "Total Training Time: 3084.70 Seconds\n",
      "  Processed 10833 Samples. (Time: 47.55 Sec.)                              \n",
      "\n",
      "    Exact Match: 79.745\n",
      "    f1:          87.431\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Un-remark the following line if you want to delete the existing re-trained model and re-train it again.\n",
    "# if os.path.exists( \"Models/BertSquadRR.fbm\" ): os.remove( \"Models/BertSquadRR.fbm\" )\n",
    "\n",
    "trainDs = SquadDSet.makeDatasets(\"Train\", batchSize=128, version=1 )\n",
    "\n",
    "model = Model.makeFromFile(\"Models/BertSquadR.fbm\", trainDs=trainDs, testDs=testDs,\n",
    "                           batchSize=32, numEpochs=2,\n",
    "                           regFactor=0.0001,\n",
    "                           learningRate=(2e-5,4e-6), optimizer='Adam',\n",
    "                           saveModelFileName=\"Models/BertSquadRR.fbm\",  # Save the re-training ...\n",
    "                           savePeriod=1,                                # ... every epoch\n",
    "                           saveBest=False,\n",
    "                           gpus=gpus)\n",
    "model.printNetConfig()\n",
    "model.initSession()\n",
    "model.train()\n",
    "results = model.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where do I go from here?\n",
    "\n",
    "[Pruning BERT/SQuAD Model](BertSquad-Prune.ipynb)\n",
    "\n",
    "[Quantizing BERT/SQuAD Model](BertSquad-Quantize.ipynb)\n",
    "\n",
    "[Exporting BERT/SQuAD Model to ONNX](BertSquad-ONNX.ipynb)\n",
    "\n",
    "[Exporting BERT/SQuAD Model to TensorFlow](BertSquad-TF.ipynb)\n",
    "\n",
    "[Exporting BERT/SQuAD Model to CoreML](BertSquad-CoreML.ipynb)\n",
    "\n",
    "________________\n",
    "\n",
    "[Fireball Playgrounds](../Contents.ipynb)\n",
    "\n",
    "[Question Answering (BERT/SQuAD)](BertSquad.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
