{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantizing the SSD Model\n",
    "This notebook shows how to quantize a pre-trained Fireball model using Codebook Quantization. It assumes \n",
    "that a trained ```SSD``` model already exists in the ```Models``` directory. Please refer to the notebook [Object Detection with SSD](SSD.ipynb) for more info about using a pretrained SSD model.\n",
    "\n",
    "If you want to quantize a Low-Rank model, you can use [this](SSD-Reduce.ipynb) notebook to reduce the number of parameters in ```SSD```.\n",
    "\n",
    "Model quantization reduces the size of the model by using less number of bits for each floating point parameter. Fireball uses a codebook quantization method based on K-Means clustering algorithm.\n",
    "\n",
    "[quantizeModel](https://interdigitalinc.github.io/Fireball/html/source/model.html#fireball.model.Model.quantizeModel) is a class method that receives the file names of input and output to the \n",
    "quantization process. It also receives the quantization parameters such as ```minBits```, ```maxBits```, \n",
    "and ```mseUb```.\n",
    "\n",
    "Fireball can create models with 2-bit to 12-bit quantization (Codebook sizes 4 to 4096). For the quantized\n",
    "model to be compatible with [CoreML](https://developer.apple.com/documentation/coreml), we need to make sure the codebook size is a power of 2, less than or equal to 256, and only \"weight\" parameters are quantized (not biases)\n",
    "\n",
    "## Quantizing a pretrained model\n",
    "The code in the following cell quantizes the model specified by ```orgFileName``` and creates a new quantized model.\n",
    "\n",
    "For each parameter tensor of the model, we try quantization bits 2 to 8 and find the best quantization that satisfies the specified MSE value.\n",
    "\n",
    "To get better quantization (smaller model) increase ```mse```; to get better performance (larger model)\n",
    "use a smaller ```mse```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading model parameters from \"Models/SSD512RRPR.fbm\" ... Done.\n",
      "Quantizing 92 tensors using 36 workers ... \n",
      "   Quantization Parameters:\n",
      "        mseUb .............. 3.2e-06\n",
      "        pdfFactor .......... 0.1\n",
      "        reuseEmptyClusters . True\n",
      "        weightsOnly ........ True\n",
      "        minBits ............ 2\n",
      "        maxBits ............ 8\n",
      "Quantization complete (6.35 Sec.)\n",
      "Now saving to \"Models/SSD512RRPRQ.fbm\" ... Done.\n",
      "\n",
      "Size of Data: 66,089,335 -> 18,922,286 bytes\n",
      "Model File Size: 66,097,263 -> 18,931,811 bytes\n"
     ]
    }
   ],
   "source": [
    "from fireball import Model\n",
    "gpus='upto4'\n",
    "\n",
    "orgFileName = \"Models/SSD512RRPR.fbm\"    # Reduced - Retrained - Pruned - Retrained\n",
    "\n",
    "quantizedFileName = orgFileName.replace('.fbm', 'Q.fbm')  # Append 'Q' to the filename for \"Quantized\"\n",
    "\n",
    "qResults = Model.quantizeModel(orgFileName, quantizedFileName,\n",
    "                               minBits=2, maxBits=8, mseUb=3.2e-6, reuseEmptyClusters=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the data size before and after quantization. \n",
    "\n",
    "## Evaluate the quantized model\n",
    "Let's see the impact on model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading from \"Models/SSD512RRPRQ.fbm\" ... Done.\n",
      "Creating the fireball model \"SSD512\" ... Done.\n",
      "  Processed 5000 Sample. (Time: 54.84 Sec.)                              \n",
      "\n",
      "Evaluating inference results for 5000 images ... \n",
      "  Calculating IoUs - Done (7.3 Seconds)                       \n",
      "  Finding matches - Done (116.1 Seconds)                     \n",
      "  Processing the matches - Done (3.6 Seconds)                    \n",
      "Done (127.0 Seconds)\n",
      "\n",
      "Average Precision (AP):\n",
      "    IoU=0.50:0.95   Area: All      MaxDet: 100  = 0.238\n",
      "    IoU=0.50        Area: All      MaxDet: 100  = 0.456\n",
      "    IoU=0.75        Area: All      MaxDet: 100  = 0.226\n",
      "    IoU=0.50:0.95   Area: Small    MaxDet: 100  = 0.092\n",
      "    IoU=0.50:0.95   Area: Medium   MaxDet: 100  = 0.278\n",
      "    IoU=0.50:0.95   Area: Large    MaxDet: 100  = 0.347\n",
      "Average Recall (AR):\n",
      "    IoU=0.50:0.95   Area: All      MaxDet: 1    = 0.221\n",
      "    IoU=0.50:0.95   Area: All      MaxDet: 10   = 0.340\n",
      "    IoU=0.50:0.95   Area: All      MaxDet: 100  = 0.365\n",
      "    IoU=0.50:0.95   Area: Small    MaxDet: 100  = 0.167\n",
      "    IoU=0.50:0.95   Area: Medium   MaxDet: 100  = 0.414\n",
      "    IoU=0.50:0.95   Area: Large    MaxDet: 100  = 0.500\n"
     ]
    }
   ],
   "source": [
    "from fireball.datasets.coco import CocoDSet\n",
    "\n",
    "trainDs,testDs = CocoDSet.makeDatasets('Train,Test', batchSize=64, resolution=512, keepAr=False, numWorkers=4)\n",
    "\n",
    "model = Model.makeFromFile(quantizedFileName, testDs=testDs, gpus=gpus)\n",
    "model.initSession()\n",
    "results = model.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-train and evaluate\n",
    "Fireball can retrain the quantized models by modifying the quantization codebooks. Here we first create new quantized model for training and then call the [train](https://interdigitalinc.github.io/Fireball/html/source/model.html#fireball.model.Model.train) method of the model to start the training. Note that the re-training can take up to 2 hours on a 4-GPU machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading from \"Models/SSD512RRPRQ.fbm\" ... Done.\n",
      "Creating the fireball model \"SSD512\" ... Done.\n",
      "\n",
      "Network configuration:\n",
      "  Input:                     Color images of size 512x512\n",
      "  Output:                    A tuple of class labels, boxes, class probabilities, and number of detections.\n",
      "  Network Layers:            28\n",
      "  Tower Devices:             GPU0, GPU1, GPU2, GPU3\n",
      "  Total Network Parameters:  15,799,194\n",
      "  Total Parameter Tensors:   92\n",
      "  Trainable Tensors:         92\n",
      "  Training Samples:          82,783\n",
      "  Test Samples:              5,000\n",
      "  Num Epochs:                5\n",
      "  Batch Size:                64\n",
      "  L2 Reg. Factor:            0     \n",
      "  Global Drop Rate:          0   \n",
      "  Learning Rate: (Exponential Decay)\n",
      "    Initial Value:           0.000000001  \n",
      "    Final Value:             0.00000000001\n",
      "  Optimizer:                 Momentum\n",
      "\n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "| Epoch  | Batch   | Learning Rate | Loss      | Valid/Test mAP    |\n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "| 1      | 1293    | 0.00000000042 | 1.5995638 | N/A        23.99% |\n",
      "| 2      | 2587    | 0.00000000017 | 1.596567  | N/A        23.99% |\n",
      "| 3      | 3881    | 0.00000000007 | 1.5956165 | N/A        23.99% |\n",
      "| 4      | 5175    | 0.00000000003 | 1.5959707 | N/A        23.99% |\n",
      "| 5      | 6469    | 0.00000000001 | 1.5960757 | N/A        23.99% |\n",
      "+--------+---------+---------------+-----------+-------------------+\n",
      "Total Training Time: 5170.68 Seconds\n",
      "  Processed 5000 Sample. (Time: 32.35 Sec.)                              \n",
      "\n",
      "Evaluating inference results for 5000 images ... \n",
      "  Calculating IoUs - Done (7.3 Seconds)                       \n",
      "  Finding matches - Done (122.1 Seconds)                     \n",
      "  Processing the matches - Done (4.0 Seconds)                    \n",
      "Done (133.4 Seconds)\n",
      "\n",
      "Average Precision (AP):\n",
      "    IoU=0.50:0.95   Area: All      MaxDet: 100  = 0.240\n",
      "    IoU=0.50        Area: All      MaxDet: 100  = 0.459\n",
      "    IoU=0.75        Area: All      MaxDet: 100  = 0.230\n",
      "    IoU=0.50:0.95   Area: Small    MaxDet: 100  = 0.091\n",
      "    IoU=0.50:0.95   Area: Medium   MaxDet: 100  = 0.283\n",
      "    IoU=0.50:0.95   Area: Large    MaxDet: 100  = 0.349\n",
      "Average Recall (AR):\n",
      "    IoU=0.50:0.95   Area: All      MaxDet: 1    = 0.222\n",
      "    IoU=0.50:0.95   Area: All      MaxDet: 10   = 0.342\n",
      "    IoU=0.50:0.95   Area: All      MaxDet: 100  = 0.367\n",
      "    IoU=0.50:0.95   Area: Small    MaxDet: 100  = 0.166\n",
      "    IoU=0.50:0.95   Area: Medium   MaxDet: 100  = 0.416\n",
      "    IoU=0.50:0.95   Area: Large    MaxDet: 100  = 0.504\n"
     ]
    }
   ],
   "source": [
    "model = Model.makeFromFile(quantizedFileName, trainDs=trainDs, testDs=testDs,\n",
    "                           numEpochs=5,\n",
    "                           learningRate=(1e-9,1e-11),\n",
    "                           optimizer=\"Momentum\",\n",
    "                           gpus=gpus)\n",
    "model.printNetConfig()\n",
    "model.initSession()\n",
    "model.train()\n",
    "results = model.evaluate()\n",
    "\n",
    "retrainedFileName = quantizedFileName.replace('.fbm', 'R.fbm')  # Append 'R' to the filename for \"Re-trained\"\n",
    "model.save(retrainedFileName)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Also look at\n",
    "\n",
    "[Exporting SSD Model to ONNX](SSD-ONNX.ipynb)\n",
    "\n",
    "[Exporting SSD Model to TensorFlow](SSD-TF.ipynb)\n",
    "\n",
    "[Exporting SSD Model to CoreML](SSD-CoreML.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "[Fireball Playgrounds](../Contents.ipynb)\n",
    "\n",
    "[Object Detection with SSD](SSD.ipynb)\n",
    "\n",
    "[Reducing number of parameters of SSD Model](SSD-Reduce.ipynb)\n",
    "\n",
    "[Pruning SSD Model](SSD-Prune.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
